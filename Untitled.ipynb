{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/patsy/constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# stop_words.extend(['mr', 'ms', 'said'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# def lemmatize(content, tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "#     texts_out = []\n",
    "#     for sent in texts:\n",
    "#         doc = nlp(\" \".join(sent)) \n",
    "#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "#     return texts_out\n",
    "\n",
    "# Tokenize and remove stop words from content\n",
    "def tokenize(content, lemmatize=False):\n",
    "    words = gensim.utils.simple_preprocess(content, deacc=True)  # tokenizes\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(content):\n",
    "    words = []\n",
    "    for word in content:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not lemmatizing or stemming. If we need to increase accuracy in the future, we can consider it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[two, years, ago, homer, bush, came, yankee, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>[texas, record, tell, op, ed, april, paul, bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>[top, foreign, policy, adviser, gov, george, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[aides, gov, george, bush, fought, back, today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[gov, tommy, thompson, wisconsin, named, chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[new, york, times, cbs, news, poll, var, strin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[tick, tock, diner, ted, friedrich, stockbroke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[difference, us, vital, issue, would, go, wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[bush, administration, wanted, overturn, would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[first, gov, jeb, bush, florida, told, hallowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5806 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                            Content\n",
       "0     2000-05-03  [two, years, ago, homer, bush, came, yankee, b...\n",
       "1     2000-05-02  [texas, record, tell, op, ed, april, paul, bur...\n",
       "2     2000-05-01  [top, foreign, policy, adviser, gov, george, b...\n",
       "3     2000-05-03  [aides, gov, george, bush, fought, back, today...\n",
       "4     2000-05-03  [gov, tommy, thompson, wisconsin, named, chair...\n",
       "...          ...                                                ...\n",
       "5801  2000-10-31  [new, york, times, cbs, news, poll, var, strin...\n",
       "5802  2000-10-31  [tick, tock, diner, ted, friedrich, stockbroke...\n",
       "5803  2000-11-01  [difference, us, vital, issue, would, go, wash...\n",
       "5804  2000-11-01  [bush, administration, wanted, overturn, would...\n",
       "5805  2000-11-01  [first, gov, jeb, bush, florida, told, hallowe...\n",
       "\n",
       "[5806 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New York Times Data\n",
    "rows = []\n",
    "dates = []\n",
    "articles = []\n",
    "for month in range(5, 11):\n",
    "    with open(\"Data/NYTimes/\"+ str(month) + \".txt\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            date, article = line.split(\",\", 1)\n",
    "            timestamp = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "            tokenized = tokenize(article)\n",
    "            destopped = remove_stopwords(tokenized)\n",
    "\n",
    "            articles.append(destopped)\n",
    "            dates.append(timestamp)\n",
    "            rows.append([timestamp, destopped])\n",
    "\n",
    "nytimes = pd.DataFrame(rows, columns=[\"Date\", \"Content\"]) \n",
    "unique_dates = sorted(list(set(nytimes[\"Date\"])))\n",
    "# print (unique_dates)\n",
    "nytimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 days missing from the stock market data: 6/07, 6/08, 11/01. There are several ways we can deal with this. \n",
    "1. Toss out the three days from the NYTimes data\n",
    "2. Condense 6/07 --> 6/06; 6/08 --> 6/09 (or something similar) and toss out 11/01. \n",
    "3. Something else that I can't think of at the moment\n",
    "\n",
    "I also haven't looked at the paper to see how they deal with it yet.\n",
    "\n",
    "Edit: Reading over some articles about time series, it seems that we should pad the missing datapoints with previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-04</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-05</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  LastPrice\n",
       "0    2000-05-01   0.523810\n",
       "1    2000-05-02   0.504970\n",
       "2    2000-05-03   0.509491\n",
       "3    2000-05-04   0.511466\n",
       "4    2000-05-05   0.520875\n",
       "..          ...        ...\n",
       "177  2000-10-27   0.384310\n",
       "178  2000-10-28   0.296488\n",
       "179  2000-10-29   0.345703\n",
       "180  2000-10-30   0.380711\n",
       "181  2000-10-31   0.381966\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Series Data\n",
    "ts_months = [\"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\"]\n",
    "cols = ['Date', 'LastPrice']\n",
    "stock_prices = pd.DataFrame()\n",
    "for month in ts_months:\n",
    "    ts_df = pd.read_csv(\"Data/PriceHistory/\" + month + \".txt\", delim_whitespace=True)\n",
    "    ts_df['Date'] =  ts_df['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%y\").date())\n",
    "    \n",
    "    Gore = ts_df.loc[ts_df['Contract'] == 'Dem'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "    Bush = ts_df.loc[ts_df['Contract'] == 'Rep'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "\n",
    "    # Gore/(Gore + Bush)\n",
    "    relation = list(zip(Gore['Date'], (Gore['LastPrice']/(Gore['LastPrice'] + Bush['LastPrice'])).fillna(0)))\n",
    "    stock_prices = stock_prices.append(relation, ignore_index=True)\n",
    "\n",
    "stock_prices.columns = cols\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(unique_dates)):\n",
    "#     if unique_dates[i] not in list(stock_prices[0]):\n",
    "#         print (unique_dates[i])\n",
    "\n",
    "# bigram = Phrases(articles, min_count=1)\n",
    "# bigrams = [b for b in bigram[articles]]\n",
    "# articles = bigrams\n",
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-7-5488d17a90b0>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  doc_word_cnts = (np.array([np.array([(id2word[id], freq) for id, freq in cp]) for cp in corpus]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('ago', 0.07712049873418031),\n",
       "  ('awesome', 0.23220574510227418),\n",
       "  ('backup', 0.2198823985449398),\n",
       "  ('backups', 0.2515408271170864),\n",
       "  ('bases', 0.19264069440348208),\n",
       "  ('bellinger', 0.27548950382241366),\n",
       "  ('bench', 0.1896343958919212),\n",
       "  ('bush', 0.007894722475376273),\n",
       "  ('came', 0.08612993720379283),\n",
       "  ('catcher', 0.26148042600790294),\n",
       "  ('clay', 0.2135830725972484),\n",
       "  ('games', 0.1562902360625982),\n",
       "  ('girardi', 0.27548950382241366),\n",
       "  ('homer', 0.21658937110880933),\n",
       "  ('jim', 0.1245222966630543),\n",
       "  ('joe', 0.1146922085996351),\n",
       "  ('leyritz', 0.27548950382241366),\n",
       "  ('speed', 0.17969479700110466),\n",
       "  ('stole', 0.20587332073042908),\n",
       "  ('strength', 0.13402729061444735),\n",
       "  ('turner', 0.2108175460504276),\n",
       "  ('two', 0.04788545375938528),\n",
       "  ('versatility', 0.27548950382241366),\n",
       "  ('whose', 0.0887458288821732),\n",
       "  ('yankee', 0.20825706839694694),\n",
       "  ('yankees', 0.19264069440348208),\n",
       "  ('years', 0.05159983565074285)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(articles)\n",
    "\n",
    "# Attempt at filtering out words that appear too frequently\n",
    "# id2word.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "# id2word.filter_extremes(no_above=0.5)\n",
    "\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in articles]\n",
    "doc_word_cnts = (np.array([np.array([(id2word[id], freq) for id, freq in cp]) for cp in corpus]))\n",
    "\n",
    "# TF-IDF seems to give better coherence (but it wasn't in the paper...)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in tfidf_corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ago', 4),\n",
       " ('awesome', 2),\n",
       " ('backup', 2),\n",
       " ('backups', 2),\n",
       " ('bases', 2),\n",
       " ('bellinger', 2),\n",
       " ('bench', 2),\n",
       " ('bush', 150),\n",
       " ('came', 4),\n",
       " ('catcher', 2),\n",
       " ('clay', 2),\n",
       " ('games', 2),\n",
       " ('girardi', 2),\n",
       " ('homer', 2),\n",
       " ('jim', 2),\n",
       " ('joe', 4),\n",
       " ('leyritz', 2),\n",
       " ('speed', 2),\n",
       " ('stole', 2),\n",
       " ('strength', 2),\n",
       " ('turner', 2),\n",
       " ('two', 8),\n",
       " ('versatility', 2),\n",
       " ('whose', 4),\n",
       " ('yankee', 2),\n",
       " ('yankees', 2),\n",
       " ('years', 16),\n",
       " ('across', 2),\n",
       " ('also', 14),\n",
       " ('april', 2),\n",
       " ('chief', 4),\n",
       " ('conservative', 8),\n",
       " ('george', 22),\n",
       " ('get', 6),\n",
       " ('gov', 18),\n",
       " ('governor', 24),\n",
       " ('held', 2),\n",
       " ('little', 2),\n",
       " ('long', 2),\n",
       " ('name', 2),\n",
       " ('one', 20),\n",
       " ('part', 2),\n",
       " ('perhaps', 2),\n",
       " ('point', 2),\n",
       " ('president', 38),\n",
       " ('question', 2),\n",
       " ('record', 2),\n",
       " ('republican', 24),\n",
       " ('running', 10),\n",
       " ('social', 16),\n",
       " ('state', 12),\n",
       " ('states', 8),\n",
       " ('texas', 12),\n",
       " ('trying', 2),\n",
       " ('would', 46),\n",
       " ('year', 12),\n",
       " ('accounts', 6),\n",
       " ('administration', 14),\n",
       " ('adviser', 4),\n",
       " ('al', 22),\n",
       " ('argued', 4),\n",
       " ('assertion', 2),\n",
       " ('boston', 4),\n",
       " ('call', 2),\n",
       " ('campaign', 42),\n",
       " ('clear', 2),\n",
       " ('clinton', 16),\n",
       " ('committee', 10),\n",
       " ('country', 4),\n",
       " ('critical', 2),\n",
       " ('cut', 34),\n",
       " ('cuts', 2),\n",
       " ('day', 4),\n",
       " ('delivered', 2),\n",
       " ('devoted', 2),\n",
       " ('dispute', 2),\n",
       " ('economic', 10),\n",
       " ('effort', 2),\n",
       " ('either', 2),\n",
       " ('enemies', 2),\n",
       " ('even', 8),\n",
       " ('failed', 2),\n",
       " ('form', 2),\n",
       " ('free', 2),\n",
       " ('future', 4),\n",
       " ('going', 4),\n",
       " ('gore', 108),\n",
       " ('half', 6),\n",
       " ('included', 2),\n",
       " ('issue', 6),\n",
       " ('issues', 6),\n",
       " ('left', 2),\n",
       " ('meant', 4),\n",
       " ('meeting', 2),\n",
       " ('meetings', 2),\n",
       " ('missile', 2),\n",
       " ('money', 14),\n",
       " ('mr', 196),\n",
       " ('ms', 2),\n",
       " ('national', 16),\n",
       " ('new', 24),\n",
       " ('offered', 2),\n",
       " ('others', 2),\n",
       " ('particularly', 2),\n",
       " ('past', 4),\n",
       " ('percent', 8),\n",
       " ('policy', 16),\n",
       " ('presidential', 22),\n",
       " ('reporters', 2),\n",
       " ('republicans', 14),\n",
       " ('right', 12),\n",
       " ('role', 2),\n",
       " ('round', 2),\n",
       " ('said', 54),\n",
       " ('saying', 10),\n",
       " ('security', 16),\n",
       " ('senator', 8),\n",
       " ('series', 2),\n",
       " ('served', 2),\n",
       " ('session', 2),\n",
       " ('set', 4),\n",
       " ('since', 4),\n",
       " ('speech', 14),\n",
       " ('speeches', 6),\n",
       " ('stand', 2),\n",
       " ('taken', 2),\n",
       " ('three', 4),\n",
       " ('time', 6),\n",
       " ('today', 24),\n",
       " ('union', 2),\n",
       " ('using', 4),\n",
       " ('vice', 30),\n",
       " ('violent', 4),\n",
       " ('vision', 4),\n",
       " ('vote', 4),\n",
       " ('war', 4),\n",
       " ('way', 2),\n",
       " ('weeks', 2),\n",
       " ('win', 2),\n",
       " ('work', 2),\n",
       " ('world', 2),\n",
       " ('yet', 2),\n",
       " ('accommodate', 6),\n",
       " ('accusations', 4),\n",
       " ('added', 6),\n",
       " ('addressed', 2),\n",
       " ('advertising', 2),\n",
       " ('advisers', 10),\n",
       " ('agenda', 2),\n",
       " ('aides', 20),\n",
       " ('allowing', 4),\n",
       " ('america', 6),\n",
       " ('amount', 2),\n",
       " ('analysis', 4),\n",
       " ('annual', 2),\n",
       " ('another', 4),\n",
       " ('appearances', 2),\n",
       " ('appropriate', 4),\n",
       " ('areas', 2),\n",
       " ('array', 6),\n",
       " ('aside', 2),\n",
       " ('asserted', 4),\n",
       " ('assets', 2),\n",
       " ('assumes', 2),\n",
       " ('assuming', 4),\n",
       " ('back', 12),\n",
       " ('backing', 2),\n",
       " ('bad', 4),\n",
       " ('balanced', 2),\n",
       " ('battle', 6),\n",
       " ('benefits', 2),\n",
       " ('billion', 8),\n",
       " ('bottom', 2),\n",
       " ('break', 2),\n",
       " ('budget', 4),\n",
       " ('calculations', 6),\n",
       " ('called', 8),\n",
       " ('campaigning', 2),\n",
       " ('campaigns', 2),\n",
       " ('capitol', 2),\n",
       " ('care', 4),\n",
       " ('carry', 2),\n",
       " ('centerpiece', 2),\n",
       " ('charging', 2),\n",
       " ('claimed', 2),\n",
       " ('comfortably', 2),\n",
       " ('congress', 12),\n",
       " ('congressional', 2),\n",
       " ('considers', 2),\n",
       " ('context', 2),\n",
       " ('continue', 2),\n",
       " ('controlled', 2),\n",
       " ('core', 2),\n",
       " ('cost', 10),\n",
       " ('costs', 4),\n",
       " ('counter', 2),\n",
       " ('criticized', 4),\n",
       " ('days', 8),\n",
       " ('debt', 8),\n",
       " ('debts', 2),\n",
       " ('decrease', 2),\n",
       " ('defense', 4),\n",
       " ('deficits', 4),\n",
       " ('disclose', 2),\n",
       " ('discretionary', 2),\n",
       " ('dollar', 2),\n",
       " ('dollars', 4),\n",
       " ('domestic', 4),\n",
       " ('drug', 22),\n",
       " ('earlier', 6),\n",
       " ('economy', 8),\n",
       " ('effect', 2),\n",
       " ('elaine', 2),\n",
       " ('eliminating', 4),\n",
       " ('embrace', 2),\n",
       " ('enough', 6),\n",
       " ('era', 4),\n",
       " ('estimate', 2),\n",
       " ('estimated', 2),\n",
       " ('estimates', 2),\n",
       " ('examine', 2),\n",
       " ('extra', 2),\n",
       " ('families', 4),\n",
       " ('federal', 14),\n",
       " ('figures', 2),\n",
       " ('financial', 2),\n",
       " ('finding', 2),\n",
       " ('first', 10),\n",
       " ('fiscal', 8),\n",
       " ('fit', 2),\n",
       " ('five', 8),\n",
       " ('forecast', 2),\n",
       " ('fought', 4),\n",
       " ('giving', 2),\n",
       " ('go', 10),\n",
       " ('government', 6),\n",
       " ('greatest', 2),\n",
       " ('grow', 2),\n",
       " ('growth', 6),\n",
       " ('higher', 2),\n",
       " ('hill', 2),\n",
       " ('hours', 4),\n",
       " ('huge', 4),\n",
       " ('increased', 2),\n",
       " ('increases', 2),\n",
       " ('individual', 6),\n",
       " ('instead', 2),\n",
       " ('interest', 4),\n",
       " ('interviews', 2),\n",
       " ('invested', 2),\n",
       " ('investment', 2),\n",
       " ('joint', 2),\n",
       " ('kamarck', 2),\n",
       " ('large', 4),\n",
       " ('larger', 2),\n",
       " ('last', 14),\n",
       " ('lawrence', 2),\n",
       " ('less', 6),\n",
       " ('lindsey', 2),\n",
       " ('line', 2),\n",
       " ('looming', 2),\n",
       " ('lost', 2),\n",
       " ('made', 6),\n",
       " ('make', 4),\n",
       " ('markets', 2),\n",
       " ('means', 4),\n",
       " ('monday', 6),\n",
       " ('month', 2),\n",
       " ('months', 6),\n",
       " ('much', 4),\n",
       " ('multitrillion', 2),\n",
       " ('nation', 4),\n",
       " ('nominee', 12),\n",
       " ('numbers', 4),\n",
       " ('obligation', 2),\n",
       " ('offensive', 2),\n",
       " ('original', 2),\n",
       " ('otherwise', 2),\n",
       " ('paid', 2),\n",
       " ('pay', 4),\n",
       " ('payroll', 2),\n",
       " ('plan', 10),\n",
       " ('plans', 2),\n",
       " ('pointed', 4),\n",
       " ('portion', 2),\n",
       " ('prescription', 2),\n",
       " ('presumptive', 8),\n",
       " ('previously', 2),\n",
       " ('private', 2),\n",
       " ('privatization', 2),\n",
       " ('program', 6),\n",
       " ('programs', 4),\n",
       " ('projections', 2),\n",
       " ('promises', 2),\n",
       " ('proposal', 14),\n",
       " ('proposals', 14),\n",
       " ('prosperity', 2),\n",
       " ('provides', 2),\n",
       " ('public', 2),\n",
       " ('push', 2),\n",
       " ('put', 4),\n",
       " ('putting', 4),\n",
       " ('rate', 2),\n",
       " ('reduction', 4),\n",
       " ('reductions', 2),\n",
       " ('refused', 2),\n",
       " ('related', 2),\n",
       " ('released', 8),\n",
       " ('require', 2),\n",
       " ('retirement', 4),\n",
       " ('return', 4),\n",
       " ('revenues', 2),\n",
       " ('risk', 2),\n",
       " ('risky', 4),\n",
       " ('robust', 2),\n",
       " ('roughly', 2),\n",
       " ('say', 10),\n",
       " ('says', 4),\n",
       " ('serious', 2),\n",
       " ('sharply', 2),\n",
       " ('shore', 2),\n",
       " ('showed', 4),\n",
       " ('six', 6),\n",
       " ('slightly', 2),\n",
       " ('spending', 22),\n",
       " ('stepping', 2),\n",
       " ('still', 4),\n",
       " ('stopped', 2),\n",
       " ('surplus', 8),\n",
       " ('surpluses', 2),\n",
       " ('system', 4),\n",
       " ('takes', 2),\n",
       " ('tax', 26),\n",
       " ('taxation', 2),\n",
       " ('taxes', 6),\n",
       " ('television', 2),\n",
       " ('term', 2),\n",
       " ('toward', 2),\n",
       " ('trillion', 14),\n",
       " ('true', 2),\n",
       " ('underestimating', 2),\n",
       " ('underscores', 2),\n",
       " ('unimaginable', 2),\n",
       " ('use', 8),\n",
       " ('waged', 2),\n",
       " ('weakness', 2),\n",
       " ('well', 6),\n",
       " ('went', 2),\n",
       " ('within', 4),\n",
       " ('workers', 2),\n",
       " ('working', 2),\n",
       " ('abortion', 10),\n",
       " ('action', 4),\n",
       " ('advocacy', 4),\n",
       " ('advocates', 2),\n",
       " ('among', 10),\n",
       " ('anti', 2),\n",
       " ('appointment', 4),\n",
       " ('arizona', 2),\n",
       " ('articulate', 2),\n",
       " ('ayres', 2),\n",
       " ('bind', 2),\n",
       " ('birth', 2),\n",
       " ('cares', 2),\n",
       " ('chairman', 4),\n",
       " ('cnn', 4),\n",
       " ('convention', 6),\n",
       " ('despite', 4),\n",
       " ('draft', 2),\n",
       " ('drummond', 2),\n",
       " ('ease', 2),\n",
       " ('error', 2),\n",
       " ('far', 4),\n",
       " ('forward', 4),\n",
       " ('found', 2),\n",
       " ('gallup', 4),\n",
       " ('gives', 2),\n",
       " ('ideas', 6),\n",
       " ('inclined', 4),\n",
       " ('inclusiveness', 2),\n",
       " ('independents', 4),\n",
       " ('indicates', 2),\n",
       " ('innovative', 2),\n",
       " ('irvin', 2),\n",
       " ('john', 6),\n",
       " ('jr', 2),\n",
       " ('kate', 2),\n",
       " ('latest', 2),\n",
       " ('lead', 4),\n",
       " ('league', 2),\n",
       " ('led', 6),\n",
       " ('legislation', 6),\n",
       " ('likely', 2),\n",
       " ('looked', 4),\n",
       " ('margin', 2),\n",
       " ('mate', 8),\n",
       " ('mccain', 12),\n",
       " ('michelman', 2),\n",
       " ('minus', 2),\n",
       " ('molotsky', 2),\n",
       " ('named', 2),\n",
       " ('nine', 2),\n",
       " ('nyt', 4),\n",
       " ('opponents', 4),\n",
       " ('outlawing', 2),\n",
       " ('partial', 2),\n",
       " ('party', 12),\n",
       " ('pick', 2),\n",
       " ('platform', 2),\n",
       " ('plus', 2),\n",
       " ('points', 6),\n",
       " ('poll', 10),\n",
       " ('position', 8),\n",
       " ('preference', 2),\n",
       " ('presumed', 2),\n",
       " ('principles', 2),\n",
       " ('procedure', 2),\n",
       " ('regard', 2),\n",
       " ('rights', 8),\n",
       " ('sampling', 2),\n",
       " ('selection', 2),\n",
       " ('serving', 2),\n",
       " ('sign', 4),\n",
       " ('signed', 2),\n",
       " ('staunch', 2),\n",
       " ('summer', 4),\n",
       " ('surveyed', 2),\n",
       " ('thompson', 6),\n",
       " ('ticket', 4),\n",
       " ('together', 2),\n",
       " ('tommy', 2),\n",
       " ('us', 6),\n",
       " ('usa', 4),\n",
       " ('voters', 10),\n",
       " ('wants', 2),\n",
       " ('widen', 2),\n",
       " ('wisconsin', 2),\n",
       " ('apparent', 2),\n",
       " ('contributions', 2),\n",
       " ('democrats', 4),\n",
       " ('event', 2),\n",
       " ('example', 2),\n",
       " ('million', 4),\n",
       " ('raise', 2),\n",
       " ('received', 2),\n",
       " ('soft', 6),\n",
       " ('age', 2),\n",
       " ('although', 2),\n",
       " ('american', 4),\n",
       " ('analysts', 2),\n",
       " ('around', 2),\n",
       " ('ban', 6),\n",
       " ('comes', 2),\n",
       " ('could', 6),\n",
       " ('defend', 2),\n",
       " ('directly', 2),\n",
       " ('filled', 2),\n",
       " ('health', 2),\n",
       " ('institute', 2),\n",
       " ('joined', 2),\n",
       " ('majority', 4),\n",
       " ('meet', 2),\n",
       " ('message', 2),\n",
       " ('people', 6),\n",
       " ('phrase', 2),\n",
       " ('press', 2),\n",
       " ('provided', 2),\n",
       " ('test', 4),\n",
       " ('used', 4),\n",
       " ('yesterday', 2),\n",
       " ('civil', 2),\n",
       " ('consider', 2),\n",
       " ('early', 4),\n",
       " ('fact', 2),\n",
       " ('father', 2),\n",
       " ('might', 2),\n",
       " ('photo', 2),\n",
       " ('race', 2),\n",
       " ('rule', 2),\n",
       " ('secretary', 6),\n",
       " ('services', 2),\n",
       " ('americans', 4),\n",
       " ('bill', 12),\n",
       " ('calls', 2),\n",
       " ('candidates', 2),\n",
       " ('cause', 2),\n",
       " ('commands', 2),\n",
       " ('corporation', 2),\n",
       " ('declared', 2),\n",
       " ('democratic', 8),\n",
       " ('donations', 8),\n",
       " ('donors', 2),\n",
       " ('enactment', 2),\n",
       " ('energized', 2),\n",
       " ('extend', 2),\n",
       " ('favors', 4),\n",
       " ('feingold', 2),\n",
       " ('finance', 4),\n",
       " ('foes', 2),\n",
       " ('highest', 2),\n",
       " ('individuals', 2),\n",
       " ('known', 2),\n",
       " ('late', 8),\n",
       " ('leader', 2),\n",
       " ('leave', 2),\n",
       " ('like', 4),\n",
       " ('limits', 4),\n",
       " ('loophole', 2),\n",
       " ('lott', 6),\n",
       " ('needs', 2),\n",
       " ('never', 2),\n",
       " ('obstacle', 2),\n",
       " ('old', 8),\n",
       " ('open', 4),\n",
       " ('ought', 2),\n",
       " ('parties', 10),\n",
       " ('political', 10),\n",
       " ('primary', 6),\n",
       " ('priorities', 2),\n",
       " ('real', 2),\n",
       " ('reform', 8),\n",
       " ('reforms', 2),\n",
       " ('scandals', 2),\n",
       " ('senate', 4),\n",
       " ('simply', 2),\n",
       " ('support', 6),\n",
       " ('talk', 4),\n",
       " ('tired', 2),\n",
       " ('trent', 2),\n",
       " ('undermine', 2),\n",
       " ('unfortunately', 2),\n",
       " ('unlimited', 4),\n",
       " ('want', 8),\n",
       " ('watergate', 2),\n",
       " ('wide', 2),\n",
       " ('case', 2),\n",
       " ('declined', 6),\n",
       " ('anticrime', 8),\n",
       " ('backaides', 2),\n",
       " ('broad', 4),\n",
       " ('counsel', 4),\n",
       " ('disputed', 6),\n",
       " ('easily', 2),\n",
       " ('fight', 2),\n",
       " ('help', 16),\n",
       " ('mandatory', 4),\n",
       " ('measures', 6),\n",
       " ('parolees', 8),\n",
       " ('prisoners', 8),\n",
       " ('proposalvice', 2),\n",
       " ('spend', 2),\n",
       " ('testing', 4),\n",
       " ('treat', 4),\n",
       " ('checks', 2),\n",
       " ('heaven', 2),\n",
       " ('house', 2),\n",
       " ('questions', 2),\n",
       " ('seems', 2),\n",
       " ('sent', 2),\n",
       " ('st', 2),\n",
       " ('white', 2),\n",
       " ('woman', 2),\n",
       " ('comment', 4),\n",
       " ('decisive', 2),\n",
       " ('existing', 2),\n",
       " ('play', 6),\n",
       " ('reflected', 2),\n",
       " ('report', 2),\n",
       " ('satisfaction', 2),\n",
       " ('side', 4),\n",
       " ('studying', 2),\n",
       " ('tonight', 2),\n",
       " ('article', 2),\n",
       " ('deny', 4),\n",
       " ('disdained', 2),\n",
       " ('explicitly', 2),\n",
       " ('godly', 2),\n",
       " ('gorelick', 2),\n",
       " ('haredi', 2),\n",
       " ('holocaust', 4),\n",
       " ('israel', 2),\n",
       " ('kept', 2),\n",
       " ('lambs', 2),\n",
       " ('minute', 2),\n",
       " ('moshe', 2),\n",
       " ('official', 2),\n",
       " ('pointedly', 2),\n",
       " ('slaughter', 2),\n",
       " ('souls', 2),\n",
       " ('titled', 2),\n",
       " ('weekly', 2),\n",
       " ('beat', 2),\n",
       " ('best', 2),\n",
       " ('boy', 4),\n",
       " ('brian', 2),\n",
       " ('broke', 2),\n",
       " ('carefully', 2),\n",
       " ('consultant', 2),\n",
       " ('courts', 2),\n",
       " ('crucial', 2),\n",
       " ('cuban', 2),\n",
       " ('deliver', 2),\n",
       " ('florida', 6),\n",
       " ('group', 8),\n",
       " ('guns', 4),\n",
       " ('hard', 4),\n",
       " ('helped', 8),\n",
       " ('kennedy', 2),\n",
       " ('leans', 2),\n",
       " ('remind', 2),\n",
       " ('stake', 2),\n",
       " ('suggest', 4),\n",
       " ('suggested', 2),\n",
       " ('take', 2),\n",
       " ('treading', 2),\n",
       " ('candidate', 2),\n",
       " ('discussed', 2),\n",
       " ('endorsed', 2),\n",
       " ('former', 6),\n",
       " ('including', 2),\n",
       " ('leaders', 2),\n",
       " ('many', 8),\n",
       " ('may', 4),\n",
       " ('october', 4),\n",
       " ('policies', 2),\n",
       " ('something', 2),\n",
       " ('spoke', 2),\n",
       " ('york', 2),\n",
       " ('apt', 2),\n",
       " ('battles', 2),\n",
       " ('bloodiest', 2),\n",
       " ('book', 2),\n",
       " ('bradley', 8),\n",
       " ('brave', 2),\n",
       " ('cruel', 2),\n",
       " ('edmund', 2),\n",
       " ('enemy', 2),\n",
       " ('fathers', 2),\n",
       " ('flags', 2),\n",
       " ('good', 2),\n",
       " ('guys', 2),\n",
       " ('historical', 2),\n",
       " ('ii', 2),\n",
       " ('japanese', 2),\n",
       " ('patriotic', 4),\n",
       " ('reconstruction', 2),\n",
       " ('revisionism', 2),\n",
       " ('ruthless', 2),\n",
       " ('title', 2),\n",
       " ('unspeakably', 2),\n",
       " ('wilson', 2),\n",
       " ('writings', 2),\n",
       " ('actors', 2),\n",
       " ('alerted', 2),\n",
       " ('ballot', 2),\n",
       " ('cast', 2),\n",
       " ('charges', 2),\n",
       " ('david', 2),\n",
       " ('director', 2),\n",
       " ('esbjornson', 2),\n",
       " ('join', 2),\n",
       " ('kelly', 2),\n",
       " ('miller', 2),\n",
       " ('notified', 2),\n",
       " ('onstage', 2),\n",
       " ('rest', 2),\n",
       " ('secret', 4),\n",
       " ('spokeswoman', 4),\n",
       " ('stewart', 8),\n",
       " ('ability', 2),\n",
       " ('already', 2),\n",
       " ('attack', 4),\n",
       " ('attacks', 2),\n",
       " ('behind', 2),\n",
       " ('center', 2),\n",
       " ('controversial', 2),\n",
       " ('debate', 4),\n",
       " ('defending', 2),\n",
       " ('education', 6),\n",
       " ('every', 2),\n",
       " ('fill', 2),\n",
       " ('massachusetts', 2),\n",
       " ('nomination', 4),\n",
       " ('quayle', 2),\n",
       " ('recent', 4),\n",
       " ('think', 6),\n",
       " ('tried', 2),\n",
       " ('offer', 2),\n",
       " ('several', 2),\n",
       " ('turned', 2),\n",
       " ('biggest', 2),\n",
       " ('elizabeth', 2),\n",
       " ('approach', 6),\n",
       " ('believe', 2),\n",
       " ('benefit', 2),\n",
       " ('certainly', 2),\n",
       " ('commit', 2),\n",
       " ('drive', 2),\n",
       " ('generation', 2),\n",
       " ('increase', 4),\n",
       " ('making', 6),\n",
       " ('rising', 2),\n",
       " ('street', 2),\n",
       " ('adopted', 2),\n",
       " ('agreed', 2),\n",
       " ('armstrong', 2),\n",
       " ('band', 4),\n",
       " ('buck', 2),\n",
       " ('bushkin', 2),\n",
       " ('clayton', 2),\n",
       " ('clubs', 2),\n",
       " ('davis', 2),\n",
       " ('embers', 2),\n",
       " ('familiar', 2),\n",
       " ('fazed', 2),\n",
       " ('forceful', 2),\n",
       " ('hands', 2),\n",
       " ('horn', 4),\n",
       " ('jazz', 2),\n",
       " ('jones', 6),\n",
       " ('knew', 2),\n",
       " ('lanin', 2),\n",
       " ('lester', 2),\n",
       " ('louis', 2),\n",
       " ('melodies', 2),\n",
       " ('meyer', 2),\n",
       " ('midcareer', 2),\n",
       " ('mute', 4),\n",
       " ('nd', 2),\n",
       " ('pianist', 2),\n",
       " ('pop', 2),\n",
       " ('predecessor', 2),\n",
       " ('preferred', 2),\n",
       " ('quieter', 2),\n",
       " ('regular', 2),\n",
       " ('restaurant', 2),\n",
       " ('resume', 2),\n",
       " ('resurgence', 2),\n",
       " ('society', 2),\n",
       " ('softly', 2),\n",
       " ('sound', 2),\n",
       " ('staged', 2),\n",
       " ('stints', 2),\n",
       " ('style', 6),\n",
       " ('swinging', 2),\n",
       " ('vein', 2),\n",
       " ('abandon', 2),\n",
       " ('address', 2),\n",
       " ('affection', 2),\n",
       " ('aggressive', 2),\n",
       " ('aide', 4),\n",
       " ('along', 2),\n",
       " ('appeal', 2),\n",
       " ('appear', 2),\n",
       " ('appearance', 2),\n",
       " ('availability', 4),\n",
       " ('background', 2),\n",
       " ('battleground', 2),\n",
       " ('bearer', 2),\n",
       " ('begun', 2),\n",
       " ('bid', 2),\n",
       " ('biography', 2),\n",
       " ('bob', 4),\n",
       " ('brimming', 2),\n",
       " ('california', 2),\n",
       " ('camps', 2),\n",
       " ('candor', 2),\n",
       " ('careful', 2),\n",
       " ('catch', 2),\n",
       " ('chance', 2),\n",
       " ('cheney', 2),\n",
       " ('choice', 2),\n",
       " ('christopher', 6),\n",
       " ('club', 2),\n",
       " ('coelho', 4),\n",
       " ('compassionate', 2),\n",
       " ('compelling', 2),\n",
       " ('conduct', 2),\n",
       " ('contender', 2),\n",
       " ('contenders', 2),\n",
       " ('contention', 2),\n",
       " ('conventions', 2),\n",
       " ('course', 2),\n",
       " ('cove', 2),\n",
       " ('coy', 2),\n",
       " ('dare', 2),\n",
       " ('decision', 2),\n",
       " ('defended', 2),\n",
       " ('desire', 2),\n",
       " ('dick', 2),\n",
       " ('direct', 2),\n",
       " ('directness', 2),\n",
       " ('dispensing', 2),\n",
       " ('dole', 6),\n",
       " ('drawback', 2),\n",
       " ('drove', 2),\n",
       " ('duties', 2),\n",
       " ('ending', 2),\n",
       " ('energy', 2),\n",
       " ('feel', 2),\n",
       " ('find', 2),\n",
       " ('flattering', 2),\n",
       " ('flew', 2),\n",
       " ('fly', 2),\n",
       " ('frantically', 2),\n",
       " ('frequently', 2),\n",
       " ('gets', 2),\n",
       " ('golf', 2),\n",
       " ('hampshire', 2),\n",
       " ('hanover', 2),\n",
       " ('hot', 2),\n",
       " ('humor', 2),\n",
       " ('hunts', 2),\n",
       " ('husband', 2),\n",
       " ('important', 2),\n",
       " ('india', 4),\n",
       " ('informing', 2),\n",
       " ('insisted', 2),\n",
       " ('interview', 2),\n",
       " ('job', 2),\n",
       " ('kerry', 2),\n",
       " ('know', 2),\n",
       " ('lincoln', 2),\n",
       " ('lingering', 2),\n",
       " ('london', 2),\n",
       " ('lot', 4),\n",
       " ('makes', 2),\n",
       " ('mindful', 2),\n",
       " ('mischievous', 2),\n",
       " ('moderate', 2),\n",
       " ('mystery', 2),\n",
       " ('nearly', 2),\n",
       " ('northern', 2),\n",
       " ('noticed', 2),\n",
       " ('nuclear', 2),\n",
       " ('object', 2),\n",
       " ('obvious', 4),\n",
       " ('ocean', 2),\n",
       " ('opportunity', 4),\n",
       " ('overlooking', 2),\n",
       " ('oversee', 2),\n",
       " ('pacific', 2),\n",
       " ('painstaking', 2),\n",
       " ('parking', 2),\n",
       " ('pennsylvania', 2),\n",
       " ('picked', 4),\n",
       " ('picks', 2),\n",
       " ('plays', 2),\n",
       " ('politician', 4),\n",
       " ('politicians', 2),\n",
       " ('practitioners', 2),\n",
       " ('praise', 4),\n",
       " ('preparation', 2),\n",
       " ('pressure', 2),\n",
       " ('pretty', 2),\n",
       " ('process', 2),\n",
       " ('profile', 2),\n",
       " ('proliferation', 2),\n",
       " ('prospects', 2),\n",
       " ('rarely', 2),\n",
       " ('reaction', 2),\n",
       " ('resolve', 2),\n",
       " ('richardson', 4),\n",
       " ('ridge', 12),\n",
       " ('rounds', 2),\n",
       " ('rushed', 2),\n",
       " ('score', 2),\n",
       " ('screening', 2),\n",
       " ('search', 2),\n",
       " ('seeking', 2),\n",
       " ('seizing', 2),\n",
       " ('sense', 2),\n",
       " ('settle', 2),\n",
       " ('short', 2),\n",
       " ('spectacular', 2),\n",
       " ('squeeze', 2),\n",
       " ('staff', 2),\n",
       " ('standard', 2),\n",
       " ('stumped', 2),\n",
       " ('stumping', 2),\n",
       " ('subtle', 2),\n",
       " ('sweepstakes', 2),\n",
       " ('swing', 2),\n",
       " ('thing', 2),\n",
       " ('things', 2),\n",
       " ('though', 2),\n",
       " ('tips', 2),\n",
       " ('tom', 2),\n",
       " ('tony', 2),\n",
       " ('toss', 2),\n",
       " ('traveled', 2),\n",
       " ('trumpets', 2),\n",
       " ('unseemly', 2),\n",
       " ('unsolicited', 2),\n",
       " ('utter', 2),\n",
       " ('versed', 2),\n",
       " ('veteran', 2),\n",
       " ('vietnam', 2),\n",
       " ('visit', 2),\n",
       " ('waiting', 2),\n",
       " ('warren', 2),\n",
       " ('words', 2),\n",
       " ('ada', 2),\n",
       " ('allwood', 2),\n",
       " ('audrey', 2),\n",
       " ('beloved', 2),\n",
       " ('bernard', 2),\n",
       " ('caldwell', 2),\n",
       " ('chapel', 2),\n",
       " ('clifton', 4),\n",
       " ('dear', 2),\n",
       " ('dorothy', 2),\n",
       " ('edwin', 2),\n",
       " ('fleishman', 4),\n",
       " ('gordon', 2),\n",
       " ('grandmother', 2),\n",
       " ('hamada', 6),\n",
       " ('jacobs', 2),\n",
       " ('jewish', 2),\n",
       " ('jill', 2),\n",
       " ('joseph', 2),\n",
       " ('kathy', 2),\n",
       " ('loving', 2),\n",
       " ('matthew', 2),\n",
       " ('memorial', 2),\n",
       " ('mother', 2),\n",
       " ('nee', 2),\n",
       " ('nikelle', 2),\n",
       " ('rd', 2),\n",
       " ('rose', 2),\n",
       " ('roslyn', 2),\n",
       " ('sean', 2),\n",
       " ('sister', 2),\n",
       " ('wendy', 2),\n",
       " ('wenig', 2),\n",
       " ('west', 2),\n",
       " ('wife', 2),\n",
       " ('financing', 4),\n",
       " ('abusers', 2),\n",
       " ('accusation', 2),\n",
       " ('adolescents', 2),\n",
       " ('advocating', 2),\n",
       " ('aid', 2),\n",
       " ('alamo', 2),\n",
       " ('amendment', 4),\n",
       " ('backdrop', 2),\n",
       " ('bartlett', 2),\n",
       " ('bearing', 2),\n",
       " ('become', 2),\n",
       " ('bore', 2),\n",
       " ('building', 2),\n",
       " ('buy', 4),\n",
       " ('cases', 2),\n",
       " ('causes', 2),\n",
       " ('centrist', 2),\n",
       " ('choosing', 2),\n",
       " ('clean', 2),\n",
       " ('coming', 2),\n",
       " ('committed', 2),\n",
       " ('computers', 2),\n",
       " ('constitutional', 2),\n",
       " ('content', 2),\n",
       " ('contentious', 2),\n",
       " ('court', 2),\n",
       " ('crime', 24),\n",
       " ('crimes', 6),\n",
       " ('criminals', 6),\n",
       " ('crowd', 2),\n",
       " ('dan', 2),\n",
       " ('death', 2),\n",
       " ('decade', 2),\n",
       " ('demand', 2),\n",
       " ('door', 2),\n",
       " ('endorsing', 2),\n",
       " ('escape', 2),\n",
       " ('executed', 2),\n",
       " ('expand', 4),\n",
       " ('expecting', 2),\n",
       " ('experienced', 2),\n",
       " ('fallen', 2),\n",
       " ('fighting', 2),\n",
       " ('finger', 2),\n",
       " ('governments', 4),\n",
       " ('grant', 2),\n",
       " ('gusto', 2),\n",
       " ('handguns', 2),\n",
       " ('harsh', 2),\n",
       " ('hire', 4),\n",
       " ('hiring', 2),\n",
       " ('incarcerated', 2),\n",
       " ('inmates', 4),\n",
       " ('involving', 2),\n",
       " ('jail', 2),\n",
       " ('july', 2),\n",
       " ('jumped', 2),\n",
       " ('juveniles', 2),\n",
       " ('keep', 2),\n",
       " ('largest', 4),\n",
       " ('lengthened', 2),\n",
       " ('licenses', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_term_cnts = defaultdict(lambda: [])\n",
    "\n",
    "for index, row in nytimes.iterrows():\n",
    "    date = row[\"Date\"]\n",
    "    content = row[\"Content\"]\n",
    "    \n",
    "    date_term_cnts[date] += content\n",
    "    \n",
    "date_term_cnts = dict(date_term_cnts)\n",
    "date_term_cnts = [id2word.doc2bow(text) for text in date_term_cnts.values()]\n",
    "date_term_cnts = [[(id2word[id], freq) for id, freq in date] for date in date_term_cnts]\n",
    "date_term_cnts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.636790510956109\n",
      "\n",
      "Coherence Score:  0.5518203637253917\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "k = 10\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "#                                            minimum_phi_value=0.5, # min threshold for word probabilities\n",
    "                                           passes=2,\n",
    "                                           alpha='auto',  # assuming that topic distribution is assymetric. Not all topics equally represented in corpus.\n",
    "                                           eta='auto',\n",
    "                                           update_every=1, # online or batch processing (everything is on disk, so use online)\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=articles, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts:\n",
    "\n",
    "We need to de-pluralize the words (governments vs government).\n",
    "Get the coherence score above 50 would be a good start probably.\n",
    "\n",
    "Need to extend stop words to include mr.\n",
    "\n",
    "But topic coherency is still very low\n",
    "\n",
    "Also, we can double check our topic coherence by comparing with Wikipedia (and other checks the paper did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ['mr',\n",
       "   'lieberman',\n",
       "   'military',\n",
       "   'visited',\n",
       "   'gore',\n",
       "   'said',\n",
       "   'clinton',\n",
       "   'misstated',\n",
       "   'bush',\n",
       "   'states',\n",
       "   'president',\n",
       "   'yesterday',\n",
       "   'administration',\n",
       "   'vice',\n",
       "   'defense',\n",
       "   'would',\n",
       "   'texas',\n",
       "   'vidal',\n",
       "   'campaign',\n",
       "   'page',\n",
       "   'united',\n",
       "   'republican',\n",
       "   'sept',\n",
       "   'gov',\n",
       "   'presidential',\n",
       "   'balkans',\n",
       "   'russia',\n",
       "   'abortion',\n",
       "   'gun',\n",
       "   'troops',\n",
       "   'article',\n",
       "   'front',\n",
       "   'environmental',\n",
       "   'national',\n",
       "   'hillary',\n",
       "   'cheney',\n",
       "   'policy',\n",
       "   'missile',\n",
       "   'rights',\n",
       "   'math',\n",
       "   'support',\n",
       "   'al',\n",
       "   'entertainment',\n",
       "   'senate',\n",
       "   'democrats',\n",
       "   'chernomyrdin',\n",
       "   'law',\n",
       "   'state',\n",
       "   'fuzzy',\n",
       "   'governor',\n",
       "   'george',\n",
       "   'foreign',\n",
       "   'franks',\n",
       "   'republicans',\n",
       "   'american',\n",
       "   'candidates',\n",
       "   'roe',\n",
       "   'senator',\n",
       "   'new',\n",
       "   'style',\n",
       "   'weapons',\n",
       "   'nominee',\n",
       "   'first',\n",
       "   'world',\n",
       "   'food',\n",
       "   'system',\n",
       "   'standards',\n",
       "   'convention',\n",
       "   'ones',\n",
       "   'error',\n",
       "   'running',\n",
       "   'california',\n",
       "   'issue',\n",
       "   'today',\n",
       "   'moderator',\n",
       "   'rodham',\n",
       "   'also',\n",
       "   'war',\n",
       "   'former',\n",
       "   'arms',\n",
       "   'one',\n",
       "   'kiss',\n",
       "   'intelligence',\n",
       "   'two',\n",
       "   'earth',\n",
       "   'congress',\n",
       "   'record',\n",
       "   'us',\n",
       "   'security',\n",
       "   'crime',\n",
       "   'russian',\n",
       "   'percent',\n",
       "   'decision',\n",
       "   'obvious',\n",
       "   'leads',\n",
       "   'might',\n",
       "   'nader',\n",
       "   'referred',\n",
       "   'party',\n",
       "   'nuclear']),\n",
       " (1,\n",
       "  ['nato',\n",
       "   'bosses',\n",
       "   'bosnia',\n",
       "   'resent',\n",
       "   'lindsey',\n",
       "   'somalia',\n",
       "   'weakening',\n",
       "   'haiti',\n",
       "   'caption',\n",
       "   'upstate',\n",
       "   'pillow',\n",
       "   'theaters',\n",
       "   'russell',\n",
       "   'curriculum',\n",
       "   'schwarzkopf',\n",
       "   'europeans',\n",
       "   'milosevic',\n",
       "   'musicals',\n",
       "   'lawrence',\n",
       "   'commanded',\n",
       "   'las',\n",
       "   'vegas',\n",
       "   'marital',\n",
       "   'veered',\n",
       "   'maneuver',\n",
       "   'dividend',\n",
       "   'privileges',\n",
       "   'photography',\n",
       "   'nostalgic',\n",
       "   'cheek',\n",
       "   'cheerleading',\n",
       "   'mr',\n",
       "   'persuaded',\n",
       "   'refuse',\n",
       "   'duties',\n",
       "   'monument',\n",
       "   'huffington',\n",
       "   'enhance',\n",
       "   'productivity',\n",
       "   'films',\n",
       "   'dread',\n",
       "   'clark',\n",
       "   'marvin',\n",
       "   'road',\n",
       "   'norman',\n",
       "   'transformed',\n",
       "   'schiff',\n",
       "   'englewood',\n",
       "   'ad',\n",
       "   'discourse',\n",
       "   'lautenberg',\n",
       "   'cultures',\n",
       "   'street',\n",
       "   'ordered',\n",
       "   'roberts',\n",
       "   'misstated',\n",
       "   'safest',\n",
       "   'harding',\n",
       "   'tatum',\n",
       "   'debates',\n",
       "   'ethnic',\n",
       "   'admissions',\n",
       "   'tourist',\n",
       "   'column',\n",
       "   'brunt',\n",
       "   'lucy',\n",
       "   'morale',\n",
       "   'engagement',\n",
       "   'faulted',\n",
       "   'tout',\n",
       "   'bought',\n",
       "   'serbia',\n",
       "   'berger',\n",
       "   'clinton',\n",
       "   'tongue',\n",
       "   'said',\n",
       "   'snuff',\n",
       "   'gore',\n",
       "   'goodman',\n",
       "   'bush',\n",
       "   'currency',\n",
       "   'writes',\n",
       "   'chernobyl',\n",
       "   'faith',\n",
       "   'afflicting',\n",
       "   'explosive',\n",
       "   'surfaced',\n",
       "   'gorevic',\n",
       "   'arborealis',\n",
       "   'cali',\n",
       "   'troops',\n",
       "   'hale',\n",
       "   'advising',\n",
       "   'cherny',\n",
       "   'gender',\n",
       "   'simmons',\n",
       "   'equity',\n",
       "   'unafraid',\n",
       "   'sample',\n",
       "   'london']),\n",
       " (2,\n",
       "  ['glamorous',\n",
       "   'gorey',\n",
       "   'milosevic',\n",
       "   'atlantic',\n",
       "   'madison',\n",
       "   'bushnell',\n",
       "   'anthony',\n",
       "   'embarrass',\n",
       "   'lewis',\n",
       "   'playboy',\n",
       "   'rogers',\n",
       "   'hypothetical',\n",
       "   'bushehr',\n",
       "   'steel',\n",
       "   'concerts',\n",
       "   'conscience',\n",
       "   'clemens',\n",
       "   'op',\n",
       "   'philip',\n",
       "   'users',\n",
       "   'serbia',\n",
       "   'triumphs',\n",
       "   'innings',\n",
       "   'hefner',\n",
       "   'fantasy',\n",
       "   'homer',\n",
       "   'ed',\n",
       "   'contract',\n",
       "   'wells',\n",
       "   'replacing',\n",
       "   'london',\n",
       "   'georgewbush',\n",
       "   'tort',\n",
       "   'edward',\n",
       "   'tag',\n",
       "   'nassau',\n",
       "   'japan',\n",
       "   'leak',\n",
       "   'imports',\n",
       "   'intervention',\n",
       "   'isolationist',\n",
       "   'logo',\n",
       "   'mr',\n",
       "   'piercing',\n",
       "   'baron',\n",
       "   'mode',\n",
       "   'ages',\n",
       "   'art',\n",
       "   'labels',\n",
       "   'uncertainty',\n",
       "   'glass',\n",
       "   'unsustainable',\n",
       "   'jury',\n",
       "   'hurting',\n",
       "   'forged',\n",
       "   'prosecutor',\n",
       "   'iranian',\n",
       "   'morris',\n",
       "   'embarrassing',\n",
       "   'nuclear',\n",
       "   'parking',\n",
       "   'wine',\n",
       "   'toronto',\n",
       "   'arnold',\n",
       "   'methodist',\n",
       "   'dell',\n",
       "   'weakening',\n",
       "   'yankees',\n",
       "   'intrigued',\n",
       "   'prints',\n",
       "   'bomb',\n",
       "   'pure',\n",
       "   'activities',\n",
       "   'pushing',\n",
       "   'soared',\n",
       "   'avenue',\n",
       "   'muted',\n",
       "   'zoo',\n",
       "   'publicized',\n",
       "   'clinton',\n",
       "   'slap',\n",
       "   'anachronism',\n",
       "   'slots',\n",
       "   'unfortunate',\n",
       "   'erased',\n",
       "   'eleanor',\n",
       "   'abm',\n",
       "   'honda',\n",
       "   'visiting',\n",
       "   'ministers',\n",
       "   'loretta',\n",
       "   'convention',\n",
       "   'june',\n",
       "   'graeme',\n",
       "   'noble',\n",
       "   'fowler',\n",
       "   'memoir',\n",
       "   'gore',\n",
       "   'said',\n",
       "   'democratic']),\n",
       " (3,\n",
       "  ['string',\n",
       "   'voucher',\n",
       "   'refuge',\n",
       "   'arctic',\n",
       "   'kyoto',\n",
       "   'kelly',\n",
       "   'indian',\n",
       "   'indians',\n",
       "   'glover',\n",
       "   'diary',\n",
       "   'taxpayer',\n",
       "   'weiss',\n",
       "   'lockhart',\n",
       "   'greenstein',\n",
       "   'berkeley',\n",
       "   'agrees',\n",
       "   'andrea',\n",
       "   'birch',\n",
       "   'downey',\n",
       "   'springs',\n",
       "   'repairs',\n",
       "   'mr',\n",
       "   'rosa',\n",
       "   'legs',\n",
       "   'freeh',\n",
       "   'green',\n",
       "   'sensed',\n",
       "   'drawbacks',\n",
       "   'onstage',\n",
       "   'portable',\n",
       "   'tribal',\n",
       "   'gore',\n",
       "   'nader',\n",
       "   'lane',\n",
       "   'alice',\n",
       "   'iron',\n",
       "   'futures',\n",
       "   'tenants',\n",
       "   'sinks',\n",
       "   'toilets',\n",
       "   'overflowing',\n",
       "   'katz',\n",
       "   'bush',\n",
       "   'standards',\n",
       "   'formalizes',\n",
       "   'klinkenborg',\n",
       "   'verlyn',\n",
       "   'lashes',\n",
       "   'vidal',\n",
       "   'skull',\n",
       "   'irrelevant',\n",
       "   'tobacco',\n",
       "   'retreats',\n",
       "   'fosters',\n",
       "   'said',\n",
       "   'party',\n",
       "   'counterparts',\n",
       "   'damp',\n",
       "   'students',\n",
       "   'editorials',\n",
       "   'subheadline',\n",
       "   'presidencies',\n",
       "   'fist',\n",
       "   'petroleum',\n",
       "   'tribes',\n",
       "   'bushgov',\n",
       "   'eighth',\n",
       "   'goreformer',\n",
       "   'perpetuate',\n",
       "   'patriotic',\n",
       "   'ralph',\n",
       "   'news',\n",
       "   'president',\n",
       "   'watched',\n",
       "   'clinton',\n",
       "   'reform',\n",
       "   'gracious',\n",
       "   'govern',\n",
       "   'structure',\n",
       "   'gorethe',\n",
       "   'speech',\n",
       "   'would',\n",
       "   'kuhn',\n",
       "   'intellectualism',\n",
       "   'edmund',\n",
       "   'thrilled',\n",
       "   'buchanan',\n",
       "   'portions',\n",
       "   'pine',\n",
       "   'loftily',\n",
       "   'overhauling',\n",
       "   'stiffly',\n",
       "   'flake',\n",
       "   'july',\n",
       "   'agreements',\n",
       "   'school',\n",
       "   'nomination',\n",
       "   'book',\n",
       "   'revolutions',\n",
       "   'age']),\n",
       " (4,\n",
       "  ['cuba',\n",
       "   'castro',\n",
       "   'bethany',\n",
       "   'ore',\n",
       "   'revival',\n",
       "   'dee',\n",
       "   'herbert',\n",
       "   'greens',\n",
       "   'monument',\n",
       "   'influencing',\n",
       "   'damaging',\n",
       "   'sack',\n",
       "   'taiwan',\n",
       "   'overturning',\n",
       "   'sanctions',\n",
       "   'mr',\n",
       "   'pork',\n",
       "   'plaintiffs',\n",
       "   'neck',\n",
       "   'transferred',\n",
       "   'rican',\n",
       "   'legally',\n",
       "   'gorelick',\n",
       "   'puerto',\n",
       "   'determining',\n",
       "   'caliber',\n",
       "   'elementary',\n",
       "   'pirates',\n",
       "   'european',\n",
       "   'vidal',\n",
       "   'violating',\n",
       "   'creek',\n",
       "   'dearth',\n",
       "   'nader',\n",
       "   'appellate',\n",
       "   'damages',\n",
       "   'standardized',\n",
       "   'truman',\n",
       "   'override',\n",
       "   'kenny',\n",
       "   'editorials',\n",
       "   'oversight',\n",
       "   'hagelin',\n",
       "   'defying',\n",
       "   'forbidding',\n",
       "   'cream',\n",
       "   'beaver',\n",
       "   'party',\n",
       "   'appointment',\n",
       "   'kiss',\n",
       "   'clinton',\n",
       "   'martha',\n",
       "   'gonzales',\n",
       "   'gore',\n",
       "   'vote',\n",
       "   'accountability',\n",
       "   'backer',\n",
       "   'said',\n",
       "   'assent',\n",
       "   'hoffa',\n",
       "   'mentally',\n",
       "   'teamsters',\n",
       "   'percent',\n",
       "   'state',\n",
       "   'postconvention',\n",
       "   'immigration',\n",
       "   'bush',\n",
       "   'madison',\n",
       "   'convention',\n",
       "   'appointees',\n",
       "   'dignitaries',\n",
       "   'president',\n",
       "   'kahn',\n",
       "   'roe',\n",
       "   'violated',\n",
       "   'publishers',\n",
       "   'torricelli',\n",
       "   'wade',\n",
       "   'elect',\n",
       "   'repertory',\n",
       "   'would',\n",
       "   'republican',\n",
       "   'cartagena',\n",
       "   'ronnie',\n",
       "   'watergate',\n",
       "   'trumanesque',\n",
       "   'route',\n",
       "   'essex',\n",
       "   'codey',\n",
       "   'court',\n",
       "   'lame',\n",
       "   'profitably',\n",
       "   'youth',\n",
       "   'fracture',\n",
       "   'improbable',\n",
       "   'turnpike',\n",
       "   'new',\n",
       "   'ballet',\n",
       "   'giblin',\n",
       "   'campaign']),\n",
       " (5,\n",
       "  ['peacekeeping',\n",
       "   'ridgewood',\n",
       "   'sheriff',\n",
       "   'leone',\n",
       "   'biting',\n",
       "   'minimize',\n",
       "   'taylor',\n",
       "   'holbrooke',\n",
       "   'criner',\n",
       "   'henryk',\n",
       "   'gorecki',\n",
       "   'albright',\n",
       "   'archer',\n",
       "   'waging',\n",
       "   'sits',\n",
       "   'temptation',\n",
       "   'cutbacks',\n",
       "   'contract',\n",
       "   'harlem',\n",
       "   'polish',\n",
       "   'madeleine',\n",
       "   'absurd',\n",
       "   'newport',\n",
       "   'amato',\n",
       "   'bridegroom',\n",
       "   'reinvigorated',\n",
       "   'rice',\n",
       "   'suzanne',\n",
       "   'melrose',\n",
       "   'sierra',\n",
       "   'alliance',\n",
       "   'safire',\n",
       "   'clinical',\n",
       "   'goren',\n",
       "   'lebowitz',\n",
       "   'european',\n",
       "   'sleeping',\n",
       "   'dictator',\n",
       "   'fran',\n",
       "   'enrollment',\n",
       "   'freeze',\n",
       "   'mr',\n",
       "   'freed',\n",
       "   'captan',\n",
       "   'division',\n",
       "   'condoleeza',\n",
       "   'accelerate',\n",
       "   'blocking',\n",
       "   'riot',\n",
       "   'pardons',\n",
       "   'pm',\n",
       "   'singers',\n",
       "   'linda',\n",
       "   'spiritual',\n",
       "   'pataki',\n",
       "   'said',\n",
       "   'wit',\n",
       "   'banking',\n",
       "   'gregg',\n",
       "   'roukema',\n",
       "   'bergen',\n",
       "   'exchanged',\n",
       "   'ed',\n",
       "   'boggs',\n",
       "   'gregory',\n",
       "   'policy',\n",
       "   'circulated',\n",
       "   'pardon',\n",
       "   'mumble',\n",
       "   'vanquishers',\n",
       "   'winners',\n",
       "   'ginsberg',\n",
       "   'mayor',\n",
       "   'outdone',\n",
       "   'strongly',\n",
       "   'texas',\n",
       "   'fox',\n",
       "   'humiliated',\n",
       "   'chieftains',\n",
       "   'jessica',\n",
       "   'supplies',\n",
       "   'peace',\n",
       "   'norcross',\n",
       "   'murderer',\n",
       "   'giuliani',\n",
       "   'pipe',\n",
       "   'token',\n",
       "   'valuable',\n",
       "   'affected',\n",
       "   'bruins',\n",
       "   'rw',\n",
       "   'conferences',\n",
       "   'beauty',\n",
       "   'mandela',\n",
       "   'beach',\n",
       "   'sutton',\n",
       "   'retiree',\n",
       "   'epidemics',\n",
       "   'gore',\n",
       "   'invariable']),\n",
       " (6,\n",
       "  ['var',\n",
       "   'string',\n",
       "   'else',\n",
       "   'pat',\n",
       "   'buchanan',\n",
       "   'ralph',\n",
       "   'nader',\n",
       "   'gore',\n",
       "   'cbs',\n",
       "   'bush',\n",
       "   'party',\n",
       "   'intervention',\n",
       "   'debater',\n",
       "   'held',\n",
       "   'democrat',\n",
       "   'reform',\n",
       "   'green',\n",
       "   'poll',\n",
       "   'neck',\n",
       "   'candidates',\n",
       "   'vote',\n",
       "   'baseball',\n",
       "   'times',\n",
       "   'york',\n",
       "   'eisenhower',\n",
       "   'news',\n",
       "   'candidate',\n",
       "   'milwaukee',\n",
       "   'election',\n",
       "   'carbon',\n",
       "   'religion',\n",
       "   'today',\n",
       "   'editing',\n",
       "   'pundits',\n",
       "   'petroleum',\n",
       "   'new',\n",
       "   'accountability',\n",
       "   'arafat',\n",
       "   'republican',\n",
       "   'would',\n",
       "   'misleading',\n",
       "   'alliance',\n",
       "   'debates',\n",
       "   'portland',\n",
       "   'conferences',\n",
       "   'tapping',\n",
       "   'mr',\n",
       "   'al',\n",
       "   'profit',\n",
       "   'arrogant',\n",
       "   'microphone',\n",
       "   'singer',\n",
       "   'projections',\n",
       "   'gentlemen',\n",
       "   'sorry',\n",
       "   'dwight',\n",
       "   'mideast',\n",
       "   'profoundly',\n",
       "   'stewart',\n",
       "   'performances',\n",
       "   'george',\n",
       "   'shirt',\n",
       "   'fired',\n",
       "   'pronounce',\n",
       "   'affected',\n",
       "   'humble',\n",
       "   'girls',\n",
       "   'claiming',\n",
       "   'literary',\n",
       "   'programming',\n",
       "   'tap',\n",
       "   'kill',\n",
       "   'rowland',\n",
       "   'unaware',\n",
       "   'smirk',\n",
       "   'lying',\n",
       "   'el',\n",
       "   'barbara',\n",
       "   'krugman',\n",
       "   'buoyed',\n",
       "   'franklin',\n",
       "   'schiff',\n",
       "   'diplomacy',\n",
       "   'manage',\n",
       "   'nixon',\n",
       "   'unfortunate',\n",
       "   'jonathan',\n",
       "   'tensions',\n",
       "   'distancing',\n",
       "   'calm',\n",
       "   'assumes',\n",
       "   'charging',\n",
       "   'wilderness',\n",
       "   'messy',\n",
       "   'mccollum',\n",
       "   'thoughtful',\n",
       "   'truman',\n",
       "   'honesty',\n",
       "   'regis',\n",
       "   'visited']),\n",
       " (7,\n",
       "  ['heating',\n",
       "   'entertainment',\n",
       "   'leno',\n",
       "   'wilensky',\n",
       "   'ploy',\n",
       "   'tame',\n",
       "   'lieberman',\n",
       "   'supplies',\n",
       "   'ordered',\n",
       "   'secondary',\n",
       "   'gorelick',\n",
       "   'manchester',\n",
       "   'diner',\n",
       "   'reserve',\n",
       "   'india',\n",
       "   'squad',\n",
       "   'marketing',\n",
       "   'collection',\n",
       "   'calculated',\n",
       "   'material',\n",
       "   'oil',\n",
       "   'roles',\n",
       "   'windfall',\n",
       "   'regulatory',\n",
       "   'homosexuals',\n",
       "   'stone',\n",
       "   'scamp',\n",
       "   'lawton',\n",
       "   'worldwide',\n",
       "   'front',\n",
       "   'dancers',\n",
       "   'page',\n",
       "   'owns',\n",
       "   'aug',\n",
       "   'greene',\n",
       "   'rightly',\n",
       "   'ten',\n",
       "   'ramifications',\n",
       "   'indirectly',\n",
       "   'clothing',\n",
       "   'mr',\n",
       "   'generals',\n",
       "   'positives',\n",
       "   'winter',\n",
       "   'daniel',\n",
       "   'peek',\n",
       "   'titles',\n",
       "   'joseph',\n",
       "   'industry',\n",
       "   'inn',\n",
       "   'reno',\n",
       "   'petition',\n",
       "   'users',\n",
       "   'propose',\n",
       "   'urges',\n",
       "   'bulk',\n",
       "   'gore',\n",
       "   'prosecutor',\n",
       "   'metal',\n",
       "   'widened',\n",
       "   'promotional',\n",
       "   'searching',\n",
       "   'laundry',\n",
       "   'deploy',\n",
       "   'inner',\n",
       "   'deepest',\n",
       "   'department',\n",
       "   'jews',\n",
       "   'shalom',\n",
       "   'pakistan',\n",
       "   'said',\n",
       "   'lawrence',\n",
       "   'tolerance',\n",
       "   'liberalism',\n",
       "   'pershing',\n",
       "   'yalie',\n",
       "   'sheet',\n",
       "   'raiservice',\n",
       "   'demonstrators',\n",
       "   'investigate',\n",
       "   'centerpiece',\n",
       "   'delayed',\n",
       "   'investigator',\n",
       "   'readers',\n",
       "   'embassies',\n",
       "   'freeh',\n",
       "   'wyden',\n",
       "   'mischief',\n",
       "   'president',\n",
       "   'hollywood',\n",
       "   'strengthened',\n",
       "   'diplomacy',\n",
       "   'primarily',\n",
       "   'cold',\n",
       "   'owens',\n",
       "   'yale',\n",
       "   'sperling',\n",
       "   'vice',\n",
       "   'incompetent',\n",
       "   'misconduct']),\n",
       " (8,\n",
       "  ['mr',\n",
       "   'gore',\n",
       "   'said',\n",
       "   'debate',\n",
       "   'bush',\n",
       "   'campaign',\n",
       "   'would',\n",
       "   'tax',\n",
       "   'clinton',\n",
       "   'percent',\n",
       "   'president',\n",
       "   'lieberman',\n",
       "   'nader',\n",
       "   'plan',\n",
       "   'oil',\n",
       "   'vice',\n",
       "   'cheney',\n",
       "   'one',\n",
       "   'people',\n",
       "   'voters',\n",
       "   'governor',\n",
       "   'state',\n",
       "   'debates',\n",
       "   'new',\n",
       "   'party',\n",
       "   'texas',\n",
       "   'presidential',\n",
       "   'republican',\n",
       "   'today',\n",
       "   'democratic',\n",
       "   'like',\n",
       "   'health',\n",
       "   'al',\n",
       "   'security',\n",
       "   'government',\n",
       "   'drug',\n",
       "   'social',\n",
       "   'last',\n",
       "   'vote',\n",
       "   'gov',\n",
       "   'democrats',\n",
       "   'time',\n",
       "   'two',\n",
       "   'states',\n",
       "   'years',\n",
       "   'also',\n",
       "   'money',\n",
       "   'election',\n",
       "   'first',\n",
       "   'american',\n",
       "   'could',\n",
       "   'political',\n",
       "   'medicare',\n",
       "   'year',\n",
       "   'republicans',\n",
       "   'week',\n",
       "   'say',\n",
       "   'senator',\n",
       "   'house',\n",
       "   'national',\n",
       "   'million',\n",
       "   'think',\n",
       "   'many',\n",
       "   'cut',\n",
       "   'even',\n",
       "   'george',\n",
       "   'candidate',\n",
       "   'convention',\n",
       "   'candidates',\n",
       "   'day',\n",
       "   'made',\n",
       "   'administration',\n",
       "   'running',\n",
       "   'issues',\n",
       "   'much',\n",
       "   'florida',\n",
       "   'policy',\n",
       "   'oct',\n",
       "   'support',\n",
       "   'york',\n",
       "   'federal',\n",
       "   'speech',\n",
       "   'race',\n",
       "   'care',\n",
       "   'night',\n",
       "   'get',\n",
       "   'education',\n",
       "   'way',\n",
       "   'big',\n",
       "   'washington',\n",
       "   'polls',\n",
       "   'make',\n",
       "   'aides',\n",
       "   'poll',\n",
       "   'may',\n",
       "   'lazio',\n",
       "   'page',\n",
       "   'proposal',\n",
       "   'bill',\n",
       "   'man']),\n",
       " (9,\n",
       "  ['bushnell',\n",
       "   'blondes',\n",
       "   'candace',\n",
       "   'monthly',\n",
       "   'sex',\n",
       "   'crude',\n",
       "   'author',\n",
       "   'manhattan',\n",
       "   'surname',\n",
       "   'collins',\n",
       "   'love',\n",
       "   'lives',\n",
       "   'injected',\n",
       "   'city',\n",
       "   'women',\n",
       "   'haass',\n",
       "   'seen',\n",
       "   'scholar',\n",
       "   'four',\n",
       "   'goldsmith',\n",
       "   'emissions',\n",
       "   'cookies',\n",
       "   'digit',\n",
       "   'indianapolis',\n",
       "   'recipes',\n",
       "   'bureaucrats',\n",
       "   'liaison',\n",
       "   'brookings',\n",
       "   'spur',\n",
       "   'hartford',\n",
       "   'petroleum',\n",
       "   'pure',\n",
       "   'hudson',\n",
       "   'envisions',\n",
       "   'chocolate',\n",
       "   'exporting',\n",
       "   'bites',\n",
       "   'barbour',\n",
       "   'canadian',\n",
       "   'digital',\n",
       "   'hbo',\n",
       "   'deserving',\n",
       "   'raines',\n",
       "   'gail',\n",
       "   'decrease',\n",
       "   'boring',\n",
       "   'village',\n",
       "   'columns',\n",
       "   'pollutants',\n",
       "   'motive',\n",
       "   'suffer',\n",
       "   'howell',\n",
       "   'computers',\n",
       "   'bart',\n",
       "   'government',\n",
       "   'tutorial',\n",
       "   'plants',\n",
       "   'ian',\n",
       "   'institution',\n",
       "   'heats',\n",
       "   'thyroid',\n",
       "   'ballots',\n",
       "   'costumes',\n",
       "   'gentle',\n",
       "   'mr',\n",
       "   'loop',\n",
       "   'savvy',\n",
       "   'prose',\n",
       "   'schiff',\n",
       "   'applaud',\n",
       "   'evaluate',\n",
       "   'karenna',\n",
       "   'forthcoming',\n",
       "   'canada',\n",
       "   'backlog',\n",
       "   'gore',\n",
       "   'scholarships',\n",
       "   'gerson',\n",
       "   'yeats',\n",
       "   'bland',\n",
       "   'plan',\n",
       "   'haley',\n",
       "   'arthur',\n",
       "   'output',\n",
       "   'relax',\n",
       "   'chretien',\n",
       "   'star',\n",
       "   'teenage',\n",
       "   'advice',\n",
       "   'convention',\n",
       "   'philosopher',\n",
       "   'karmack',\n",
       "   'farbrother',\n",
       "   'jesus',\n",
       "   'irish',\n",
       "   'tax',\n",
       "   'million',\n",
       "   'ginger',\n",
       "   'smoking',\n",
       "   'oil'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "def get_topics(lda_model, num_topics=-1, num_words=100, prob_thresh=0.8):\n",
    "    topics = []\n",
    "    for topic, topic_words in lda_model.print_topics(num_topics=num_topics, num_words=num_words):\n",
    "        words = topic_words.split(\" + \")\n",
    "        all_words = []\n",
    "        all_prob = 0\n",
    "        for elem in words:\n",
    "            prob, word = elem.split(\"*\")\n",
    "            all_prob += float(prob)\n",
    "            all_words.append(word.split('\"')[1])\n",
    "\n",
    "            if all_prob >= prob_thresh:\n",
    "                break\n",
    "        topics.append((topic, all_words))\n",
    "\n",
    "    return topics\n",
    "topics = get_topics(lda_model)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003*\"mr\" + 0.002*\"lieberman\" + 0.002*\"military\" + 0.002*\"visited\" + 0.002*\"gore\" + 0.001*\"said\" + 0.001*\"clinton\" + 0.001*\"misstated\" + 0.001*\"bush\" + 0.001*\"states\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002*\"nato\" + 0.002*\"bosses\" + 0.002*\"bosnia\" + 0.001*\"resent\" + 0.001*\"lindsey\" + 0.001*\"somalia\" + 0.001*\"weakening\" + 0.001*\"haiti\" + 0.001*\"caption\" + 0.001*\"upstate\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002*\"glamorous\" + 0.002*\"gorey\" + 0.002*\"milosevic\" + 0.002*\"atlantic\" + 0.001*\"madison\" + 0.001*\"bushnell\" + 0.001*\"anthony\" + 0.001*\"embarrass\" + 0.001*\"lewis\" + 0.001*\"playboy\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003*\"string\" + 0.002*\"voucher\" + 0.001*\"refuge\" + 0.001*\"arctic\" + 0.001*\"kyoto\" + 0.001*\"kelly\" + 0.000*\"indian\" + 0.000*\"indians\" + 0.000*\"glover\" + 0.000*\"diary\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001*\"cuba\" + 0.001*\"castro\" + 0.001*\"bethany\" + 0.001*\"ore\" + 0.001*\"revival\" + 0.001*\"dee\" + 0.001*\"herbert\" + 0.001*\"greens\" + 0.000*\"monument\" + 0.000*\"influencing\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002*\"peacekeeping\" + 0.001*\"ridgewood\" + 0.001*\"sheriff\" + 0.001*\"leone\" + 0.001*\"biting\" + 0.001*\"minimize\" + 0.001*\"taylor\" + 0.000*\"holbrooke\" + 0.000*\"criner\" + 0.000*\"henryk\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.018*\"var\" + 0.016*\"string\" + 0.012*\"else\" + 0.004*\"pat\" + 0.003*\"buchanan\" + 0.003*\"ralph\" + 0.003*\"nader\" + 0.002*\"gore\" + 0.002*\"cbs\" + 0.002*\"bush\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.003*\"heating\" + 0.001*\"entertainment\" + 0.001*\"leno\" + 0.001*\"wilensky\" + 0.001*\"ploy\" + 0.001*\"tame\" + 0.001*\"lieberman\" + 0.001*\"supplies\" + 0.001*\"ordered\" + 0.001*\"secondary\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006*\"mr\" + 0.003*\"gore\" + 0.003*\"said\" + 0.003*\"debate\" + 0.003*\"bush\" + 0.002*\"campaign\" + 0.002*\"would\" + 0.002*\"tax\" + 0.002*\"clinton\" + 0.002*\"percent\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.003*\"bushnell\" + 0.002*\"blondes\" + 0.002*\"candace\" + 0.002*\"monthly\" + 0.002*\"sex\" + 0.002*\"crude\" + 0.002*\"author\" + 0.001*\"manhattan\" + 0.001*\"surname\" + 0.001*\"collins\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  0   \n",
       "1  1   \n",
       "2  2   \n",
       "3  3   \n",
       "4  4   \n",
       "5  5   \n",
       "6  6   \n",
       "7  7   \n",
       "8  8   \n",
       "9  9   \n",
       "\n",
       "                                                                                                                                                                                       1  \n",
       "0                0.003*\"mr\" + 0.002*\"lieberman\" + 0.002*\"military\" + 0.002*\"visited\" + 0.002*\"gore\" + 0.001*\"said\" + 0.001*\"clinton\" + 0.001*\"misstated\" + 0.001*\"bush\" + 0.001*\"states\"  \n",
       "1            0.002*\"nato\" + 0.002*\"bosses\" + 0.002*\"bosnia\" + 0.001*\"resent\" + 0.001*\"lindsey\" + 0.001*\"somalia\" + 0.001*\"weakening\" + 0.001*\"haiti\" + 0.001*\"caption\" + 0.001*\"upstate\"  \n",
       "2  0.002*\"glamorous\" + 0.002*\"gorey\" + 0.002*\"milosevic\" + 0.002*\"atlantic\" + 0.001*\"madison\" + 0.001*\"bushnell\" + 0.001*\"anthony\" + 0.001*\"embarrass\" + 0.001*\"lewis\" + 0.001*\"playboy\"  \n",
       "3                 0.003*\"string\" + 0.002*\"voucher\" + 0.001*\"refuge\" + 0.001*\"arctic\" + 0.001*\"kyoto\" + 0.001*\"kelly\" + 0.000*\"indian\" + 0.000*\"indians\" + 0.000*\"glover\" + 0.000*\"diary\"  \n",
       "4              0.001*\"cuba\" + 0.001*\"castro\" + 0.001*\"bethany\" + 0.001*\"ore\" + 0.001*\"revival\" + 0.001*\"dee\" + 0.001*\"herbert\" + 0.001*\"greens\" + 0.000*\"monument\" + 0.000*\"influencing\"  \n",
       "5  0.002*\"peacekeeping\" + 0.001*\"ridgewood\" + 0.001*\"sheriff\" + 0.001*\"leone\" + 0.001*\"biting\" + 0.001*\"minimize\" + 0.001*\"taylor\" + 0.000*\"holbrooke\" + 0.000*\"criner\" + 0.000*\"henryk\"  \n",
       "6                               0.018*\"var\" + 0.016*\"string\" + 0.012*\"else\" + 0.004*\"pat\" + 0.003*\"buchanan\" + 0.003*\"ralph\" + 0.003*\"nader\" + 0.002*\"gore\" + 0.002*\"cbs\" + 0.002*\"bush\"  \n",
       "7   0.003*\"heating\" + 0.001*\"entertainment\" + 0.001*\"leno\" + 0.001*\"wilensky\" + 0.001*\"ploy\" + 0.001*\"tame\" + 0.001*\"lieberman\" + 0.001*\"supplies\" + 0.001*\"ordered\" + 0.001*\"secondary\"  \n",
       "8                          0.006*\"mr\" + 0.003*\"gore\" + 0.003*\"said\" + 0.003*\"debate\" + 0.003*\"bush\" + 0.002*\"campaign\" + 0.002*\"would\" + 0.002*\"tax\" + 0.002*\"clinton\" + 0.002*\"percent\"  \n",
       "9          0.003*\"bushnell\" + 0.002*\"blondes\" + 0.002*\"candace\" + 0.002*\"monthly\" + 0.002*\"sex\" + 0.002*\"crude\" + 0.002*\"author\" + 0.001*\"manhattan\" + 0.001*\"surname\" + 0.001*\"collins\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "display(pd.DataFrame(lda_model.print_topics()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.04045957), (8, 0.9339579)]\n",
      "[(0, 0.3243524), (8, 0.6666913)]\n",
      "[(0, 0.30909115), (8, 0.6894434)]\n",
      "[(0, 0.04109392), (6, 0.026417011), (8, 0.93162614)]\n",
      "[(0, 0.2568817), (8, 0.74014485)]\n",
      "[(2, 0.036716957), (8, 0.95034015)]\n",
      "[(0, 0.18049702), (7, 0.011881296), (8, 0.80311793)]\n",
      "[(0, 0.08385625), (1, 0.0243626), (5, 0.019589037), (8, 0.86802256)]\n",
      "[(0, 0.06893439), (6, 0.032124456), (8, 0.89596695)]\n",
      "[(0, 0.13616636), (8, 0.84633857)]\n"
     ]
    }
   ],
   "source": [
    "document_topics = lda_model.get_document_topics(corpus)\n",
    "date_doc_topics = list(zip(nytimes[\"Date\"], lda_model.get_document_topics(corpus)))\n",
    "for l in document_topics[:10]:\n",
    "    print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for any given day, you look at all the diff topics and identify the prob of that topic\n",
    "# should I normalize? Paper doesn't seem to normalize...\n",
    "date_topic_prob = np.zeros((len(unique_dates), k))\n",
    "for date, article in date_doc_topics:\n",
    "    i = unique_dates.index(date)\n",
    "    for topic, prob in article:\n",
    "        date_topic_prob[i][topic] += prob \n",
    "\n",
    "# Figure out how to normalize [reread paper/rewatch lecture]\n",
    "# date_topic_prob = date_topic_prob/date_topic_prob.max(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>1.621332</td>\n",
       "      <td>0.102854</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.079944</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>9.911343</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>2000-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.808829</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.951341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>3.981537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.660461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.318624</td>\n",
       "      <td>25.241359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>3.127851</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234628</td>\n",
       "      <td>0.277770</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>14.108353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>2.719636</td>\n",
       "      <td>0.178353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>0.123833</td>\n",
       "      <td>22.396716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>2.505886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>14.066949</td>\n",
       "      <td>0.109456</td>\n",
       "      <td>26.743063</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>2000-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>10.246954</td>\n",
       "      <td>0.136531</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198791</td>\n",
       "      <td>0.317390</td>\n",
       "      <td>1.180757</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>58.986601</td>\n",
       "      <td>1.632303</td>\n",
       "      <td>2000-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>2.568369</td>\n",
       "      <td>0.360951</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.405873</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>20.968395</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>2000-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>5.339139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048223</td>\n",
       "      <td>23.992102</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>63.308257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01</th>\n",
       "      <td>2.846635</td>\n",
       "      <td>0.041964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010481</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>14.563442</td>\n",
       "      <td>0.064738</td>\n",
       "      <td>30.878968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5  \\\n",
       "2000-05-01   1.621332  0.102854  0.094026  0.025079  0.000000  0.019590   \n",
       "2000-05-02   0.808829  0.015675  0.063167  0.027439  0.000000  0.000000   \n",
       "2000-05-03   3.981537  0.000000  0.080919  0.660461  0.000000  0.000000   \n",
       "2000-05-04   3.127851  0.029079  0.000000  0.000000  0.000000  0.234628   \n",
       "2000-05-05   2.719636  0.178353  0.000000  0.000000  0.000000  0.000000   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "2000-10-28   2.505886  0.000000  0.000000  0.000000  0.000000  0.026498   \n",
       "2000-10-29  10.246954  0.136531  0.313021  0.000000  0.198791  0.317390   \n",
       "2000-10-30   2.568369  0.360951  0.224304  0.018136  0.013114  0.000000   \n",
       "2000-10-31   5.339139  0.000000  0.106858  0.000000  0.000000  0.048223   \n",
       "2000-11-01   2.846635  0.041964  0.000000  0.000000  0.010481  0.017514   \n",
       "\n",
       "                    6         7          8         9        Date  \n",
       "2000-05-01   0.079944  0.011881   9.911343  0.042537  2000-05-01  \n",
       "2000-05-02   0.017249  0.000000   7.951341  0.000000  2000-05-02  \n",
       "2000-05-03   0.361854  1.318624  25.241359  0.000000  2000-05-03  \n",
       "2000-05-04   0.277770  0.022733  14.108353  0.000000  2000-05-04  \n",
       "2000-05-05   0.344190  0.123833  22.396716  0.000000  2000-05-05  \n",
       "...               ...       ...        ...       ...         ...  \n",
       "2000-10-28  14.066949  0.109456  26.743063  0.046997  2000-10-28  \n",
       "2000-10-29   1.180757  0.077100  58.986601  1.632303  2000-10-29  \n",
       "2000-10-30   8.405873  0.010417  20.968395  0.031752  2000-10-30  \n",
       "2000-10-31  23.992102  0.050947  63.308257  0.000000  2000-10-31  \n",
       "2000-11-01  14.563442  0.064738  30.878968  0.000000  2000-11-01  \n",
       "\n",
       "[185 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_topic = pd.DataFrame(date_topic_prob, index=unique_dates)\n",
    "date_topic[\"Date\"] = unique_dates\n",
    "date_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>1.621332</td>\n",
       "      <td>0.102854</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.079944</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>9.911343</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.808829</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.951341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>3.981537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.660461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.318624</td>\n",
       "      <td>25.241359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>3.127851</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234628</td>\n",
       "      <td>0.277770</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>14.108353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>2.719636</td>\n",
       "      <td>0.178353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>0.123833</td>\n",
       "      <td>22.396716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-27</th>\n",
       "      <td>5.295602</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.398398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.628495</td>\n",
       "      <td>0.260327</td>\n",
       "      <td>63.268936</td>\n",
       "      <td>0.156157</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>2.505886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>14.066949</td>\n",
       "      <td>0.109456</td>\n",
       "      <td>26.743063</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>10.246954</td>\n",
       "      <td>0.136531</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198791</td>\n",
       "      <td>0.317390</td>\n",
       "      <td>1.180757</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>58.986601</td>\n",
       "      <td>1.632303</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>2.568369</td>\n",
       "      <td>0.360951</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.405873</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>20.968395</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>5.339139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048223</td>\n",
       "      <td>23.992102</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>63.308257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5  \\\n",
       "Date                                                                      \n",
       "2000-05-01   1.621332  0.102854  0.094026  0.025079  0.000000  0.019590   \n",
       "2000-05-02   0.808829  0.015675  0.063167  0.027439  0.000000  0.000000   \n",
       "2000-05-03   3.981537  0.000000  0.080919  0.660461  0.000000  0.000000   \n",
       "2000-05-04   3.127851  0.029079  0.000000  0.000000  0.000000  0.234628   \n",
       "2000-05-05   2.719636  0.178353  0.000000  0.000000  0.000000  0.000000   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "2000-10-27   5.295602  0.713348  0.398398  0.000000  0.000000  0.000000   \n",
       "2000-10-28   2.505886  0.000000  0.000000  0.000000  0.000000  0.026498   \n",
       "2000-10-29  10.246954  0.136531  0.313021  0.000000  0.198791  0.317390   \n",
       "2000-10-30   2.568369  0.360951  0.224304  0.018136  0.013114  0.000000   \n",
       "2000-10-31   5.339139  0.000000  0.106858  0.000000  0.000000  0.048223   \n",
       "\n",
       "                    6         7          8         9  LastPrice  \n",
       "Date                                                             \n",
       "2000-05-01   0.079944  0.011881   9.911343  0.042537   0.523810  \n",
       "2000-05-02   0.017249  0.000000   7.951341  0.000000   0.504970  \n",
       "2000-05-03   0.361854  1.318624  25.241359  0.000000   0.509491  \n",
       "2000-05-04   0.277770  0.022733  14.108353  0.000000   0.511466  \n",
       "2000-05-05   0.344190  0.123833  22.396716  0.000000   0.520875  \n",
       "...               ...       ...        ...       ...        ...  \n",
       "2000-10-27  22.628495  0.260327  63.268936  0.156157   0.384310  \n",
       "2000-10-28  14.066949  0.109456  26.743063  0.046997   0.296488  \n",
       "2000-10-29   1.180757  0.077100  58.986601  1.632303   0.345703  \n",
       "2000-10-30   8.405873  0.010417  20.968395  0.031752   0.380711  \n",
       "2000-10-31  23.992102  0.050947  63.308257  0.000000   0.381966  \n",
       "\n",
       "[182 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_topic_prices = date_topic.set_index('Date').join(stock_prices.set_index('Date')).dropna()\n",
    "date_topic_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# temp_df = date_topic_prices[[0, 'LastPrice']].copy()\n",
    "# significance = 0.1\n",
    "\n",
    "# dt = pd.DataFrame(np.zeros((len(temp_df.columns), len(temp_df.columns))), columns=temp_df.columns, index=temp_df.columns)\n",
    "\n",
    "# relevant_topics = []\n",
    "# for c in temp_df.columns:\n",
    "#     for r in temp_df.columns:\n",
    "#         test_result = grangercausalitytests(temp_df[[r, c]], maxlag=5, verbose=False)\n",
    "#         p_values = [round(test_result[i+1][0]['ssr_ftest'][1], 4) for i in range(5)]\n",
    "        \n",
    "#         max_p_value_i = np.argmax(p_values)\n",
    "#         max_p_value = p_values[max_p_value_i]\n",
    "#         dt.loc[r, c] = max_p_value\n",
    "        \n",
    "# if dt.iloc[0, 1] > significance or dt.iloc[1, 0] > significance:\n",
    "#     relevant_topics.append(dt.columns[0])\n",
    "\n",
    "# dt.iloc[0, 1] * -1,dt, relevant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1746</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.3061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.6963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3561</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.5211</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.9456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.9181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.9283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9502</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.5567</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8799</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.7473</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1       2       3       4       5       6       7  \\\n",
       "0          1.0000  0.4773  0.4331  0.9868  0.6332  0.5860  0.1958  0.3013   \n",
       "1          0.1746  1.0000  0.6159  0.3993  0.4145  0.9056  0.9589  0.4811   \n",
       "2          0.0555  0.8640  1.0000  0.2492  0.7706  0.8359  0.9347  0.7319   \n",
       "3          0.9602  0.7892  0.9448  1.0000  0.9686  0.6534  0.9742  0.8327   \n",
       "4          0.4507  0.4466  0.6567  0.8875  1.0000  0.6834  0.9614  0.8840   \n",
       "5          0.4801  0.8156  0.2516  0.7899  0.5134  1.0000  0.6086  0.4321   \n",
       "6          0.3561  0.8975  0.5211  0.8655  0.6051  0.4055  1.0000  0.2722   \n",
       "7          0.1512  0.7041  0.9861  0.9717  0.6293  0.5585  0.8922  1.0000   \n",
       "8          0.6460  0.5934  0.1130  0.9833  0.3455  0.4971  0.5629  0.8804   \n",
       "9          0.4072  0.5711  0.7885  0.9204  0.9275  0.9502  0.2320  0.5567   \n",
       "LastPrice  0.8799  0.7234  0.2516  0.4499  0.5516  0.7473  0.5313  0.8637   \n",
       "\n",
       "                8       9  LastPrice  \n",
       "0          0.8192  0.5624     0.8051  \n",
       "1          0.1122  0.8977     0.3061  \n",
       "2          0.0143  0.1878     0.9954  \n",
       "3          0.9615  0.7886     0.6963  \n",
       "4          0.5303  0.5881     0.9860  \n",
       "5          0.5463  0.4863     0.0231  \n",
       "6          0.1119  0.7538     0.9456  \n",
       "7          0.4557  0.6103     0.9181  \n",
       "8          1.0000  0.2143     0.9283  \n",
       "9          0.1296  1.0000     0.8900  \n",
       "LastPrice  0.8776  0.6199     1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9  LastPrice\n",
       "0          0.0  4.0  4.0  4.0  3.0  4.0  3.0  3.0  0.0  4.0        1.0\n",
       "1          2.0  0.0  0.0  2.0  1.0  4.0  3.0  2.0  4.0  2.0        4.0\n",
       "2          2.0  2.0  0.0  2.0  0.0  3.0  0.0  1.0  0.0  0.0        4.0\n",
       "3          4.0  1.0  4.0  0.0  0.0  4.0  4.0  3.0  4.0  3.0        4.0\n",
       "4          3.0  4.0  1.0  4.0  0.0  4.0  4.0  1.0  4.0  0.0        1.0\n",
       "5          1.0  0.0  0.0  1.0  2.0  0.0  0.0  0.0  4.0  0.0        0.0\n",
       "6          0.0  0.0  1.0  4.0  1.0  0.0  0.0  4.0  0.0  0.0        4.0\n",
       "7          2.0  4.0  0.0  1.0  2.0  0.0  4.0  0.0  4.0  0.0        0.0\n",
       "8          2.0  4.0  4.0  3.0  1.0  4.0  3.0  4.0  0.0  2.0        0.0\n",
       "9          2.0  1.0  4.0  4.0  2.0  4.0  0.0  3.0  0.0  0.0        1.0\n",
       "LastPrice  2.0  4.0  4.0  1.0  0.0  1.0  4.0  0.0  3.0  1.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/58005681/is-it-possible-to-run-a-vector-autoregression-analysis-on-a-large-gdp-data-with\n",
    "def grangers_causality_matrix(data, variables, maxlag=5, test='ssr_ftest', verbose=False):\n",
    "    dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    lags    = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in dataset.columns:\n",
    "        for r in dataset.index:            \n",
    "            test_result = grangercausalitytests(data[[r,c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4) for i in range(maxlag)]\n",
    "            \n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "\n",
    "            max_p_value_i = np.argmax(p_values)\n",
    "            max_p_value = p_values[max_p_value_i]\n",
    "            dataset.loc[r, c] = max_p_value\n",
    "            \n",
    "            lags.loc[r, c] = max_p_value_i\n",
    "    \n",
    "    return dataset, lags\n",
    "\n",
    "# grangers_causality_matrix(dataset, variables = dataset.columns)\n",
    "causality, lags = grangers_causality_matrix(date_topic_prices, variables=date_topic_prices.columns, verbose=False)\n",
    "display(causality)\n",
    "display(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8799</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0  LastPrice\n",
       "0          1.0000     0.8051\n",
       "LastPrice  0.8799     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.7234</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1  LastPrice\n",
       "1          1.0000     0.3061\n",
       "LastPrice  0.7234     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2  LastPrice\n",
       "2          1.0000     0.9954\n",
       "LastPrice  0.2516     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.4499</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                3  LastPrice\n",
       "3          1.0000     0.6963\n",
       "LastPrice  0.4499     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.5516</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                4  LastPrice\n",
       "4          1.0000      0.986\n",
       "LastPrice  0.5516      1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.7473</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                5  LastPrice\n",
       "5          1.0000     0.0231\n",
       "LastPrice  0.7473     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.5313</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                6  LastPrice\n",
       "6          1.0000     0.9456\n",
       "LastPrice  0.5313     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8637</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                7  LastPrice\n",
       "7          1.0000     0.9181\n",
       "LastPrice  0.8637     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                8  LastPrice\n",
       "8          1.0000     0.9283\n",
       "LastPrice  0.8776     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.6199</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                9  LastPrice\n",
       "9          1.0000       0.89\n",
       "LastPrice  0.6199       1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([(2, 0.9954), (4, 0.986)], [-4.0, -1.0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_causal_vars(data, significance=0.95, getLags=False, getCausalSig=False, verbose=False):\n",
    "    cols = data.columns[:-1]\n",
    "    causal_vars = []\n",
    "    causal_lags = []\n",
    "    \n",
    "#     i = 0\n",
    "    for col in cols:\n",
    "        gc, lags = grangers_causality_matrix(data[[col, 'LastPrice']], \n",
    "                                             variables=[col, 'LastPrice'], \n",
    "                                             verbose=False)\n",
    "        \n",
    "#         if i < 10:\n",
    "#             display(gc)\n",
    "#             i += 1\n",
    "        \n",
    "        col_causes = gc.loc['LastPrice', col] >= significance\n",
    "        col_causedBy =  gc.loc[col, 'LastPrice'] >= significance\n",
    "        if col_causes or col_causedBy:\n",
    "            if getCausalSig:\n",
    "                causal_vars.append((col, max(gc.loc['LastPrice', col], gc.loc[col, 'LastPrice'])))\n",
    "            else:\n",
    "                causal_vars.append(col)\n",
    "            \n",
    "            if getLags:\n",
    "                # if sig. granger causality for topic causing ts and ts causing topic, choose whichever is higher\n",
    "                if col_causes and col_causedBy:\n",
    "                    if gc.loc['LastPrice', col] >= gc.loc[col, 'LastPrice']:\n",
    "                        causal_lags.append(lags.loc['LastPrice', col])\n",
    "                    else:\n",
    "                        causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "                elif col_causes:\n",
    "                    causal_lags.append(lags.loc['LastPrice', col])\n",
    "                else:\n",
    "                    causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "    if getLags:\n",
    "        return causal_vars, causal_lags\n",
    "    return causal_vars\n",
    "                \n",
    "causal_topics, ct_lags = get_causal_vars(date_topic_prices, getLags=True, getCausalSig=True)\n",
    "causal_topics, ct_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# def get_causal_topics(gc, lags, significance=0.95):\n",
    "#     keep_topics = gc[gc['LastPrice' ] > significance].index[:-1] \n",
    "#     keep_lags = list(lags.loc[keep_topics, 'LastPrice'])\n",
    "\n",
    "#     keep_topics_temp = (gc.loc[\"LastPrice\", gc.loc[\"LastPrice\"] > significance].index[:-1])\n",
    "#     keep_topics = keep_topics.append(keep_topics_temp)\n",
    "#     keep_lags += list(lags.loc[\"LastPrice\", keep_topics_temp])\n",
    "\n",
    "#     keep_topics = list(keep_topics)\n",
    "#     return list(zip(keep_topics, keep_lags))\n",
    "\n",
    "# causal_topics = get_causal_topics(causality, lags)\n",
    "# causal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# # for all topics, if a majority of docs from one date are in that topic, you're going to label that topic with that date\n",
    "# def get_topic_date(date_doc_topics, causal_topics):\n",
    "#     topic_date_cnts = {key: {} for key in causal_topics}\n",
    "    \n",
    "#     for date, doc in date_doc_topics:\n",
    "#         for topic, prob in doc:\n",
    "#             if topic in causal_topics:\n",
    "#                 try:\n",
    "#                     topic_date_cnts[topic][date] += 1\n",
    "#                 except KeyError:\n",
    "#                     topic_date_cnts[topic][date] = 1\n",
    "    \n",
    "#     topic_date = []\n",
    "    \n",
    "#     for topic in topic_date_cnts:\n",
    "#         max_date = max(topic_date_cnts[topic], key=lambda key: topic_date_cnts[topic][key])\n",
    "#         topic_date += [(topic, max_date)]\n",
    "        \n",
    "#     return topic_date\n",
    "    \n",
    "# causalTopic_dates = get_topic_date(date_doc_topics, [topic for topic, lag in causal_topics])\n",
    "# causalTopic_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "                said  weakening  hypothetical  baron  bushehr  iranian  memoir  \\\n",
       "  2000-05-01   574.0        0.0           1.0    0.0      0.0      0.0     0.0   \n",
       "  2000-05-02   287.0        0.0           0.0    6.0      0.0      0.0     0.0   \n",
       "  2000-05-03  1552.0        1.0           1.0    0.0     13.0      3.0     1.0   \n",
       "  2000-05-04   912.0        2.0           1.0    0.0      1.0      0.0     2.0   \n",
       "  2000-05-05  1485.0        2.0           1.0    6.0      0.0      0.0     6.0   \n",
       "  ...            ...        ...           ...    ...      ...      ...     ...   \n",
       "  2000-10-28     0.0        0.0           0.0    0.0      0.0      0.0     0.0   \n",
       "  2000-10-29     0.0        0.0           0.0    0.0      0.0      0.0     0.0   \n",
       "  2000-10-30     0.0        0.0           0.0    0.0      0.0      0.0     0.0   \n",
       "  2000-10-31     0.0        0.0           0.0    0.0      0.0      0.0     0.0   \n",
       "  2000-11-01     0.0        0.0           0.0    0.0      0.0      0.0     0.0   \n",
       "  \n",
       "              leak  unsustainable  muted  ...  lewis  playboy  tort  philip  \\\n",
       "  2000-05-01   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  2000-05-02   0.0            0.0    0.0  ...    0.0      0.0   4.0     1.0   \n",
       "  2000-05-03   1.0            0.0    0.0  ...    0.0      3.0   3.0     0.0   \n",
       "  2000-05-04   0.0            0.0    0.0  ...    1.0      0.0   1.0     0.0   \n",
       "  2000-05-05   1.0            0.0    3.0  ...    2.0     13.0   6.0     3.0   \n",
       "  ...          ...            ...    ...  ...    ...      ...   ...     ...   \n",
       "  2000-10-28   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  2000-10-29   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  2000-10-30   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  2000-10-31   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  2000-11-01   0.0            0.0    0.0  ...    0.0      0.0   0.0     0.0   \n",
       "  \n",
       "              rogers  nuclear  glass  methodist  activities  japan  \n",
       "  2000-05-01     0.0     23.0    2.0        0.0         6.0    0.0  \n",
       "  2000-05-02     0.0     21.0    0.0        2.0         4.0    1.0  \n",
       "  2000-05-03     2.0     73.0    9.0        5.0        18.0    0.0  \n",
       "  2000-05-04     0.0      6.0    1.0        2.0        21.0    2.0  \n",
       "  2000-05-05    10.0     15.0    1.0        3.0        11.0    4.0  \n",
       "  ...            ...      ...    ...        ...         ...    ...  \n",
       "  2000-10-28     0.0      0.0    0.0        0.0         0.0    0.0  \n",
       "  2000-10-29     0.0      0.0    0.0        0.0         0.0    0.0  \n",
       "  2000-10-30     0.0      0.0    0.0        0.0         0.0    0.0  \n",
       "  2000-10-31     0.0      0.0    0.0        0.0         0.0    0.0  \n",
       "  2000-11-01     0.0      0.0    0.0        0.0         0.0    0.0  \n",
       "  \n",
       "  [185 rows x 100 columns]),\n",
       " (4,\n",
       "              court  dee  campaign  profitably  defying    said  improbable  \\\n",
       "  2000-05-01   36.0  4.0     225.0         0.0      0.0   574.0         0.0   \n",
       "  2000-05-02   11.0  0.0     129.0         0.0      3.0   287.0         0.0   \n",
       "  2000-05-03  101.0  0.0     730.0         0.0      0.0  1552.0         1.0   \n",
       "  2000-05-04   54.0  0.0     523.0         0.0      2.0   912.0         0.0   \n",
       "  2000-05-05   43.0  0.0     892.0         2.0      0.0  1485.0         0.0   \n",
       "  ...           ...  ...       ...         ...      ...     ...         ...   \n",
       "  2000-10-28    0.0  0.0       0.0         0.0      0.0     0.0         0.0   \n",
       "  2000-10-29    0.0  0.0       0.0         0.0      0.0     0.0         0.0   \n",
       "  2000-10-30    0.0  0.0       0.0         0.0      0.0     0.0         0.0   \n",
       "  2000-10-31    0.0  0.0       0.0         0.0      0.0     0.0         0.0   \n",
       "  2000-11-01    0.0  0.0       0.0         0.0      0.0     0.0         0.0   \n",
       "  \n",
       "              greens  kiss  standardized  ...    gore  kenny  appellate  \\\n",
       "  2000-05-01     0.0   2.0           0.0  ...   872.0    0.0        0.0   \n",
       "  2000-05-02     0.0   0.0           0.0  ...   605.0    0.0        0.0   \n",
       "  2000-05-03     0.0   2.0           4.0  ...  2715.0    0.0        5.0   \n",
       "  2000-05-04     3.0   1.0           0.0  ...  1626.0    0.0        0.0   \n",
       "  2000-05-05     1.0   4.0           2.0  ...  2809.0    7.0        1.0   \n",
       "  ...            ...   ...           ...  ...     ...    ...        ...   \n",
       "  2000-10-28     0.0   0.0           0.0  ...     0.0    0.0        0.0   \n",
       "  2000-10-29     0.0   0.0           0.0  ...     0.0    0.0        0.0   \n",
       "  2000-10-30     0.0   0.0           0.0  ...     0.0    0.0        0.0   \n",
       "  2000-10-31     0.0   0.0           0.0  ...     0.0    0.0        0.0   \n",
       "  2000-11-01     0.0   0.0           0.0  ...     0.0    0.0        0.0   \n",
       "  \n",
       "              overturning  neck  editorials  martha  hagelin  backer    new  \n",
       "  2000-05-01          0.0   0.0         0.0     0.0      0.0     0.0  149.0  \n",
       "  2000-05-02          0.0   2.0         0.0     0.0      0.0     0.0   85.0  \n",
       "  2000-05-03          2.0   2.0         0.0     2.0      2.0     0.0  348.0  \n",
       "  2000-05-04          2.0   2.0         2.0     0.0      0.0     0.0  205.0  \n",
       "  2000-05-05          1.0   6.0         4.0     3.0      1.0     0.0  413.0  \n",
       "  ...                 ...   ...         ...     ...      ...     ...    ...  \n",
       "  2000-10-28          0.0   0.0         0.0     0.0      0.0     0.0    0.0  \n",
       "  2000-10-29          0.0   0.0         0.0     0.0      0.0     0.0    0.0  \n",
       "  2000-10-30          0.0   0.0         0.0     0.0      0.0     0.0    0.0  \n",
       "  2000-10-31          0.0   0.0         0.0     0.0      0.0     0.0    0.0  \n",
       "  2000-11-01          0.0   0.0         0.0     0.0      0.0     0.0    0.0  \n",
       "  \n",
       "  [185 rows x 100 columns])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_stream(nytimes, topics, causal_topics):\n",
    "    ct_ws = []\n",
    "    for ct in causal_topics:\n",
    "        causal_vocab = list(set(topics[ct][1]))\n",
    "        date_terms = pd.DataFrame(np.zeros((len(unique_dates), len(causal_vocab))), index=unique_dates, columns=causal_vocab)\n",
    "\n",
    "        for date, doc in zip(nytimes['Date'], date_term_cnts):\n",
    "            for word, count in doc:\n",
    "                try:\n",
    "                     date_terms.loc[date, word] += int(count)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        ct_ws.append((ct, date_terms))\n",
    "    \n",
    "    return ct_ws\n",
    "\n",
    "ct_ws = get_word_stream(nytimes, topics, causal_topics)\n",
    "ct_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>said</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9901</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             said  LastPrice\n",
       "said       1.0000     0.8869\n",
       "LastPrice  0.9901     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weakening</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weakening</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.7032</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           weakening  LastPrice\n",
       "weakening     1.0000     0.9843\n",
       "LastPrice     0.7032     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothetical</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hypothetical</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8779</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hypothetical  LastPrice\n",
       "hypothetical        1.0000     0.9255\n",
       "LastPrice           0.8779     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (res2down.ssr - res2djoint.ssr)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1421: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fgc2 = res2down.nobs * (res2down.ssr - res2djoint.ssr) / res2djoint.ssr\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:903: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1430: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lr = -2 * (res2down.llf - res2djoint.llf)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1850: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F /= J\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baron</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baron</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            baron  LastPrice\n",
       "baron         NaN        NaN\n",
       "LastPrice  0.9171        1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bushehr</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bushehr</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9909</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bushehr  LastPrice\n",
       "bushehr     1.0000     0.9151\n",
       "LastPrice   0.9909     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iranian</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iranian</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9964</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           iranian  LastPrice\n",
       "iranian     1.0000      0.209\n",
       "LastPrice   0.9964      1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (res2down.ssr - res2djoint.ssr)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1421: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fgc2 = res2down.nobs * (res2down.ssr - res2djoint.ssr) / res2djoint.ssr\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:903: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1430: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lr = -2 * (res2down.llf - res2djoint.llf)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1850: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F /= J\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memoir</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>memoir</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8972</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           memoir  LastPrice\n",
       "memoir        NaN        NaN\n",
       "LastPrice  0.8972        1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leak</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leak</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9469</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             leak  LastPrice\n",
       "leak       1.0000     0.9942\n",
       "LastPrice  0.9469     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unsustainable</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unsustainable</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9996</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               unsustainable  LastPrice\n",
       "unsustainable         1.0000     0.0338\n",
       "LastPrice             0.9996     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>muted</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>muted</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.2544</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            muted  LastPrice\n",
       "muted      1.0000     0.4837\n",
       "LastPrice  0.2544     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>court</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.8544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.802</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           court  LastPrice\n",
       "court      1.000     0.8544\n",
       "LastPrice  0.802     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dee</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dee</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dee  LastPrice\n",
       "dee        1.0000        1.0\n",
       "LastPrice  0.9792        1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  LastPrice\n",
       "campaign     1.0000     0.8514\n",
       "LastPrice    0.9762     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (res2down.ssr - res2djoint.ssr)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1421: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fgc2 = res2down.nobs * (res2down.ssr - res2djoint.ssr) / res2djoint.ssr\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:903: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1430: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lr = -2 * (res2down.llf - res2djoint.llf)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1850: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F /= J\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profitably</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profitably</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.936</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            profitably  LastPrice\n",
       "profitably         NaN        NaN\n",
       "LastPrice        0.936        1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defying</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>defying</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8843</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           defying  LastPrice\n",
       "defying     1.0000     0.6302\n",
       "LastPrice   0.8843     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>said</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9901</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             said  LastPrice\n",
       "said       1.0000     0.8869\n",
       "LastPrice  0.9901     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>improbable</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>improbable</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9799</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            improbable  LastPrice\n",
       "improbable      1.0000     0.9809\n",
       "LastPrice       0.9799     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greens</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>greens</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9952</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           greens  LastPrice\n",
       "greens     1.0000     0.9077\n",
       "LastPrice  0.9952     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kiss</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kiss</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9433</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kiss  LastPrice\n",
       "kiss       1.0000     0.8741\n",
       "LastPrice  0.9433     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standardized</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>standardized</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.6147</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standardized  LastPrice\n",
       "standardized        1.0000     0.9923\n",
       "LastPrice           0.6147     1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (res2down.ssr - res2djoint.ssr)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1421: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fgc2 = res2down.nobs * (res2down.ssr - res2djoint.ssr) / res2djoint.ssr\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:903: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/tsa/stattools.py:1430: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lr = -2 * (res2down.llf - res2djoint.llf)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1850: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F /= J\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  [('iranian', 0.9964),\n",
       "   ('unsustainable', 0.9996),\n",
       "   ('replacing', 0.9689),\n",
       "   ('clemens', 0.9835),\n",
       "   ('honda', 0.973),\n",
       "   ('parking', 0.9977),\n",
       "   ('ministers', 0.9885),\n",
       "   ('graeme', 0.9947),\n",
       "   ('logo', 0.9961)],\n",
       "  [('said', 0.9901),\n",
       "   ('weakening', 0.9843),\n",
       "   ('bushehr', 0.9909),\n",
       "   ('leak', 0.9942),\n",
       "   ('glamorous', 0.9884),\n",
       "   ('pure', 0.9876),\n",
       "   ('publicized', 0.9946),\n",
       "   ('georgewbush', 0.9701),\n",
       "   ('mr', 0.9506),\n",
       "   ('gorey', 0.9999),\n",
       "   ('innings', 0.9993),\n",
       "   ('bushnell', 0.9987),\n",
       "   ('milosevic', 0.9927),\n",
       "   ('embarrassing', 0.9977),\n",
       "   ('zoo', 0.992),\n",
       "   ('embarrass', 0.9839),\n",
       "   ('wells', 0.9701),\n",
       "   ('pushing', 0.9939),\n",
       "   ('bomb', 0.9873),\n",
       "   ('erased', 0.9736),\n",
       "   ('arnold', 0.9533),\n",
       "   ('visiting', 0.9933),\n",
       "   ('anthony', 0.9968),\n",
       "   ('hefner', 0.9964),\n",
       "   ('anachronism', 0.9782),\n",
       "   ('concerts', 1.0),\n",
       "   ('isolationist', 0.9991),\n",
       "   ('triumphs', 0.9996),\n",
       "   ('nassau', 0.9993),\n",
       "   ('london', 0.9888),\n",
       "   ('toronto', 0.9891),\n",
       "   ('morris', 0.9983),\n",
       "   ('mode', 0.9724),\n",
       "   ('intervention', 0.9941),\n",
       "   ('tag', 0.9995),\n",
       "   ('dell', 0.9903),\n",
       "   ('lewis', 0.9913),\n",
       "   ('rogers', 0.9982),\n",
       "   ('nuclear', 0.9921),\n",
       "   ('glass', 0.9965)]),\n",
       " (4,\n",
       "  [('torricelli', 0.9639),\n",
       "   ('beaver', 0.9965),\n",
       "   ('repertory', 0.9944),\n",
       "   ('turnpike', 1.0),\n",
       "   ('bethany', 0.9999)],\n",
       "  [('dee', 1.0),\n",
       "   ('campaign', 0.9762),\n",
       "   ('said', 0.9901),\n",
       "   ('improbable', 0.9809),\n",
       "   ('greens', 0.9952),\n",
       "   ('standardized', 0.9923),\n",
       "   ('appointees', 0.9677),\n",
       "   ('caliber', 0.9558),\n",
       "   ('lame', 0.9744),\n",
       "   ('assent', 1.0),\n",
       "   ('pork', 0.9627),\n",
       "   ('gonzales', 0.9992),\n",
       "   ('mr', 0.9506),\n",
       "   ('revival', 0.9852),\n",
       "   ('legally', 0.995),\n",
       "   ('nader', 0.9819),\n",
       "   ('castro', 0.996),\n",
       "   ('vote', 0.9503),\n",
       "   ('dignitaries', 0.9999),\n",
       "   ('state', 0.955),\n",
       "   ('influencing', 0.999),\n",
       "   ('hoffa', 0.9825),\n",
       "   ('mentally', 0.9809),\n",
       "   ('postconvention', 0.9518),\n",
       "   ('pirates', 1.0),\n",
       "   ('cream', 0.9532),\n",
       "   ('fracture', 0.9991),\n",
       "   ('percent', 0.99),\n",
       "   ('watergate', 0.9874),\n",
       "   ('creek', 0.9879),\n",
       "   ('accountability', 0.9934),\n",
       "   ('violated', 0.9765),\n",
       "   ('sack', 0.9999),\n",
       "   ('violating', 0.9999),\n",
       "   ('ore', 0.9724),\n",
       "   ('monument', 0.993),\n",
       "   ('roe', 0.9734),\n",
       "   ('plaintiffs', 0.9993),\n",
       "   ('kenny', 0.9997),\n",
       "   ('appellate', 0.9646),\n",
       "   ('neck', 0.9865),\n",
       "   ('backer', 0.9687),\n",
       "   ('new', 0.991)])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_impact_words(topic_wordstream, significance=0.95, verbose=False):\n",
    "    topic_impact_words = []\n",
    "    \n",
    "    first = True\n",
    "    for topic, ws in topic_wordstream:\n",
    "        ws_prices = ws.join(stock_prices.set_index('Date')).dropna()        \n",
    "        ws_gc = get_causal_vars(ws_prices, significance=significance, getCausalSig=True, verbose=verbose)\n",
    "        \n",
    "#         if first:\n",
    "#             display(ws_gc)\n",
    "#             first = False\n",
    "        \n",
    "        pos = []\n",
    "        neg = []\n",
    "        for word, sig in ws_gc:                \n",
    "            corr = pearsonr(ws_prices[word], stock_prices['LastPrice'])[0]\n",
    "            if corr > 0:\n",
    "                pos.append((word, sig))\n",
    "            else:\n",
    "                neg.append((word, sig))\n",
    "                \n",
    "        topic_impact_words.append((topic, pos, neg))\n",
    "    \n",
    "    return topic_impact_words\n",
    "        \n",
    "\n",
    "impact_words = get_impact_words(ct_ws)\n",
    "impact_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_prices = ct_ws.join(stock_prices.set_index('Date')).dropna()\n",
    "ws_impact, ws_lags = grangers_causality_matrix(ws_prices, variables=ws_prices.columns, verbose=False)\n",
    "\n",
    "display(ws_prices)\n",
    "display(ws_impact)\n",
    "display(ws_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pearsonr(ws_prices[\"cleansing\"], stock_prices['LastPrice'])[0]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_ws[0][1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass prob to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
