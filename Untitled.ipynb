{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# stop_words.extend(['mr', 'ms', 'said'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# def lemmatize(content, tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "#     texts_out = []\n",
    "#     for sent in texts:\n",
    "#         doc = nlp(\" \".join(sent)) \n",
    "#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "#     return texts_out\n",
    "\n",
    "# Tokenize and remove stop words from content\n",
    "def tokenize(content, lemmatize=False):\n",
    "    words = gensim.utils.simple_preprocess(content, deacc=True)  # tokenizes\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(content):\n",
    "    words = []\n",
    "    for word in content:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not lemmatizing or stemming. If we need to increase accuracy in the future, we can consider it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[two, years, ago, homer, bush, came, yankee, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>[texas, record, tell, op, ed, april, paul, bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>[top, foreign, policy, adviser, gov, george, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[aides, gov, george, bush, fought, back, today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[gov, tommy, thompson, wisconsin, named, chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[new, york, times, cbs, news, poll, var, strin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[tick, tock, diner, ted, friedrich, stockbroke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[difference, us, vital, issue, would, go, wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[bush, administration, wanted, overturn, would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[first, gov, jeb, bush, florida, told, hallowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                            Content\n",
       "0     2000-05-03  [two, years, ago, homer, bush, came, yankee, b...\n",
       "1     2000-05-02  [texas, record, tell, op, ed, april, paul, bur...\n",
       "2     2000-05-01  [top, foreign, policy, adviser, gov, george, b...\n",
       "3     2000-05-03  [aides, gov, george, bush, fought, back, today...\n",
       "4     2000-05-03  [gov, tommy, thompson, wisconsin, named, chair...\n",
       "...          ...                                                ...\n",
       "5801  2000-10-31  [new, york, times, cbs, news, poll, var, strin...\n",
       "5802  2000-10-31  [tick, tock, diner, ted, friedrich, stockbroke...\n",
       "5803  2000-11-01  [difference, us, vital, issue, would, go, wash...\n",
       "5804  2000-11-01  [bush, administration, wanted, overturn, would...\n",
       "5805  2000-11-01  [first, gov, jeb, bush, florida, told, hallowe...\n",
       "\n",
       "[5806 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New York Times Data\n",
    "rows = []\n",
    "dates = []\n",
    "articles = []\n",
    "for month in range(5, 11):\n",
    "    with open(\"Data/NYTimes/\"+ str(month) + \".txt\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            date, article = line.split(\",\", 1)\n",
    "            timestamp = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "            tokenized = tokenize(article)\n",
    "            destopped = remove_stopwords(tokenized)\n",
    "\n",
    "            articles.append(destopped)\n",
    "            dates.append(timestamp)\n",
    "            rows.append([timestamp, destopped])\n",
    "\n",
    "nytimes = pd.DataFrame(rows, columns=[\"Date\", \"Content\"]) \n",
    "unique_dates = sorted(list(set(nytimes[\"Date\"])))\n",
    "# print (unique_dates)\n",
    "nytimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 days missing from the stock market data: 6/07, 6/08, 11/01. There are several ways we can deal with this. \n",
    "1. Toss out the three days from the NYTimes data\n",
    "2. Condense 6/07 --> 6/06; 6/08 --> 6/09 (or something similar) and toss out 11/01. \n",
    "3. Something else that I can't think of at the moment\n",
    "\n",
    "I also haven't looked at the paper to see how they deal with it yet.\n",
    "\n",
    "Edit: Reading over some articles about time series, it seems that we should pad the missing datapoints with previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-04</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-05</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  LastPrice\n",
       "0    2000-05-01   0.523810\n",
       "1    2000-05-02   0.504970\n",
       "2    2000-05-03   0.509491\n",
       "3    2000-05-04   0.511466\n",
       "4    2000-05-05   0.520875\n",
       "..          ...        ...\n",
       "177  2000-10-27   0.384310\n",
       "178  2000-10-28   0.296488\n",
       "179  2000-10-29   0.345703\n",
       "180  2000-10-30   0.380711\n",
       "181  2000-10-31   0.381966\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Series Data\n",
    "ts_months = [\"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\"]\n",
    "cols = ['Date', 'LastPrice']\n",
    "stock_prices = pd.DataFrame()\n",
    "for month in ts_months:\n",
    "    ts_df = pd.read_csv(\"Data/PriceHistory/\" + month + \".txt\", delim_whitespace=True)\n",
    "    ts_df['Date'] =  ts_df['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%y\").date())\n",
    "    \n",
    "    Gore = ts_df.loc[ts_df['Contract'] == 'Dem'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "    Bush = ts_df.loc[ts_df['Contract'] == 'Rep'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "\n",
    "    # Gore/(Gore + Bush)\n",
    "    relation = list(zip(Gore['Date'], (Gore['LastPrice']/(Gore['LastPrice'] + Bush['LastPrice'])).fillna(0.001)))\n",
    "    stock_prices = stock_prices.append(relation, ignore_index=True)\n",
    "\n",
    "stock_prices.columns = cols\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(unique_dates)):\n",
    "#     if unique_dates[i] not in list(stock_prices[0]):\n",
    "#         print (unique_dates[i])\n",
    "\n",
    "# bigram = Phrases(articles, min_count=1)\n",
    "# bigrams = [b for b in bigram[articles]]\n",
    "# articles = bigrams\n",
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ago', 0.07712049873418031),\n",
       " ('awesome', 0.23220574510227418),\n",
       " ('backup', 0.2198823985449398),\n",
       " ('backups', 0.2515408271170864),\n",
       " ('bases', 0.19264069440348208)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(articles)\n",
    "\n",
    "# Attempt at filtering out words that appear too frequently\n",
    "# id2word.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "# id2word.filter_extremes(no_above=0.5)\n",
    "\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in articles]\n",
    "# doc_word_cnts = (np.array([np.array([(id2word[id], freq) for id, freq in cp]) for cp in corpus]))\n",
    "\n",
    "# TF-IDF seems to give better coherence (but it wasn't in the paper...)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in tfidf_corpus[:1]][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ago</th>\n",
       "      <th>bush</th>\n",
       "      <th>two</th>\n",
       "      <th>years</th>\n",
       "      <th>also</th>\n",
       "      <th>chief</th>\n",
       "      <th>conservative</th>\n",
       "      <th>executive</th>\n",
       "      <th>george</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>pitted</th>\n",
       "      <th>reappeared</th>\n",
       "      <th>actuary</th>\n",
       "      <th>deerfield</th>\n",
       "      <th>issimmee</th>\n",
       "      <th>madame</th>\n",
       "      <th>subtraction</th>\n",
       "      <th>tussaud</th>\n",
       "      <th>unchartered</th>\n",
       "      <th>buffett</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>1.000</td>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16</td>\n",
       "      <td>5.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.001</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>4.000</td>\n",
       "      <td>150</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>22</td>\n",
       "      <td>6.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>6.000</td>\n",
       "      <td>246</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>38</td>\n",
       "      <td>16.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>368</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>94</td>\n",
       "      <td>7.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>24.000</td>\n",
       "      <td>464</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>76</td>\n",
       "      <td>16.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>6.000</td>\n",
       "      <td>271</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000</td>\n",
       "      <td>43</td>\n",
       "      <td>9.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>2.000</td>\n",
       "      <td>592</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.000</td>\n",
       "      <td>134</td>\n",
       "      <td>16.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01</th>\n",
       "      <td>5.000</td>\n",
       "      <td>396</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88</td>\n",
       "      <td>22.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 28658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ago  bush   two  years  also  chief  conservative  executive  \\\n",
       "2000-05-01   1.000    74   2.0    6.0   6.0    2.0         1.000      2.000   \n",
       "2000-05-02   0.001    13   2.0    1.0   4.0    1.0         1.000      1.000   \n",
       "2000-05-03   4.000   150   8.0   16.0  14.0    4.0         8.000      0.001   \n",
       "2000-05-04   0.001    86   2.0    2.0   7.0    1.0         2.000      0.001   \n",
       "2000-05-05   6.000   246  14.0   16.0  14.0    2.0         0.001      0.001   \n",
       "...            ...   ...   ...    ...   ...    ...           ...        ...   \n",
       "2000-10-28   1.000   368  15.0    7.0  23.0    2.0        13.000      2.000   \n",
       "2000-10-29  24.000   464  50.0   42.0  32.0    8.0        22.000      4.000   \n",
       "2000-10-30   6.000   271  13.0    9.0  11.0    4.0         0.001      2.000   \n",
       "2000-10-31   2.000   592  30.0   26.0  24.0   14.0         0.001      4.000   \n",
       "2000-11-01   5.000   396  24.0    3.0  24.0    1.0         6.000      1.000   \n",
       "\n",
       "            george     get  ...  pitted  reappeared  actuary  deerfield  \\\n",
       "2000-05-01      16   5.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-05-02       8   2.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-05-03      22   6.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-05-04      19   0.001  ...   0.001       0.001    0.001      0.001   \n",
       "2000-05-05      38  16.000  ...   0.001       0.001    0.001      0.001   \n",
       "...            ...     ...  ...     ...         ...      ...        ...   \n",
       "2000-10-28      94   7.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-10-29      76  16.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-10-30      43   9.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-10-31     134  16.000  ...   0.001       0.001    0.001      0.001   \n",
       "2000-11-01      88  22.000  ...   1.000       1.000    1.000      1.000   \n",
       "\n",
       "            issimmee  madame  subtraction  tussaud  unchartered  buffett  \n",
       "2000-05-01     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-05-02     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-05-03     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-05-04     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-05-05     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "...              ...     ...          ...      ...          ...      ...  \n",
       "2000-10-28     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-10-29     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-10-30     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-10-31     0.001   0.001        0.001    0.001        0.001    0.001  \n",
       "2000-11-01     1.000   1.000        1.000    1.000        1.000    1.000  \n",
       "\n",
       "[185 rows x 28658 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow by date?\n",
    "date_term_cnts = defaultdict(lambda: [])\n",
    "\n",
    "for index, row in nytimes.iterrows():\n",
    "    date = row[\"Date\"]\n",
    "    content = row[\"Content\"]\n",
    "    \n",
    "    date_term_cnts[date] += content\n",
    "    \n",
    "date_term_cnts = list(date_term_cnts.items())\n",
    "# date_term_cnts\n",
    "date_term_cnts = [(date, {id2word[id]: freq for id, freq in id2word.doc2bow(text)}) for date, text in date_term_cnts]\n",
    "date_term_cnts = sorted(date_term_cnts, key=lambda x: x[0])\n",
    "date_term_cnts = pd.DataFrame([date_term_cnts[i][1] for i in range(len(date_term_cnts))], index=[date_term_cnts[i][0] for i in range(len(date_term_cnts))]).fillna(0.001)\n",
    "date_term_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ad37a52b408c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build LDA model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m lda_model = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                            \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mdirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mrho\u001b[0;34m()\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;31m# while allowing it to \"reset\" on the first pass of each update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpass_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "k = 10\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "                                           passes=2,\n",
    "                                           alpha='auto',  # assuming that topic distribution is assymetric. Not all topics equally represented in corpus.\n",
    "                                           eta='auto',\n",
    "                                           update_every=1, # online or batch processing (everything is on disk, so use online)\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=articles, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts:\n",
    "\n",
    "We need to de-pluralize the words (governments vs government).\n",
    "Get the coherence score above 50 would be a good start probably.\n",
    "\n",
    "Need to extend stop words to include mr.\n",
    "\n",
    "But topic coherency is still very low\n",
    "\n",
    "Also, we can double check our topic coherence by comparing with Wikipedia (and other checks the paper did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ['gorey',\n",
       "   'intervention',\n",
       "   'bushwick',\n",
       "   'wrongful',\n",
       "   'stuyvesant',\n",
       "   'bedford',\n",
       "   'predicting',\n",
       "   'insults',\n",
       "   'derby',\n",
       "   'monetary',\n",
       "   'patriot',\n",
       "   'exemptions',\n",
       "   'assent',\n",
       "   'intervene',\n",
       "   'stewart',\n",
       "   'chernobyl',\n",
       "   'greenhouse',\n",
       "   'hale',\n",
       "   'wyly',\n",
       "   'trent',\n",
       "   'harlem',\n",
       "   'inmate',\n",
       "   'shalom',\n",
       "   'mr',\n",
       "   'riot',\n",
       "   'dance',\n",
       "   'exposure',\n",
       "   'enron',\n",
       "   'passengers',\n",
       "   'solicitor',\n",
       "   'jewish',\n",
       "   'factors',\n",
       "   'depart',\n",
       "   'brooklyn',\n",
       "   'marshall',\n",
       "   'humanities',\n",
       "   'recycling',\n",
       "   'trash',\n",
       "   'reforms',\n",
       "   'lockstep',\n",
       "   'interventionist',\n",
       "   'said',\n",
       "   'goren',\n",
       "   'bone',\n",
       "   'olympic',\n",
       "   'gore',\n",
       "   'counts',\n",
       "   'amusing',\n",
       "   'drily',\n",
       "   'cultural',\n",
       "   'police',\n",
       "   'neighborhood',\n",
       "   'sgt',\n",
       "   'capelludo',\n",
       "   'priest',\n",
       "   'nikas',\n",
       "   'elias',\n",
       "   'lourdes',\n",
       "   'sodomy',\n",
       "   'busing',\n",
       "   'starr',\n",
       "   'presumptive',\n",
       "   'absence',\n",
       "   'insistence',\n",
       "   'opera',\n",
       "   'president',\n",
       "   'wrongly',\n",
       "   'rectify',\n",
       "   'humanitarian',\n",
       "   'beautiful',\n",
       "   'trio',\n",
       "   'bush',\n",
       "   'would',\n",
       "   'enterprise',\n",
       "   'appoints',\n",
       "   'observed',\n",
       "   'lott',\n",
       "   'campaign',\n",
       "   'churchill',\n",
       "   'crown',\n",
       "   'cheney',\n",
       "   'nonworking',\n",
       "   'ratio',\n",
       "   'running',\n",
       "   'abuse',\n",
       "   'port',\n",
       "   'singled',\n",
       "   'infection',\n",
       "   'money',\n",
       "   'glasses',\n",
       "   'accept',\n",
       "   'yorktown',\n",
       "   'fixated',\n",
       "   'classes',\n",
       "   'erroneous',\n",
       "   'tendency',\n",
       "   'front',\n",
       "   'texas',\n",
       "   'similant',\n",
       "   'vice']),\n",
       " (1,\n",
       "  ['mr',\n",
       "   'gore',\n",
       "   'said',\n",
       "   'bush',\n",
       "   'debate',\n",
       "   'campaign',\n",
       "   'would',\n",
       "   'clinton',\n",
       "   'tax',\n",
       "   'president',\n",
       "   'percent',\n",
       "   'cheney',\n",
       "   'vice',\n",
       "   'plan',\n",
       "   'nader',\n",
       "   'one',\n",
       "   'lieberman',\n",
       "   'people',\n",
       "   'oil',\n",
       "   'voters',\n",
       "   'governor',\n",
       "   'texas',\n",
       "   'state',\n",
       "   'presidential',\n",
       "   'republican',\n",
       "   'states',\n",
       "   'new',\n",
       "   'party',\n",
       "   'debates',\n",
       "   'today',\n",
       "   'democratic',\n",
       "   'gov',\n",
       "   'al',\n",
       "   'like',\n",
       "   'security',\n",
       "   'democrats',\n",
       "   'last',\n",
       "   'first',\n",
       "   'american',\n",
       "   'two',\n",
       "   'also',\n",
       "   'administration',\n",
       "   'time',\n",
       "   'government',\n",
       "   'vote',\n",
       "   'could',\n",
       "   'republicans',\n",
       "   'years',\n",
       "   'social',\n",
       "   'election',\n",
       "   'national',\n",
       "   'political',\n",
       "   'policy',\n",
       "   'senator',\n",
       "   'year',\n",
       "   'george',\n",
       "   'money',\n",
       "   'health',\n",
       "   'convention',\n",
       "   'drug',\n",
       "   'house',\n",
       "   'candidates',\n",
       "   'candidate',\n",
       "   'say',\n",
       "   'running',\n",
       "   'many',\n",
       "   'support',\n",
       "   'oct',\n",
       "   'page',\n",
       "   'even',\n",
       "   'day',\n",
       "   'week',\n",
       "   'federal',\n",
       "   'think',\n",
       "   'much',\n",
       "   'issues',\n",
       "   'million',\n",
       "   'made',\n",
       "   'race',\n",
       "   'speech',\n",
       "   'education',\n",
       "   'abortion',\n",
       "   'cut',\n",
       "   'york',\n",
       "   'military',\n",
       "   'issue',\n",
       "   'way',\n",
       "   'get',\n",
       "   'washington',\n",
       "   'may',\n",
       "   'lazio',\n",
       "   'make',\n",
       "   'night',\n",
       "   'bill',\n",
       "   'polls',\n",
       "   'florida',\n",
       "   'news',\n",
       "   'white',\n",
       "   'big',\n",
       "   'aides']),\n",
       " (2,\n",
       "  ['heating',\n",
       "   'barrels',\n",
       "   'supply',\n",
       "   'petroleum',\n",
       "   'carbon',\n",
       "   'lieberman',\n",
       "   'reserves',\n",
       "   'coal',\n",
       "   'tame',\n",
       "   'kelly',\n",
       "   'windfall',\n",
       "   'coach',\n",
       "   'spokesmen',\n",
       "   'oil',\n",
       "   'exporting',\n",
       "   'deadline',\n",
       "   'parody',\n",
       "   'prepare',\n",
       "   'entertainment',\n",
       "   'glimpse',\n",
       "   'sites',\n",
       "   'prayers',\n",
       "   'page',\n",
       "   'gorecki',\n",
       "   'henryk',\n",
       "   'skirmishes',\n",
       "   'trapping',\n",
       "   'bids',\n",
       "   'weighed',\n",
       "   'kline',\n",
       "   'withdrawing',\n",
       "   'www',\n",
       "   'terminal',\n",
       "   'stewart',\n",
       "   'industry',\n",
       "   'landscape',\n",
       "   'fuel',\n",
       "   'complaints',\n",
       "   'richardson',\n",
       "   'scamp',\n",
       "   'front',\n",
       "   'sources',\n",
       "   'dare',\n",
       "   'sits',\n",
       "   'irish',\n",
       "   'buildings',\n",
       "   'inexperienced',\n",
       "   'com',\n",
       "   'jews',\n",
       "   'praying',\n",
       "   'deciding',\n",
       "   'fuels',\n",
       "   'aug',\n",
       "   'happening',\n",
       "   'tenants',\n",
       "   'redefine',\n",
       "   'webster',\n",
       "   'influencing',\n",
       "   'harvey',\n",
       "   'huffington',\n",
       "   'transformed',\n",
       "   'theater',\n",
       "   'joseph',\n",
       "   'md',\n",
       "   'mr',\n",
       "   'berkeley',\n",
       "   'stations',\n",
       "   'video',\n",
       "   'energy',\n",
       "   'forgot',\n",
       "   'birch',\n",
       "   'regional',\n",
       "   'interracial',\n",
       "   'waterfront',\n",
       "   'chretien',\n",
       "   'nassau',\n",
       "   'breakthrough',\n",
       "   'contains',\n",
       "   'noonan',\n",
       "   'brooklyn',\n",
       "   'autumn',\n",
       "   'gore',\n",
       "   'ambiguity',\n",
       "   'ticket',\n",
       "   'stickers',\n",
       "   'repairs',\n",
       "   'actor',\n",
       "   'horn',\n",
       "   'reserve',\n",
       "   'swiftly',\n",
       "   'warner',\n",
       "   'giuliani',\n",
       "   'tally',\n",
       "   'jeff',\n",
       "   'dioxide',\n",
       "   'hollywood',\n",
       "   'jar',\n",
       "   'rudy',\n",
       "   'prices',\n",
       "   'cents']),\n",
       " (3,\n",
       "  ['sanctions',\n",
       "   'franks',\n",
       "   'letterman',\n",
       "   'miller',\n",
       "   'upstate',\n",
       "   'location',\n",
       "   'corzine',\n",
       "   'fires',\n",
       "   'nelson',\n",
       "   'reserves',\n",
       "   'film',\n",
       "   'arafat',\n",
       "   'cents',\n",
       "   'europe',\n",
       "   'fed',\n",
       "   'pbs',\n",
       "   'diner',\n",
       "   'performances',\n",
       "   'profoundly',\n",
       "   'resign',\n",
       "   'heating',\n",
       "   'mccollum',\n",
       "   'dwight',\n",
       "   'goren',\n",
       "   'taylor',\n",
       "   'marshall',\n",
       "   'gather',\n",
       "   'greenspan',\n",
       "   'manchester',\n",
       "   'forests',\n",
       "   'denver',\n",
       "   'burton',\n",
       "   'diplomatic',\n",
       "   'admitting',\n",
       "   'mr',\n",
       "   'inc',\n",
       "   'leone',\n",
       "   'bobby',\n",
       "   'logging',\n",
       "   'bushwick',\n",
       "   'triumphs',\n",
       "   'prepare',\n",
       "   'purely',\n",
       "   'actor',\n",
       "   'kahn',\n",
       "   'biting',\n",
       "   'comptroller',\n",
       "   'achieved',\n",
       "   'whoever',\n",
       "   'village',\n",
       "   'tick',\n",
       "   'dancers',\n",
       "   'divisive',\n",
       "   'legally',\n",
       "   'retiring',\n",
       "   'rebuild',\n",
       "   'trick',\n",
       "   'lautenberg',\n",
       "   'inclusiveness',\n",
       "   'weakness',\n",
       "   'lifting',\n",
       "   'mack',\n",
       "   'maintaining',\n",
       "   'holbrooke',\n",
       "   'hart',\n",
       "   'percent',\n",
       "   'conceded',\n",
       "   'devastating',\n",
       "   'casual',\n",
       "   'anymore',\n",
       "   'stressing',\n",
       "   'spells',\n",
       "   'thurgood',\n",
       "   'onstage',\n",
       "   'ordering',\n",
       "   'rogue',\n",
       "   'lockhart',\n",
       "   'demographically',\n",
       "   'defying',\n",
       "   'emboldened',\n",
       "   'fees',\n",
       "   'transfer',\n",
       "   'sierra',\n",
       "   'solo',\n",
       "   'torch',\n",
       "   'limelight',\n",
       "   'albright',\n",
       "   'narrower',\n",
       "   'siewert',\n",
       "   'williamsburg',\n",
       "   'objected',\n",
       "   'said',\n",
       "   'embracing',\n",
       "   'urban',\n",
       "   'movies',\n",
       "   'conversely',\n",
       "   'patient',\n",
       "   'strained',\n",
       "   'citizen',\n",
       "   'squandered']),\n",
       " (4,\n",
       "  ['martinez',\n",
       "   'ridgewood',\n",
       "   'queens',\n",
       "   'india',\n",
       "   'judiciary',\n",
       "   'clemens',\n",
       "   'musicals',\n",
       "   'certification',\n",
       "   'bushwick',\n",
       "   'brooklyn',\n",
       "   'barrier',\n",
       "   'broadway',\n",
       "   'wells',\n",
       "   'raines',\n",
       "   'edition',\n",
       "   'fray',\n",
       "   'makersvice',\n",
       "   'mandela',\n",
       "   'piercing',\n",
       "   'discontent',\n",
       "   'homer',\n",
       "   'productivity',\n",
       "   'howell',\n",
       "   'albright',\n",
       "   'dolls',\n",
       "   'nelson',\n",
       "   'wine',\n",
       "   'madeleine',\n",
       "   'jeff',\n",
       "   'replacing',\n",
       "   'bomb',\n",
       "   'unwillingness',\n",
       "   'bushehr',\n",
       "   'reinvigorated',\n",
       "   'toronto',\n",
       "   'harlem',\n",
       "   'lieberman',\n",
       "   'characters',\n",
       "   'ubiquitous',\n",
       "   'jamaica',\n",
       "   'bushnell',\n",
       "   'walking',\n",
       "   'lighten',\n",
       "   'graeme',\n",
       "   'nuclear',\n",
       "   'freeing',\n",
       "   'atomic',\n",
       "   'sleeping',\n",
       "   'melrose',\n",
       "   'observer',\n",
       "   'branch',\n",
       "   'camden',\n",
       "   'theaters',\n",
       "   'duke',\n",
       "   'door',\n",
       "   'wyden',\n",
       "   'spiritual',\n",
       "   'shocked',\n",
       "   'japan',\n",
       "   'lloyd',\n",
       "   'antonetty',\n",
       "   'iranian',\n",
       "   'suspicion',\n",
       "   'nemesis',\n",
       "   'cooee',\n",
       "   'lumia',\n",
       "   'meantime',\n",
       "   'mr',\n",
       "   'rows',\n",
       "   'housing',\n",
       "   'reactor',\n",
       "   'upholding',\n",
       "   'misconduct',\n",
       "   'drastically',\n",
       "   'donation',\n",
       "   'convention',\n",
       "   'stealth',\n",
       "   'gotten',\n",
       "   'recorded',\n",
       "   'african',\n",
       "   'bolton',\n",
       "   'acceptable',\n",
       "   'borders',\n",
       "   'garde',\n",
       "   'reporting',\n",
       "   'section',\n",
       "   'offices',\n",
       "   'tickets',\n",
       "   'squabble',\n",
       "   'pakistan',\n",
       "   'souvenir',\n",
       "   'courteously',\n",
       "   'plopped',\n",
       "   'practiced',\n",
       "   'jenkins',\n",
       "   'armor',\n",
       "   'ii',\n",
       "   'stardom',\n",
       "   'renewing',\n",
       "   'preserved']),\n",
       " (5,\n",
       "  ['mcginn',\n",
       "   'surname',\n",
       "   'misspelled',\n",
       "   'gail',\n",
       "   'reprieve',\n",
       "   'dow',\n",
       "   'dna',\n",
       "   'wilensky',\n",
       "   'ricky',\n",
       "   'misidentified',\n",
       "   'ian',\n",
       "   'requested',\n",
       "   'favorably',\n",
       "   'inmate',\n",
       "   'correctness',\n",
       "   'playbook',\n",
       "   'execution',\n",
       "   'waging',\n",
       "   'stepdaughter',\n",
       "   'torricelli',\n",
       "   'depict',\n",
       "   'scored',\n",
       "   'programming',\n",
       "   'boards',\n",
       "   'unwelcome',\n",
       "   'grist',\n",
       "   'raping',\n",
       "   'positives',\n",
       "   'nolen',\n",
       "   'joyful',\n",
       "   'unfavorably',\n",
       "   'pirates',\n",
       "   'passes',\n",
       "   'patton',\n",
       "   'lyndon',\n",
       "   'weeklong',\n",
       "   'correctly',\n",
       "   'mr',\n",
       "   'reminds',\n",
       "   'initials',\n",
       "   'endowment',\n",
       "   'beans',\n",
       "   'grandmother',\n",
       "   'discourse',\n",
       "   'rangel',\n",
       "   'strangely',\n",
       "   'citizen',\n",
       "   'dividing',\n",
       "   'baron',\n",
       "   'wyly',\n",
       "   'levin',\n",
       "   'debated',\n",
       "   'nerve',\n",
       "   'senatorial',\n",
       "   'floyd',\n",
       "   'gentle',\n",
       "   'imperative',\n",
       "   'chagrin',\n",
       "   'rises',\n",
       "   'fist',\n",
       "   'supportvice',\n",
       "   'humanities',\n",
       "   'hits',\n",
       "   'pm',\n",
       "   'roadless',\n",
       "   'repertory',\n",
       "   'murder',\n",
       "   'artistic',\n",
       "   'herbert',\n",
       "   'markedly',\n",
       "   'lazy',\n",
       "   'gore',\n",
       "   'iron',\n",
       "   'fondly',\n",
       "   'health',\n",
       "   'codey',\n",
       "   'essex',\n",
       "   'restoring',\n",
       "   'pigeon',\n",
       "   'rooftops',\n",
       "   'bush',\n",
       "   'peek',\n",
       "   'giblin',\n",
       "   'said',\n",
       "   'clinton',\n",
       "   'ballet',\n",
       "   'fracture',\n",
       "   'tests',\n",
       "   'medicare',\n",
       "   'beloved',\n",
       "   'adviser',\n",
       "   'equate',\n",
       "   'nonexistent',\n",
       "   'defects',\n",
       "   'cavalier',\n",
       "   'negatives',\n",
       "   'absentee',\n",
       "   'devers',\n",
       "   'ratings',\n",
       "   'kanchanalak']),\n",
       " (6,\n",
       "  ['vidal',\n",
       "   'glamorous',\n",
       "   'atlantic',\n",
       "   'friedman',\n",
       "   'revival',\n",
       "   'quotation',\n",
       "   'bipartisanship',\n",
       "   'theater',\n",
       "   'overlooked',\n",
       "   'goldsmith',\n",
       "   'caption',\n",
       "   'assembly',\n",
       "   'actively',\n",
       "   'rats',\n",
       "   'imprecisely',\n",
       "   'envisions',\n",
       "   'indianapolis',\n",
       "   'satire',\n",
       "   'murky',\n",
       "   'societies',\n",
       "   'marginal',\n",
       "   'safire',\n",
       "   'producers',\n",
       "   'spur',\n",
       "   'digital',\n",
       "   'broadway',\n",
       "   'geraldine',\n",
       "   'ferraro',\n",
       "   'scenario',\n",
       "   'tutorial',\n",
       "   'allen',\n",
       "   'continuation',\n",
       "   'essay',\n",
       "   'montgomery',\n",
       "   'annoying',\n",
       "   'puzzlement',\n",
       "   'divisive',\n",
       "   'letting',\n",
       "   'economist',\n",
       "   'careers',\n",
       "   'dismal',\n",
       "   'mathematical',\n",
       "   'gorence',\n",
       "   'motive',\n",
       "   'constituents',\n",
       "   'polish',\n",
       "   'locally',\n",
       "   'canal',\n",
       "   'cream',\n",
       "   'cultures',\n",
       "   'dread',\n",
       "   'eszterhas',\n",
       "   'libraries',\n",
       "   'hamada',\n",
       "   'government',\n",
       "   'marvin',\n",
       "   'zoo',\n",
       "   'abm',\n",
       "   'mr',\n",
       "   'film',\n",
       "   'democracy',\n",
       "   'chaos',\n",
       "   'backlog',\n",
       "   'trent',\n",
       "   'imagination',\n",
       "   'travels',\n",
       "   'reveal',\n",
       "   'moore',\n",
       "   'jill',\n",
       "   'patriotic',\n",
       "   'schiff',\n",
       "   'deployment',\n",
       "   'ignited',\n",
       "   'brooks',\n",
       "   'mills',\n",
       "   'assailed',\n",
       "   'strange',\n",
       "   'humiliated',\n",
       "   'panama',\n",
       "   'gore',\n",
       "   'characters',\n",
       "   'farbrother',\n",
       "   'karmack',\n",
       "   'moratorium',\n",
       "   'said',\n",
       "   'beer',\n",
       "   'un',\n",
       "   'european',\n",
       "   'windy',\n",
       "   'ryan',\n",
       "   'vanishing',\n",
       "   'psychologists',\n",
       "   'peculiar',\n",
       "   'wilderness',\n",
       "   'citizenship',\n",
       "   'trifecta',\n",
       "   'missile',\n",
       "   'republican',\n",
       "   'lee',\n",
       "   'startled']),\n",
       " (7,\n",
       "  ['string',\n",
       "   'var',\n",
       "   'else',\n",
       "   'pat',\n",
       "   'lieberman',\n",
       "   'nader',\n",
       "   'buchanan',\n",
       "   'ralph',\n",
       "   'gore',\n",
       "   'sept',\n",
       "   'costs',\n",
       "   'bush',\n",
       "   'nbc',\n",
       "   'green',\n",
       "   'party',\n",
       "   'wealthiest',\n",
       "   'cbs',\n",
       "   'uninsured',\n",
       "   'reform',\n",
       "   'roe',\n",
       "   'mr',\n",
       "   'voucher',\n",
       "   'debater',\n",
       "   'medicare',\n",
       "   'survey',\n",
       "   'poll',\n",
       "   'held',\n",
       "   'kiss',\n",
       "   'candidates',\n",
       "   'vote',\n",
       "   'wade',\n",
       "   'care',\n",
       "   'york',\n",
       "   'health',\n",
       "   'would',\n",
       "   'choose',\n",
       "   'news',\n",
       "   'democrat',\n",
       "   'muslim',\n",
       "   'times',\n",
       "   'insurance',\n",
       "   'bushwick',\n",
       "   'bosses',\n",
       "   'per',\n",
       "   'liberals',\n",
       "   'minimum',\n",
       "   'accomplished',\n",
       "   'new',\n",
       "   'today',\n",
       "   'recorded',\n",
       "   'video',\n",
       "   'op',\n",
       "   'election',\n",
       "   'focusing',\n",
       "   'candidate',\n",
       "   'misleading',\n",
       "   'ed',\n",
       "   'tax',\n",
       "   'plan',\n",
       "   'al',\n",
       "   'institution',\n",
       "   'sounded',\n",
       "   'finish',\n",
       "   'heavy',\n",
       "   'reproductive',\n",
       "   'brooklyn',\n",
       "   'hot',\n",
       "   'direction',\n",
       "   'humanitarian',\n",
       "   'clinton',\n",
       "   'basis',\n",
       "   'weakening',\n",
       "   'republican',\n",
       "   'premiums',\n",
       "   'wall',\n",
       "   'mckinnon',\n",
       "   'arab',\n",
       "   'said',\n",
       "   'locked',\n",
       "   'sites',\n",
       "   'maintenance',\n",
       "   'brookings',\n",
       "   'joseph',\n",
       "   'beneficiaries',\n",
       "   'jesus',\n",
       "   'profiling',\n",
       "   'alternatives',\n",
       "   'effectiveness',\n",
       "   'accomplishments',\n",
       "   'bay',\n",
       "   'safety',\n",
       "   'program',\n",
       "   'medicaid',\n",
       "   'pundits',\n",
       "   'coverage',\n",
       "   'nationwide',\n",
       "   'collins',\n",
       "   'disagreed',\n",
       "   'aug',\n",
       "   'achievement']),\n",
       " (8,\n",
       "  ['bushnell',\n",
       "   'candace',\n",
       "   'blondes',\n",
       "   'milosevic',\n",
       "   'sex',\n",
       "   'monthly',\n",
       "   'author',\n",
       "   'manhattan',\n",
       "   'love',\n",
       "   'carnahan',\n",
       "   'lives',\n",
       "   'city',\n",
       "   'seen',\n",
       "   'leno',\n",
       "   'four',\n",
       "   'women',\n",
       "   'shrinking',\n",
       "   'dumping',\n",
       "   'hypothetical',\n",
       "   'cookies',\n",
       "   'constituents',\n",
       "   'hartford',\n",
       "   'lest',\n",
       "   'recipes',\n",
       "   'serbia',\n",
       "   'concerts',\n",
       "   'squad',\n",
       "   'letterman',\n",
       "   'hook',\n",
       "   'petition',\n",
       "   'inspections',\n",
       "   'sweet',\n",
       "   'columnist',\n",
       "   'twist',\n",
       "   'hbo',\n",
       "   'photography',\n",
       "   'brokered',\n",
       "   'japanese',\n",
       "   'columns',\n",
       "   'rated',\n",
       "   'sandy',\n",
       "   'cleansing',\n",
       "   'dump',\n",
       "   'crash',\n",
       "   'hussein',\n",
       "   'nostalgic',\n",
       "   'impartial',\n",
       "   'timlin',\n",
       "   'mud',\n",
       "   'andrea',\n",
       "   'readers',\n",
       "   'gate',\n",
       "   'rapaille',\n",
       "   'mr',\n",
       "   'bishop',\n",
       "   'inauguration',\n",
       "   'efficiency',\n",
       "   'keyes',\n",
       "   'nato',\n",
       "   'cynthia',\n",
       "   'hagelin',\n",
       "   'bushido',\n",
       "   'europe',\n",
       "   'pregame',\n",
       "   'rabbi',\n",
       "   'embassies',\n",
       "   'rats',\n",
       "   'dell',\n",
       "   'freeze',\n",
       "   'entertainment',\n",
       "   'tours',\n",
       "   'britain',\n",
       "   'netanyahu',\n",
       "   'unseat',\n",
       "   'cotton',\n",
       "   'attributes',\n",
       "   'goren',\n",
       "   'slowly',\n",
       "   'repression',\n",
       "   'indicted',\n",
       "   'inspires',\n",
       "   'happening',\n",
       "   'said',\n",
       "   'internship',\n",
       "   'gingerly',\n",
       "   'unmarried',\n",
       "   'absurd',\n",
       "   'leaden',\n",
       "   'wayward',\n",
       "   'mccain',\n",
       "   'mayor',\n",
       "   'park',\n",
       "   'surest',\n",
       "   'material',\n",
       "   'nice',\n",
       "   'hardest',\n",
       "   'quarterback',\n",
       "   'giovanni',\n",
       "   'saturday',\n",
       "   'ginger']),\n",
       " (9,\n",
       "  ['bat',\n",
       "   'madison',\n",
       "   'bauer',\n",
       "   'gorelick',\n",
       "   'hills',\n",
       "   'beverly',\n",
       "   'exhibited',\n",
       "   'ellis',\n",
       "   'lacks',\n",
       "   'resident',\n",
       "   'pardon',\n",
       "   'nail',\n",
       "   'playboy',\n",
       "   'rogers',\n",
       "   'stumbles',\n",
       "   'criner',\n",
       "   'curriculum',\n",
       "   'indian',\n",
       "   'premise',\n",
       "   'gail',\n",
       "   'gilmore',\n",
       "   'symphony',\n",
       "   'pine',\n",
       "   'laudable',\n",
       "   'italy',\n",
       "   'anthony',\n",
       "   'billboard',\n",
       "   'memorized',\n",
       "   'parole',\n",
       "   'charisma',\n",
       "   'currency',\n",
       "   'educate',\n",
       "   'rowland',\n",
       "   'strikes',\n",
       "   'indians',\n",
       "   'plainly',\n",
       "   'orlando',\n",
       "   'stone',\n",
       "   'hartford',\n",
       "   'hefner',\n",
       "   'corridor',\n",
       "   'reassure',\n",
       "   'hudson',\n",
       "   'privileges',\n",
       "   'arcadia',\n",
       "   'bushnell',\n",
       "   'desk',\n",
       "   'reveal',\n",
       "   'belies',\n",
       "   'machinations',\n",
       "   'charging',\n",
       "   'nick',\n",
       "   'heston',\n",
       "   'enterprises',\n",
       "   'tougher',\n",
       "   'bureaucrats',\n",
       "   'pitcher',\n",
       "   'mr',\n",
       "   'illustrates',\n",
       "   'cuomo',\n",
       "   'greenstein',\n",
       "   'mccall',\n",
       "   'pardons',\n",
       "   'ad',\n",
       "   'deserving',\n",
       "   'spiritual',\n",
       "   'urges',\n",
       "   'massacre',\n",
       "   'steven',\n",
       "   'deploying',\n",
       "   'bull',\n",
       "   'columbine',\n",
       "   'pleasant',\n",
       "   'directors',\n",
       "   'forbes',\n",
       "   'lucas',\n",
       "   'orchestra',\n",
       "   'users',\n",
       "   'discusses',\n",
       "   'lewis',\n",
       "   'blast',\n",
       "   'literature',\n",
       "   'pants',\n",
       "   'rhythmic',\n",
       "   'marriage',\n",
       "   'adequate',\n",
       "   'tailor',\n",
       "   'christie',\n",
       "   'pin',\n",
       "   'nd',\n",
       "   'energized',\n",
       "   'secrets',\n",
       "   'goldman',\n",
       "   'teeth',\n",
       "   'inmate',\n",
       "   'restaurants',\n",
       "   'anticipate',\n",
       "   'metaphor',\n",
       "   'manipulation',\n",
       "   'ads'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "def get_topics(lda_model, num_topics=-1, num_words=100, prob_thresh=0.8):\n",
    "    topics = []\n",
    "    for topic, topic_words in lda_model.print_topics(num_topics=num_topics, num_words=num_words):\n",
    "        words = topic_words.split(\" + \")\n",
    "        all_words = []\n",
    "        all_prob = 0\n",
    "        for elem in words:\n",
    "            prob, word = elem.split(\"*\")\n",
    "            all_prob += float(prob)\n",
    "            all_words.append(word.split('\"')[1])\n",
    "\n",
    "            if all_prob >= prob_thresh:\n",
    "                break\n",
    "        topics.append((topic, all_words))\n",
    "\n",
    "    return topics\n",
    "topics = get_topics(lda_model, prob_thresh=0.3)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002*\"gorey\" + 0.000*\"intervention\" + 0.000*\"bushwick\" + 0.000*\"wrongful\" + 0.000*\"stuyvesant\" + 0.000*\"bedford\" + 0.000*\"predicting\" + 0.000*\"insults\" + 0.000*\"derby\" + 0.000*\"monetary\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006*\"mr\" + 0.003*\"gore\" + 0.003*\"said\" + 0.003*\"bush\" + 0.003*\"debate\" + 0.002*\"campaign\" + 0.002*\"would\" + 0.002*\"clinton\" + 0.002*\"tax\" + 0.002*\"president\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003*\"heating\" + 0.003*\"barrels\" + 0.002*\"supply\" + 0.002*\"petroleum\" + 0.001*\"carbon\" + 0.001*\"lieberman\" + 0.001*\"reserves\" + 0.001*\"coal\" + 0.001*\"tame\" + 0.001*\"kelly\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002*\"sanctions\" + 0.002*\"franks\" + 0.001*\"letterman\" + 0.001*\"miller\" + 0.001*\"upstate\" + 0.001*\"location\" + 0.001*\"corzine\" + 0.001*\"fires\" + 0.001*\"nelson\" + 0.001*\"reserves\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001*\"martinez\" + 0.001*\"ridgewood\" + 0.001*\"queens\" + 0.001*\"india\" + 0.001*\"judiciary\" + 0.001*\"clemens\" + 0.000*\"musicals\" + 0.000*\"certification\" + 0.000*\"bushwick\" + 0.000*\"brooklyn\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002*\"mcginn\" + 0.001*\"surname\" + 0.001*\"misspelled\" + 0.001*\"gail\" + 0.001*\"reprieve\" + 0.001*\"dow\" + 0.001*\"dna\" + 0.001*\"wilensky\" + 0.001*\"ricky\" + 0.001*\"misidentified\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.003*\"vidal\" + 0.002*\"glamorous\" + 0.002*\"atlantic\" + 0.001*\"friedman\" + 0.001*\"revival\" + 0.001*\"quotation\" + 0.001*\"bipartisanship\" + 0.001*\"theater\" + 0.001*\"overlooked\" + 0.001*\"goldsmith\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.016*\"string\" + 0.014*\"var\" + 0.008*\"else\" + 0.003*\"pat\" + 0.003*\"lieberman\" + 0.003*\"nader\" + 0.003*\"buchanan\" + 0.002*\"ralph\" + 0.002*\"gore\" + 0.002*\"sept\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005*\"bushnell\" + 0.003*\"candace\" + 0.002*\"blondes\" + 0.002*\"milosevic\" + 0.002*\"sex\" + 0.002*\"monthly\" + 0.002*\"author\" + 0.001*\"manhattan\" + 0.001*\"love\" + 0.001*\"carnahan\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.001*\"bat\" + 0.001*\"madison\" + 0.001*\"bauer\" + 0.001*\"gorelick\" + 0.001*\"hills\" + 0.001*\"beverly\" + 0.001*\"exhibited\" + 0.001*\"ellis\" + 0.001*\"lacks\" + 0.001*\"resident\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  0   \n",
       "1  1   \n",
       "2  2   \n",
       "3  3   \n",
       "4  4   \n",
       "5  5   \n",
       "6  6   \n",
       "7  7   \n",
       "8  8   \n",
       "9  9   \n",
       "\n",
       "                                                                                                                                                                                                   1  \n",
       "0        0.002*\"gorey\" + 0.000*\"intervention\" + 0.000*\"bushwick\" + 0.000*\"wrongful\" + 0.000*\"stuyvesant\" + 0.000*\"bedford\" + 0.000*\"predicting\" + 0.000*\"insults\" + 0.000*\"derby\" + 0.000*\"monetary\"  \n",
       "1                                    0.006*\"mr\" + 0.003*\"gore\" + 0.003*\"said\" + 0.003*\"bush\" + 0.003*\"debate\" + 0.002*\"campaign\" + 0.002*\"would\" + 0.002*\"clinton\" + 0.002*\"tax\" + 0.002*\"president\"  \n",
       "2                       0.003*\"heating\" + 0.003*\"barrels\" + 0.002*\"supply\" + 0.002*\"petroleum\" + 0.001*\"carbon\" + 0.001*\"lieberman\" + 0.001*\"reserves\" + 0.001*\"coal\" + 0.001*\"tame\" + 0.001*\"kelly\"  \n",
       "3                 0.002*\"sanctions\" + 0.002*\"franks\" + 0.001*\"letterman\" + 0.001*\"miller\" + 0.001*\"upstate\" + 0.001*\"location\" + 0.001*\"corzine\" + 0.001*\"fires\" + 0.001*\"nelson\" + 0.001*\"reserves\"  \n",
       "4       0.001*\"martinez\" + 0.001*\"ridgewood\" + 0.001*\"queens\" + 0.001*\"india\" + 0.001*\"judiciary\" + 0.001*\"clemens\" + 0.000*\"musicals\" + 0.000*\"certification\" + 0.000*\"bushwick\" + 0.000*\"brooklyn\"  \n",
       "5                     0.002*\"mcginn\" + 0.001*\"surname\" + 0.001*\"misspelled\" + 0.001*\"gail\" + 0.001*\"reprieve\" + 0.001*\"dow\" + 0.001*\"dna\" + 0.001*\"wilensky\" + 0.001*\"ricky\" + 0.001*\"misidentified\"  \n",
       "6  0.003*\"vidal\" + 0.002*\"glamorous\" + 0.002*\"atlantic\" + 0.001*\"friedman\" + 0.001*\"revival\" + 0.001*\"quotation\" + 0.001*\"bipartisanship\" + 0.001*\"theater\" + 0.001*\"overlooked\" + 0.001*\"goldsmith\"  \n",
       "7                                     0.016*\"string\" + 0.014*\"var\" + 0.008*\"else\" + 0.003*\"pat\" + 0.003*\"lieberman\" + 0.003*\"nader\" + 0.003*\"buchanan\" + 0.002*\"ralph\" + 0.002*\"gore\" + 0.002*\"sept\"  \n",
       "8                    0.005*\"bushnell\" + 0.003*\"candace\" + 0.002*\"blondes\" + 0.002*\"milosevic\" + 0.002*\"sex\" + 0.002*\"monthly\" + 0.002*\"author\" + 0.001*\"manhattan\" + 0.001*\"love\" + 0.001*\"carnahan\"  \n",
       "9                          0.001*\"bat\" + 0.001*\"madison\" + 0.001*\"bauer\" + 0.001*\"gorelick\" + 0.001*\"hills\" + 0.001*\"beverly\" + 0.001*\"exhibited\" + 0.001*\"ellis\" + 0.001*\"lacks\" + 0.001*\"resident\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "display(pd.DataFrame(lda_model.print_topics()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.97512877)]\n",
      "[(1, 0.8761766), (7, 0.115408726)]\n",
      "[(1, 0.99818856)]\n",
      "[(1, 0.98162955), (7, 0.017368853)]\n",
      "[(1, 0.9553608), (3, 0.021237914), (7, 0.020965328)]\n",
      "[(1, 0.9356058), (7, 0.055053487)]\n",
      "[(1, 0.9701896), (7, 0.012223703), (8, 0.01579854)]\n",
      "[(1, 0.9935671)]\n",
      "[(1, 0.95881176), (7, 0.018327104), (9, 0.019884065)]\n",
      "[(1, 0.97860914)]\n"
     ]
    }
   ],
   "source": [
    "document_topics = lda_model.get_document_topics(corpus)\n",
    "date_doc_topics = list(zip(nytimes[\"Date\"], lda_model.get_document_topics(corpus)))\n",
    "for l in document_topics[:10]:\n",
    "    print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for any given day, you look at all the diff topics and identify the prob of that topic\n",
    "# should I normalize? Paper doesn't seem to normalize...\n",
    "date_topic_prob = np.zeros((len(unique_dates), k))\n",
    "for date, article in date_doc_topics:\n",
    "    i = unique_dates.index(date)\n",
    "    for topic, prob in article:\n",
    "        date_topic_prob[i][topic] += prob \n",
    "\n",
    "# Figure out how to normalize [reread paper/rewatch lecture]\n",
    "# date_topic_prob = date_topic_prob/date_topic_prob.max(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.291009</td>\n",
       "      <td>0.209941</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376509</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.359794</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.109103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114625</td>\n",
       "      <td>2000-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.681651</td>\n",
       "      <td>0.134054</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382118</td>\n",
       "      <td>1.227326</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>2000-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.104755</td>\n",
       "      <td>16.353308</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>0.511124</td>\n",
       "      <td>0.574773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111492</td>\n",
       "      <td>2000-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.959853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.917017</td>\n",
       "      <td>0.082861</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.463583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>2000-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>65.868831</td>\n",
       "      <td>0.150507</td>\n",
       "      <td>0.262732</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700213</td>\n",
       "      <td>3.704698</td>\n",
       "      <td>1.635098</td>\n",
       "      <td>0.433084</td>\n",
       "      <td>2000-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.511357</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.047213</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>9.893672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133887</td>\n",
       "      <td>2000-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.429348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130364</td>\n",
       "      <td>24.906475</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.237854</td>\n",
       "      <td>2000-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.964572</td>\n",
       "      <td>0.057285</td>\n",
       "      <td>0.292954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231476</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>14.977522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>2000-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1         2         3         4         5  \\\n",
       "2000-05-01  0.000000  11.291009  0.209941  0.011937  0.000000  0.000000   \n",
       "2000-05-02  0.000000   8.359794  0.027041  0.109103  0.000000  0.000000   \n",
       "2000-05-03  0.000000  27.681651  0.134054  0.392987  0.000000  0.000000   \n",
       "2000-05-04  0.104755  16.353308  0.078732  0.025968  0.000000  0.040312   \n",
       "2000-05-05  0.000000  24.959853  0.000000  0.000000  0.000000  0.000000   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "2000-10-28  0.000000  27.917017  0.082861  0.144940  0.014141  0.000000   \n",
       "2000-10-29  0.137953  65.868831  0.150507  0.262732  0.126084  0.000000   \n",
       "2000-10-30  0.000000  22.511357  0.030421  0.047213  0.040909  0.000000   \n",
       "2000-10-31  0.000000  67.429348  0.000000  0.334038  0.000000  0.000000   \n",
       "2000-11-01  0.000000  32.964572  0.057285  0.292954  0.000000  0.231476   \n",
       "\n",
       "                   6          7         8         9        Date  \n",
       "2000-05-01  0.000000   0.376509  0.015799  0.000000  2000-05-01  \n",
       "2000-05-02  0.000000   0.273454  0.000000  0.114625  2000-05-02  \n",
       "2000-05-03  1.382118   1.227326  0.055857  0.784119  2000-05-03  \n",
       "2000-05-04  0.511124   0.574773  0.000000  0.111492  2000-05-04  \n",
       "2000-05-05  0.000000   0.825362  0.000000  0.000000  2000-05-05  \n",
       "...              ...        ...       ...       ...         ...  \n",
       "2000-10-28  0.000000  15.463583  0.000000  0.032488  2000-10-28  \n",
       "2000-10-29  0.700213   3.704698  1.635098  0.433084  2000-10-29  \n",
       "2000-10-30  0.030712   9.893672  0.000000  0.133887  2000-10-30  \n",
       "2000-10-31  0.130364  24.906475  0.054707  0.237854  2000-10-31  \n",
       "2000-11-01  0.019349  14.977522  0.000000  0.038005  2000-11-01  \n",
       "\n",
       "[185 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_topic = pd.DataFrame(date_topic_prob, index=unique_dates)\n",
    "date_topic[\"Date\"] = unique_dates\n",
    "date_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.291009</td>\n",
       "      <td>0.209941</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376509</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.359794</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.109103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114625</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.681651</td>\n",
       "      <td>0.134054</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382118</td>\n",
       "      <td>1.227326</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.104755</td>\n",
       "      <td>16.353308</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>0.511124</td>\n",
       "      <td>0.574773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111492</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.959853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-27</th>\n",
       "      <td>0.115797</td>\n",
       "      <td>67.148907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349068</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.193153</td>\n",
       "      <td>0.271317</td>\n",
       "      <td>24.210089</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.196642</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.917017</td>\n",
       "      <td>0.082861</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.463583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>65.868831</td>\n",
       "      <td>0.150507</td>\n",
       "      <td>0.262732</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700213</td>\n",
       "      <td>3.704698</td>\n",
       "      <td>1.635098</td>\n",
       "      <td>0.433084</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.511357</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.047213</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>9.893672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133887</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.429348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130364</td>\n",
       "      <td>24.906475</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.237854</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1         2         3         4         5  \\\n",
       "Date                                                                      \n",
       "2000-05-01  0.000000  11.291009  0.209941  0.011937  0.000000  0.000000   \n",
       "2000-05-02  0.000000   8.359794  0.027041  0.109103  0.000000  0.000000   \n",
       "2000-05-03  0.000000  27.681651  0.134054  0.392987  0.000000  0.000000   \n",
       "2000-05-04  0.104755  16.353308  0.078732  0.025968  0.000000  0.040312   \n",
       "2000-05-05  0.000000  24.959853  0.000000  0.000000  0.000000  0.000000   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "2000-10-27  0.115797  67.148907  0.000000  0.349068  0.221768  0.193153   \n",
       "2000-10-28  0.000000  27.917017  0.082861  0.144940  0.014141  0.000000   \n",
       "2000-10-29  0.137953  65.868831  0.150507  0.262732  0.126084  0.000000   \n",
       "2000-10-30  0.000000  22.511357  0.030421  0.047213  0.040909  0.000000   \n",
       "2000-10-31  0.000000  67.429348  0.000000  0.334038  0.000000  0.000000   \n",
       "\n",
       "                   6          7         8         9  LastPrice  \n",
       "Date                                                            \n",
       "2000-05-01  0.000000   0.376509  0.015799  0.000000   0.523810  \n",
       "2000-05-02  0.000000   0.273454  0.000000  0.114625   0.504970  \n",
       "2000-05-03  1.382118   1.227326  0.055857  0.784119   0.509491  \n",
       "2000-05-04  0.511124   0.574773  0.000000  0.111492   0.511466  \n",
       "2000-05-05  0.000000   0.825362  0.000000  0.000000   0.520875  \n",
       "...              ...        ...       ...       ...        ...  \n",
       "2000-10-27  0.271317  24.210089  0.202570  0.196642   0.384310  \n",
       "2000-10-28  0.000000  15.463583  0.000000  0.032488   0.296488  \n",
       "2000-10-29  0.700213   3.704698  1.635098  0.433084   0.345703  \n",
       "2000-10-30  0.030712   9.893672  0.000000  0.133887   0.380711  \n",
       "2000-10-31  0.130364  24.906475  0.054707  0.237854   0.381966  \n",
       "\n",
       "[182 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_topic_prices = date_topic.set_index('Date').join(stock_prices.set_index('Date')).dropna()\n",
    "date_topic_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.3601</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.6692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.4340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5669</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3582</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.7078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5174</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.3112</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1       2       3       4       5       6       7  \\\n",
       "0          1.0000  0.0218  0.3601  0.1663  0.5077  0.0637  0.1733  0.4518   \n",
       "1          0.0259  1.0000  0.0038  0.0090  0.0138  0.0362  0.0002  0.0197   \n",
       "2          0.3061  0.0217  1.0000  0.1437  0.2862  0.7057  0.1844  0.1384   \n",
       "3          0.1269  0.0335  0.2073  1.0000  0.5669  0.7322  0.0006  0.5505   \n",
       "4          0.1769  0.0459  0.1006  0.0608  1.0000  0.2151  0.0307  0.2922   \n",
       "5          0.0162  0.2134  0.1650  0.0101  0.2922  1.0000  0.0006  0.2404   \n",
       "6          0.3582  0.0001  0.1267  0.0439  0.0797  0.2238  1.0000  0.0400   \n",
       "7          0.6616  0.0000  0.0048  0.0002  0.0563  0.0399  0.0011  1.0000   \n",
       "8          0.5174  0.0030  0.0572  0.2310  0.7419  0.0551  0.2700  0.0112   \n",
       "9          0.4426  0.0058  0.0056  0.0608  0.2126  0.3692  0.0018  0.1294   \n",
       "LastPrice  0.3023  0.4895  0.7579  0.3112  0.3749  0.5260  0.1711  0.1175   \n",
       "\n",
       "                8       9  LastPrice  \n",
       "0          0.6023  0.0005     0.6692  \n",
       "1          0.0431  0.0830     0.4340  \n",
       "2          0.3022  0.3477     0.0986  \n",
       "3          0.3216  0.0750     0.1788  \n",
       "4          0.1340  0.5107     0.0173  \n",
       "5          0.6789  0.0895     0.0339  \n",
       "6          0.1066  0.1110     0.7078  \n",
       "7          0.0121  0.0001     0.3730  \n",
       "8          1.0000  0.1759     0.7080  \n",
       "9          0.0095  1.0000     0.0778  \n",
       "LastPrice  0.2661  0.0085     1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9  LastPrice\n",
       "0          0.0  0.0  0.0  1.0  4.0  1.0  0.0  2.0  4.0  1.0        2.0\n",
       "1          0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  3.0  0.0        2.0\n",
       "2          0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  1.0  3.0        2.0\n",
       "3          0.0  1.0  3.0  0.0  0.0  3.0  3.0  1.0  0.0  3.0        0.0\n",
       "4          2.0  0.0  0.0  0.0  0.0  4.0  3.0  1.0  0.0  0.0        0.0\n",
       "5          0.0  0.0  3.0  4.0  2.0  0.0  3.0  0.0  0.0  1.0        0.0\n",
       "6          0.0  1.0  0.0  1.0  1.0  0.0  0.0  2.0  0.0  0.0        2.0\n",
       "7          0.0  1.0  2.0  2.0  0.0  0.0  2.0  0.0  2.0  2.0        0.0\n",
       "8          0.0  3.0  3.0  0.0  3.0  4.0  0.0  1.0  0.0  3.0        3.0\n",
       "9          0.0  1.0  3.0  0.0  0.0  0.0  3.0  3.0  1.0  0.0        2.0\n",
       "LastPrice  0.0  0.0  0.0  0.0  1.0  4.0  3.0  0.0  1.0  3.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/58005681/is-it-possible-to-run-a-vector-autoregression-analysis-on-a-large-gdp-data-with\n",
    "def grangers_causality_matrix(data, variables, maxlag=5, test='ssr_ftest', verbose=False):\n",
    "    dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    lags    = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in dataset.columns:\n",
    "        for r in dataset.index:            \n",
    "            test_result = grangercausalitytests(data[[r,c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4) for i in range(maxlag)]\n",
    "            \n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "\n",
    "            min_p_value_i = np.argmin(p_values)\n",
    "            min_p_value = p_values[min_p_value_i]\n",
    "            dataset.loc[r, c] = min_p_value\n",
    "            \n",
    "            lags.loc[r, c] = min_p_value_i\n",
    "    \n",
    "    return dataset, lags\n",
    "\n",
    "# grangers_causality_matrix(dataset, variables = dataset.columns)\n",
    "c, l = grangers_causality_matrix(date_topic_prices, variables=date_topic_prices.columns, verbose=False)\n",
    "display(c)\n",
    "display(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4, 5, 9], [-0.0, -0.0, 3.0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_causal_vars(data, significance=0.95, getLags=False, getCausalSig=False, verbose=False):\n",
    "    cols = data.columns[:-1]\n",
    "    causal_vars = []\n",
    "    causal_lags = []\n",
    "    \n",
    "#     i = 0\n",
    "    for col in cols:\n",
    "        try:\n",
    "            gc, lags = grangers_causality_matrix(data[[col, 'LastPrice']], \n",
    "                                             variables=[col, 'LastPrice'], \n",
    "                                             verbose=False)\n",
    "        except:\n",
    "            raise Exception(data[[col, 'LastPrice']])\n",
    "        \n",
    "        gc = 1 - gc\n",
    "#         if i < 10:\n",
    "#             display(gc)\n",
    "#             i += 1\n",
    "        \n",
    "        col_causes = gc.loc['LastPrice', col] >= significance\n",
    "        col_causedBy = gc.loc[col, 'LastPrice'] >= significance\n",
    "        if col_causes or col_causedBy:\n",
    "            if getCausalSig:\n",
    "                causal_vars.append((col, max(gc.loc['LastPrice', col], gc.loc[col, 'LastPrice'])))\n",
    "            else:\n",
    "                causal_vars.append(col)\n",
    "            \n",
    "            if getLags:\n",
    "                # if sig. granger causality for topic causing ts and ts causing topic, choose whichever is higher\n",
    "                if col_causes and col_causedBy:\n",
    "                    if gc.loc['LastPrice', col] >= gc.loc[col, 'LastPrice']:\n",
    "                        causal_lags.append(lags.loc['LastPrice', col])\n",
    "                    else:\n",
    "                        causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "                elif col_causes:\n",
    "                    causal_lags.append(lags.loc['LastPrice', col])\n",
    "                else:\n",
    "                    causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "    if getLags:\n",
    "        return causal_vars, causal_lags\n",
    "    return causal_vars\n",
    "                \n",
    "causal_topics, ct_lags = get_causal_vars(date_topic_prices, getLags=True)\n",
    "causal_topics, ct_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section\n",
      "CPU times: user 71.4 ms, sys: 10.2 ms, total: 81.6 ms\n",
      "Wall time: 69.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "              section  iranian  broadway  homer  cooee  dolls  antonetty  \\\n",
       "  2000-05-01    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-05-02    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-05-03    0.001    0.001     0.001  2.000  0.001  0.001      0.001   \n",
       "  2000-05-04    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-05-05    2.000    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  ...             ...      ...       ...    ...    ...    ...        ...   \n",
       "  2000-10-28    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-10-29    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-10-30    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  2000-10-31    0.001    0.001     2.000  0.001  0.001  0.001      0.001   \n",
       "  2000-11-01    0.001    0.001     0.001  0.001  0.001  0.001      0.001   \n",
       "  \n",
       "              reinvigorated  armor  clemens  ...  productivity  housing  \\\n",
       "  2000-05-01          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-05-02          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-05-03          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-05-04          0.001  0.001    0.001  ...         0.001    1.000   \n",
       "  2000-05-05          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  ...                   ...    ...      ...  ...           ...      ...   \n",
       "  2000-10-28          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-10-29          0.001  0.001    0.001  ...         2.000    0.001   \n",
       "  2000-10-30          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-10-31          0.001  0.001    0.001  ...         0.001    0.001   \n",
       "  2000-11-01          0.001  0.001    0.001  ...         1.000    0.001   \n",
       "  \n",
       "              spiritual  acceptable  howell  raines  jenkins  queens  musicals  \\\n",
       "  2000-05-01      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-05-02      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-05-03      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-05-04      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-05-05      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  ...               ...         ...     ...     ...      ...     ...       ...   \n",
       "  2000-10-28      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-10-29      0.001       0.001   0.001   0.001    0.001   2.000     0.001   \n",
       "  2000-10-30      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-10-31      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  2000-11-01      0.001       0.001   0.001   0.001    0.001   0.001     0.001   \n",
       "  \n",
       "              squabble  \n",
       "  2000-05-01     0.001  \n",
       "  2000-05-02     0.001  \n",
       "  2000-05-03     0.001  \n",
       "  2000-05-04     0.001  \n",
       "  2000-05-05     0.001  \n",
       "  ...              ...  \n",
       "  2000-10-28     0.001  \n",
       "  2000-10-29     0.001  \n",
       "  2000-10-30     0.001  \n",
       "  2000-10-31     0.001  \n",
       "  2000-11-01     0.001  \n",
       "  \n",
       "  [185 rows x 100 columns]),\n",
       " (5,\n",
       "              weeklong   hits  surname  strangely   peek  unwelcome  playbook  \\\n",
       "  2000-05-01     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-05-02     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-05-03     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-05-04     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-05-05     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  ...              ...    ...      ...        ...    ...        ...       ...   \n",
       "  2000-10-28     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-10-29     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-10-30     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-10-31     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  2000-11-01     0.001  0.001    0.001      0.001  0.001      0.001     0.001   \n",
       "  \n",
       "              kanchanalak  ricky  requested  ...  baron  nonexistent  \\\n",
       "  2000-05-01        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-05-02        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-05-03        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-05-04        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-05-05        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  ...                 ...    ...        ...  ...    ...          ...   \n",
       "  2000-10-28        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-10-29        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-10-30        0.001  0.001      0.001  ...  0.001        1.000   \n",
       "  2000-10-31        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  2000-11-01        0.001  0.001      0.001  ...  0.001        0.001   \n",
       "  \n",
       "              misidentified  favorably  correctness  joyful    ian  initials  \\\n",
       "  2000-05-01          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-05-02          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-05-03          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-05-04          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-05-05          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  ...                   ...        ...          ...     ...    ...       ...   \n",
       "  2000-10-28          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-10-29          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-10-30          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-10-31          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  2000-11-01          0.001      0.001        0.001   0.001  0.001     0.001   \n",
       "  \n",
       "               wyly  reminds  \n",
       "  2000-05-01  0.001    0.001  \n",
       "  2000-05-02  0.001    0.001  \n",
       "  2000-05-03  0.001    0.001  \n",
       "  2000-05-04  1.000    0.001  \n",
       "  2000-05-05  0.001    0.001  \n",
       "  ...           ...      ...  \n",
       "  2000-10-28  0.001    0.001  \n",
       "  2000-10-29  0.001    0.001  \n",
       "  2000-10-30  0.001    0.001  \n",
       "  2000-10-31  0.001    0.001  \n",
       "  2000-11-01  0.001    2.000  \n",
       "  \n",
       "  [185 rows x 100 columns]),\n",
       " (9,\n",
       "              pants  indian  restaurants  pitcher  enterprises  manipulation  \\\n",
       "  2000-05-01  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-05-02  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-05-03  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-05-04  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-05-05  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  ...           ...     ...          ...      ...          ...           ...   \n",
       "  2000-10-28  1.000   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-10-29  0.001   0.001        2.000    0.001        0.001         0.001   \n",
       "  2000-10-30  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  2000-10-31  0.001   0.001        0.001    0.001        2.000         0.001   \n",
       "  2000-11-01  0.001   0.001        0.001    0.001        0.001         0.001   \n",
       "  \n",
       "              rogers  urges  teeth    ads  ...  spiritual  christie  parole  \\\n",
       "  2000-05-01   0.001  0.001  0.001  1.000  ...      0.001     0.001   0.001   \n",
       "  2000-05-02   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  2000-05-03   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  2000-05-04   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  2000-05-05   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  ...            ...    ...    ...    ...  ...        ...       ...     ...   \n",
       "  2000-10-28   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  2000-10-29   0.001  2.000  0.001  4.000  ...      0.001     2.000   0.001   \n",
       "  2000-10-30   0.001  0.001  0.001  1.000  ...      0.001     0.001   0.001   \n",
       "  2000-10-31   0.001  0.001  0.001  0.001  ...      0.001     0.001   0.001   \n",
       "  2000-11-01   0.001  0.001  0.001  2.000  ...      0.001     0.001   0.001   \n",
       "  \n",
       "              secrets  stumbles    pin  ellis  privileges  tailor  goldman  \n",
       "  2000-05-01    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-05-02    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-05-03    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-05-04    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-05-05    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  ...             ...       ...    ...    ...         ...     ...      ...  \n",
       "  2000-10-28    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-10-29    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-10-30    0.001     0.001  0.001  0.001       0.001   1.000    0.001  \n",
       "  2000-10-31    2.000     2.000  0.001  0.001       0.001   0.001    0.001  \n",
       "  2000-11-01    0.001     0.001  0.001  0.001       0.001   0.001    0.001  \n",
       "  \n",
       "  [185 rows x 100 columns])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def get_word_stream(nytimes, topics, causal_topics):\n",
    "    ct_ws = []\n",
    "    first = True\n",
    "    for ct in causal_topics:\n",
    "        causal_vocab = list(set(topics[ct][1]))\n",
    "        date_terms = pd.DataFrame(np.zeros((len(unique_dates), len(causal_vocab))), index=unique_dates, columns=causal_vocab)\n",
    "\n",
    "        \n",
    "        for word in causal_vocab:\n",
    "            if first:\n",
    "                first = False\n",
    "                print (word)\n",
    "            date_terms[word] = date_term_cnts[word]\n",
    "            \n",
    "        ct_ws.append((ct, date_terms))\n",
    "    \n",
    "    return ct_ws\n",
    "\n",
    "ct_ws = get_word_stream(nytimes, topics, causal_topics)\n",
    "ct_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 5, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/home/jagaskak/.local/lib/python3.8/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 s, sys: 46.9 ms, total: 16.9 s\n",
      "Wall time: 16.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  [('iranian', 0.9678),\n",
       "   ('cooee', 0.9824),\n",
       "   ('graeme', 0.9812),\n",
       "   ('observer', 0.9857),\n",
       "   ('duke', 0.9518),\n",
       "   ('jamaica', 0.9513),\n",
       "   ('rows', 0.9998),\n",
       "   ('drastically', 0.9887),\n",
       "   ('branch', 0.9919),\n",
       "   ('certification', 0.9859),\n",
       "   ('nuclear', 0.9947),\n",
       "   ('donation', 0.9675),\n",
       "   ('stealth', 0.9806),\n",
       "   ('lloyd', 0.9805),\n",
       "   ('wyden', 0.9894),\n",
       "   ('bushehr', 0.9844),\n",
       "   ('wells', 0.9956),\n",
       "   ('lumia', 0.9824),\n",
       "   ('squabble', 0.9645)],\n",
       "  [('dolls', 1.0),\n",
       "   ('reinvigorated', 0.9949),\n",
       "   ('armor', 0.9811),\n",
       "   ('makersvice', 0.9746),\n",
       "   ('atomic', 1.0),\n",
       "   ('reporting', 0.9973),\n",
       "   ('plopped', 0.982),\n",
       "   ('bushwick', 0.9804),\n",
       "   ('souvenir', 0.982),\n",
       "   ('stardom', 0.9648),\n",
       "   ('walking', 0.9691),\n",
       "   ('courteously', 0.982),\n",
       "   ('sleeping', 0.9903),\n",
       "   ('judiciary', 0.9976),\n",
       "   ('queens', 0.9765)]),\n",
       " (5,\n",
       "  [('hits', 0.9706),\n",
       "   ('unwelcome', 0.9881),\n",
       "   ('kanchanalak', 0.9999),\n",
       "   ('medicare', 0.9951),\n",
       "   ('raping', 0.9624),\n",
       "   ('absentee', 0.9732),\n",
       "   ('chagrin', 0.9835),\n",
       "   ('dna', 0.9756),\n",
       "   ('baron', 0.9986)],\n",
       "  [('rangel', 0.9763),\n",
       "   ('beans', 0.9996),\n",
       "   ('defects', 0.9908),\n",
       "   ('roadless', 0.9917),\n",
       "   ('giblin', 0.9572),\n",
       "   ('inmate', 0.9589),\n",
       "   ('codey', 0.9975),\n",
       "   ('devers', 0.9996),\n",
       "   ('essex', 0.9975),\n",
       "   ('cavalier', 0.9954),\n",
       "   ('nerve', 0.9919),\n",
       "   ('fracture', 0.9922),\n",
       "   ('execution', 0.992),\n",
       "   ('fist', 0.965),\n",
       "   ('iron', 0.9577),\n",
       "   ('supportvice', 0.9982),\n",
       "   ('initials', 0.9938)]),\n",
       " (9,\n",
       "  [('urges', 0.9967),\n",
       "   ('pardons', 0.9658),\n",
       "   ('columbine', 0.9671),\n",
       "   ('nd', 0.9662),\n",
       "   ('users', 0.9717),\n",
       "   ('parole', 0.9588)],\n",
       "  [('restaurants', 0.9662),\n",
       "   ('lucas', 0.9986),\n",
       "   ('inmate', 0.9589),\n",
       "   ('cuomo', 0.9814),\n",
       "   ('pine', 0.9786),\n",
       "   ('laudable', 0.9603)])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def get_impact_words(topic_wordstream, significance=0.95, verbose=False):\n",
    "    topic_impact_words = []\n",
    "    \n",
    "    first = True\n",
    "    for topic, ws in topic_wordstream:\n",
    "        ws_prices = ws.join(stock_prices.set_index('Date')).dropna()        \n",
    "        ws_gc = get_causal_vars(ws_prices, significance=significance, getCausalSig=True, verbose=verbose)\n",
    "        \n",
    "#         if first:\n",
    "#             display(ws_gc)\n",
    "#             first = False\n",
    "        \n",
    "        pos = []\n",
    "        neg = []\n",
    "        for word, sig in ws_gc:                \n",
    "            corr = pearsonr(ws_prices[word], stock_prices['LastPrice'])[0]\n",
    "            if corr > 0:\n",
    "                pos.append((word, sig))\n",
    "            else:\n",
    "                neg.append((word, sig))\n",
    "                \n",
    "        topic_impact_words.append((topic, pos, neg))\n",
    "    \n",
    "    return topic_impact_words\n",
    "        \n",
    "\n",
    "impact_words = get_impact_words(ct_ws)\n",
    "impact_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# ws_prices = ct_ws.join(stock_prices.set_index('Date')).dropna()\n",
    "# ws_impact, ws_lags = grangers_causality_matrix(ws_prices, variables=ws_prices.columns, verbose=False)\n",
    "\n",
    "# display(ws_prices)\n",
    "# display(ws_impact)\n",
    "# display(ws_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def calculate_purity(pWords, nWords):\n",
    "    n = float(len(pWords) + len(nWords))\n",
    "    pProb = len(pWords)/n\n",
    "    nProb = len(nWords)/n\n",
    "        \n",
    "    entropy = pProb * np.log2(pProb) + nProb * np.log2(nProb)\n",
    "    purity = 100 + 100 * entropy\n",
    "    return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0007208442481357"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_purity(impact_words[0][1], impact_words[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " [('iranian', 0.9678),\n",
       "  ('cooee', 0.9824),\n",
       "  ('graeme', 0.9812),\n",
       "  ('observer', 0.9857),\n",
       "  ('duke', 0.9518),\n",
       "  ('jamaica', 0.9513),\n",
       "  ('rows', 0.9998),\n",
       "  ('drastically', 0.9887),\n",
       "  ('branch', 0.9919),\n",
       "  ('certification', 0.9859),\n",
       "  ('nuclear', 0.9947),\n",
       "  ('donation', 0.9675),\n",
       "  ('stealth', 0.9806),\n",
       "  ('lloyd', 0.9805),\n",
       "  ('wyden', 0.9894),\n",
       "  ('bushehr', 0.9844),\n",
       "  ('wells', 0.9956),\n",
       "  ('lumia', 0.9824),\n",
       "  ('squabble', 0.9645)],\n",
       " [('dolls', 1.0),\n",
       "  ('reinvigorated', 0.9949),\n",
       "  ('armor', 0.9811),\n",
       "  ('makersvice', 0.9746),\n",
       "  ('atomic', 1.0),\n",
       "  ('reporting', 0.9973),\n",
       "  ('plopped', 0.982),\n",
       "  ('bushwick', 0.9804),\n",
       "  ('souvenir', 0.982),\n",
       "  ('stardom', 0.9648),\n",
       "  ('walking', 0.9691),\n",
       "  ('courteously', 0.982),\n",
       "  ('sleeping', 0.9903),\n",
       "  ('judiciary', 0.9976),\n",
       "  ('queens', 0.9765)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def construct_prior(impact_words, curr_k, sig=0.95):\n",
    "    # find number of topics that we are splitting\n",
    "    new_k = curr_k + len(impact_words)\n",
    "    word_priors = np.zeros((new_k, date_term_cnts.shape[1])) + 0.01\n",
    "\n",
    "    i = 0\n",
    "    for num, pos, neg in impact_words:\n",
    "        print (i)\n",
    "        pos_denom = sum([granger-sig for word, granger in pos])\n",
    "        neg_denom = sum([granger-sig for word, granger in neg])\n",
    "        \n",
    "        if len(pos) < 0.1 * len(neg):\n",
    "            # num neg words >> num pos\n",
    "            for word, granger in pos:              \n",
    "                word_priors[i, id2word.token2id[word]] = 0\n",
    "            for word, granger in neg:\n",
    "                word_priors[i, id2word.token2id[word]] = (granger-sig)/neg_denom \n",
    "            \n",
    "        elif len(neg) < 0.1 * len(pos):\n",
    "            # num pos words >> num neg\n",
    "            for word, granger in pos:              \n",
    "                word_priors[i, id2word.token2id[word]] = (granger-sig)/pos_denom \n",
    "            for word, granger in neg:\n",
    "                word_priors[i, id2word.token2id[word]] = 0\n",
    "            \n",
    "\n",
    "        for word, granger in pos:              \n",
    "            word_priors[i, id2word.token2id[word]] = (granger-sig)/pos_denom \n",
    "        \n",
    "        for word, granger in neg:\n",
    "            word_priors[i + 1, id2word.token2id[word]] = (granger-sig)/neg_denom \n",
    "        \n",
    "        i += 2\n",
    "    return word_priors\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       ...,\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, ..., 0.01, 0.01, 0.01]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_priors = construct_prior(impact_words, 10)\n",
    "word_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.002256552681826204,\n",
       " 0.003124457559451519,\n",
       " 0.01,\n",
       " 0.025169241451137022,\n",
       " 0.03037667071688949,\n",
       " 0.03089741364346468,\n",
       " 0.052942197535150184,\n",
       " 0.05311577851067525,\n",
       " 0.054157264363825626,\n",
       " 0.056240236070126765,\n",
       " 0.05971185558062841,\n",
       " 0.06196840826245442,\n",
       " 0.06231557021350455,\n",
       " 0.06717583752820688,\n",
       " 0.06839090435688233,\n",
       " 0.07273042874500948,\n",
       " 0.07759069605971182,\n",
       " 0.07915292483943759,\n",
       " 0.086443325811491}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(word_priors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
