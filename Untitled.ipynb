{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/patsy/constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases # TODO: to create bigrams with\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# stop_words.extend(['mr', 'ms', 'said'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# def lemmatize(content, tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "#     texts_out = []\n",
    "#     for sent in texts:\n",
    "#         doc = nlp(\" \".join(sent)) \n",
    "#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "#     return texts_out\n",
    "\n",
    "# Tokenize and remove stop words from content\n",
    "def tokenize(content, lemmatize=False):\n",
    "    words = gensim.utils.simple_preprocess(content, deacc=True)  # tokenizes\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(content):\n",
    "    words = []\n",
    "    for word in content:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not lemmatizing or stemming. If we need to increase accuracy in the future, we can consider it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[two, years, ago, homer, bush, came, yankee, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>[texas, record, tell, op, ed, april, paul, bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>[top, foreign, policy, adviser, gov, george, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[aides, gov, george, bush, fought, back, today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>[gov, tommy, thompson, wisconsin, named, chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[new, york, times, cbs, news, poll, var, strin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>[tick, tock, diner, ted, friedrich, stockbroke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[difference, us, vital, issue, would, go, wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[bush, administration, wanted, overturn, would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>[first, gov, jeb, bush, florida, told, hallowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                            Content\n",
       "0     2000-05-03  [two, years, ago, homer, bush, came, yankee, b...\n",
       "1     2000-05-02  [texas, record, tell, op, ed, april, paul, bur...\n",
       "2     2000-05-01  [top, foreign, policy, adviser, gov, george, b...\n",
       "3     2000-05-03  [aides, gov, george, bush, fought, back, today...\n",
       "4     2000-05-03  [gov, tommy, thompson, wisconsin, named, chair...\n",
       "...          ...                                                ...\n",
       "5801  2000-10-31  [new, york, times, cbs, news, poll, var, strin...\n",
       "5802  2000-10-31  [tick, tock, diner, ted, friedrich, stockbroke...\n",
       "5803  2000-11-01  [difference, us, vital, issue, would, go, wash...\n",
       "5804  2000-11-01  [bush, administration, wanted, overturn, would...\n",
       "5805  2000-11-01  [first, gov, jeb, bush, florida, told, hallowe...\n",
       "\n",
       "[5806 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New York Times Data\n",
    "rows = []\n",
    "dates = []\n",
    "articles = []\n",
    "for month in range(5, 11):\n",
    "    with open(\"Data/NYTimes/\"+ str(month) + \".txt\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            date, article = line.split(\",\", 1)\n",
    "            timestamp = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "            tokenized = tokenize(article)\n",
    "            destopped = remove_stopwords(tokenized)\n",
    "\n",
    "            articles.append(destopped)\n",
    "            dates.append(timestamp)\n",
    "            rows.append([timestamp, destopped])\n",
    "\n",
    "nytimes = pd.DataFrame(rows, columns=[\"Date\", \"Content\"]) \n",
    "unique_dates = sorted(list(set(nytimes[\"Date\"])))\n",
    "# print (unique_dates)\n",
    "nytimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 days missing from the stock market data: 6/07, 6/08, 11/01. There are several ways we can deal with this. \n",
    "1. Toss out the three days from the NYTimes data\n",
    "2. Condense 6/07 --> 6/06; 6/08 --> 6/09 (or something similar) and toss out 11/01. \n",
    "3. Something else that I can't think of at the moment\n",
    "\n",
    "I also haven't looked at the paper to see how they deal with it yet.\n",
    "\n",
    "Edit: Reading over some articles about time series, it seems that we should pad the missing datapoints with previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-04</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-05</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  LastPrice\n",
       "0    2000-05-01   0.523810\n",
       "1    2000-05-02   0.504970\n",
       "2    2000-05-03   0.509491\n",
       "3    2000-05-04   0.511466\n",
       "4    2000-05-05   0.520875\n",
       "..          ...        ...\n",
       "177  2000-10-27   0.384310\n",
       "178  2000-10-28   0.296488\n",
       "179  2000-10-29   0.345703\n",
       "180  2000-10-30   0.380711\n",
       "181  2000-10-31   0.381966\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Series Data\n",
    "ts_months = [\"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\"]\n",
    "cols = ['Date', 'LastPrice']\n",
    "stock_prices = pd.DataFrame()\n",
    "for month in ts_months:\n",
    "    ts_df = pd.read_csv(\"Data/PriceHistory/\" + month + \".txt\", delim_whitespace=True)\n",
    "    ts_df['Date'] =  ts_df['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%y\").date())\n",
    "    \n",
    "    Gore = ts_df.loc[ts_df['Contract'] == 'Dem'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "    Bush = ts_df.loc[ts_df['Contract'] == 'Rep'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "\n",
    "    # Gore/(Gore + Bush)\n",
    "    relation = list(zip(Gore['Date'], (Gore['LastPrice']/(Gore['LastPrice'] + Bush['LastPrice'])).fillna(0)))\n",
    "    stock_prices = stock_prices.append(relation, ignore_index=True)\n",
    "\n",
    "stock_prices.columns = cols\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(unique_dates)):\n",
    "#     if unique_dates[i] not in list(stock_prices[0]):\n",
    "#         print (unique_dates[i])\n",
    "\n",
    "# bigram = Phrases(articles, min_count=1)\n",
    "# bigrams = [b for b in bigram[articles]]\n",
    "# articles = bigrams\n",
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-91-5488d17a90b0>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  doc_word_cnts = (np.array([np.array([(id2word[id], freq) for id, freq in cp]) for cp in corpus]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('ago', 0.07712049873418031),\n",
       "  ('awesome', 0.23220574510227418),\n",
       "  ('backup', 0.2198823985449398),\n",
       "  ('backups', 0.2515408271170864),\n",
       "  ('bases', 0.19264069440348208),\n",
       "  ('bellinger', 0.27548950382241366),\n",
       "  ('bench', 0.1896343958919212),\n",
       "  ('bush', 0.007894722475376273),\n",
       "  ('came', 0.08612993720379283),\n",
       "  ('catcher', 0.26148042600790294),\n",
       "  ('clay', 0.2135830725972484),\n",
       "  ('games', 0.1562902360625982),\n",
       "  ('girardi', 0.27548950382241366),\n",
       "  ('homer', 0.21658937110880933),\n",
       "  ('jim', 0.1245222966630543),\n",
       "  ('joe', 0.1146922085996351),\n",
       "  ('leyritz', 0.27548950382241366),\n",
       "  ('speed', 0.17969479700110466),\n",
       "  ('stole', 0.20587332073042908),\n",
       "  ('strength', 0.13402729061444735),\n",
       "  ('turner', 0.2108175460504276),\n",
       "  ('two', 0.04788545375938528),\n",
       "  ('versatility', 0.27548950382241366),\n",
       "  ('whose', 0.0887458288821732),\n",
       "  ('yankee', 0.20825706839694694),\n",
       "  ('yankees', 0.19264069440348208),\n",
       "  ('years', 0.05159983565074285)]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(articles)\n",
    "\n",
    "# Attempt at filtering out words that appear too frequently\n",
    "# id2word.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "# id2word.filter_extremes(no_above=0.5)\n",
    "\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in articles]\n",
    "doc_word_cnts = (np.array([np.array([(id2word[id], freq) for id, freq in cp]) for cp in corpus]))\n",
    "\n",
    "# TF-IDF seems to give better coherence (but it wasn't in the paper...)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in tfidf_corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.051365068593375\n",
      "\n",
      "Coherence Score:  0.35735223993332144\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "k = 10\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "#                                            minimum_phi_value=0.5, # min threshold for word probabilities\n",
    "                                           passes=2,\n",
    "                                           alpha='auto',  # assuming that topic distribution is assymetric. Not all topics equally represented in corpus.\n",
    "                                           eta='auto',\n",
    "                                           update_every=1, # online or batch processing (everything is on disk, so use online)\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=articles, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts:\n",
    "\n",
    "We need to de-pluralize the words (governments vs government).\n",
    "Get the coherence score above 50 would be a good start probably.\n",
    "\n",
    "Need to extend stop words to include mr.\n",
    "\n",
    "But topic coherency is still very low\n",
    "\n",
    "Also, we can double check our topic coherence by comparing with Wikipedia (and other checks the paper did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ['kiss',\n",
       "   'simon',\n",
       "   'arthritis',\n",
       "   'puzzlement',\n",
       "   'minimize',\n",
       "   'clemens',\n",
       "   'anthony',\n",
       "   'disconcerting',\n",
       "   'casey',\n",
       "   'flash',\n",
       "   'inexperienced',\n",
       "   'medicine',\n",
       "   'cherished',\n",
       "   'diary',\n",
       "   'bigotry',\n",
       "   'ethics',\n",
       "   'spells',\n",
       "   'clark',\n",
       "   'pledges',\n",
       "   'navy',\n",
       "   'import',\n",
       "   'worthy',\n",
       "   'wells',\n",
       "   'salt',\n",
       "   'lieberman',\n",
       "   'pryor',\n",
       "   'homer',\n",
       "   'teams',\n",
       "   'manufacturer',\n",
       "   'wooing',\n",
       "   'glass',\n",
       "   'claritin',\n",
       "   'eliot',\n",
       "   'persuasion',\n",
       "   'stained',\n",
       "   'abm',\n",
       "   'performances',\n",
       "   'uncertainty',\n",
       "   'lent',\n",
       "   'canal',\n",
       "   'lovers',\n",
       "   'cleansing',\n",
       "   'techniques',\n",
       "   'diane',\n",
       "   'shiloh',\n",
       "   'negotiators',\n",
       "   'page',\n",
       "   'schering',\n",
       "   'upset',\n",
       "   'accepts',\n",
       "   'plough',\n",
       "   'front',\n",
       "   'humans',\n",
       "   'aug',\n",
       "   'evaluate',\n",
       "   'toronto',\n",
       "   'mr',\n",
       "   'medication',\n",
       "   'dissolved',\n",
       "   'governorship',\n",
       "   'deepest',\n",
       "   'raiservice',\n",
       "   'pet',\n",
       "   'jews',\n",
       "   'treaty',\n",
       "   'beans',\n",
       "   'menu',\n",
       "   'lodine',\n",
       "   'identity',\n",
       "   'restaurant',\n",
       "   'delayed',\n",
       "   'torricelli',\n",
       "   'embassies',\n",
       "   'convention',\n",
       "   'immigrant',\n",
       "   'speculation',\n",
       "   'graeme',\n",
       "   'recapture',\n",
       "   'andrea',\n",
       "   'negotiating',\n",
       "   'panama',\n",
       "   'woolsey',\n",
       "   'gentle',\n",
       "   'glorious',\n",
       "   'compares',\n",
       "   'generosity',\n",
       "   'carrier',\n",
       "   'laboratories',\n",
       "   'lloyd',\n",
       "   'said',\n",
       "   'ratified',\n",
       "   'coffin',\n",
       "   'redesign',\n",
       "   'sizzle',\n",
       "   'legendary',\n",
       "   'fated',\n",
       "   'renews',\n",
       "   'kicking',\n",
       "   'willey',\n",
       "   'antonetty']),\n",
       " (1,\n",
       "  ['kyoto',\n",
       "   'jesus',\n",
       "   'biting',\n",
       "   'terminal',\n",
       "   'allen',\n",
       "   'philosopher',\n",
       "   'buildings',\n",
       "   'waterfront',\n",
       "   'juries',\n",
       "   'humiliated',\n",
       "   'ore',\n",
       "   'ignited',\n",
       "   'rearing',\n",
       "   'internship',\n",
       "   'mr',\n",
       "   'restoring',\n",
       "   'birch',\n",
       "   'cardinal',\n",
       "   'misconduct',\n",
       "   'refers',\n",
       "   'sunset',\n",
       "   'russell',\n",
       "   'vanquishers',\n",
       "   'mumble',\n",
       "   'drip',\n",
       "   'intravenous',\n",
       "   'technicians',\n",
       "   'demps',\n",
       "   'dignity',\n",
       "   'immune',\n",
       "   'backups',\n",
       "   'misperceptions',\n",
       "   'chieftains',\n",
       "   'gurney',\n",
       "   'strapped',\n",
       "   'norcross',\n",
       "   'pipe',\n",
       "   'token',\n",
       "   'applauded',\n",
       "   'paperwork',\n",
       "   'mccain',\n",
       "   'education',\n",
       "   'centerpiece',\n",
       "   'cheney',\n",
       "   'said',\n",
       "   'security',\n",
       "   'alternate',\n",
       "   'fabricant',\n",
       "   'nguyen',\n",
       "   'gorevitz',\n",
       "   'emilia',\n",
       "   'divisional',\n",
       "   'pageant',\n",
       "   'indecipherable',\n",
       "   'insulin',\n",
       "   'invariable',\n",
       "   'catherine',\n",
       "   'vein',\n",
       "   'barneys',\n",
       "   'merchandise',\n",
       "   'bite',\n",
       "   'rye',\n",
       "   'delayed',\n",
       "   'bout',\n",
       "   'bush',\n",
       "   'gore',\n",
       "   'levy',\n",
       "   'manufactured',\n",
       "   'republican',\n",
       "   'incoherent',\n",
       "   'governor',\n",
       "   'julie',\n",
       "   'disturbing',\n",
       "   'social',\n",
       "   'vice',\n",
       "   'president',\n",
       "   'bernstein',\n",
       "   'tall',\n",
       "   'manager',\n",
       "   'allusion',\n",
       "   'departing',\n",
       "   'gown',\n",
       "   'refashion',\n",
       "   'seniority',\n",
       "   'poles',\n",
       "   'jacket',\n",
       "   'cost',\n",
       "   'unenergetically',\n",
       "   'brook',\n",
       "   'afforded',\n",
       "   'consciences',\n",
       "   'collagen',\n",
       "   'would',\n",
       "   'clinton',\n",
       "   'mourners',\n",
       "   'evil',\n",
       "   'lisa',\n",
       "   'launched',\n",
       "   'heartland',\n",
       "   'abortion']),\n",
       " (2,\n",
       "  ['mr',\n",
       "   'said',\n",
       "   'gore',\n",
       "   'tax',\n",
       "   'would',\n",
       "   'plan',\n",
       "   'bush',\n",
       "   'oil',\n",
       "   'campaign',\n",
       "   'debate',\n",
       "   'texas',\n",
       "   'clinton',\n",
       "   'president',\n",
       "   'governor',\n",
       "   'security',\n",
       "   'social',\n",
       "   'government',\n",
       "   'health',\n",
       "   'people',\n",
       "   'drug',\n",
       "   'states',\n",
       "   'money',\n",
       "   'state',\n",
       "   'vice',\n",
       "   'medicare',\n",
       "   'today',\n",
       "   'gov',\n",
       "   'federal',\n",
       "   'years',\n",
       "   'new',\n",
       "   'one',\n",
       "   'cut',\n",
       "   'administration',\n",
       "   'care',\n",
       "   'proposal',\n",
       "   'presidential',\n",
       "   'year',\n",
       "   'education',\n",
       "   'spending',\n",
       "   'republican',\n",
       "   'military',\n",
       "   'lazio',\n",
       "   'also',\n",
       "   'al',\n",
       "   'cheney',\n",
       "   'million',\n",
       "   'policy',\n",
       "   'democratic',\n",
       "   'children',\n",
       "   'national',\n",
       "   'page',\n",
       "   'prescription',\n",
       "   'issue',\n",
       "   'george',\n",
       "   'florida',\n",
       "   'much',\n",
       "   'last',\n",
       "   'say',\n",
       "   'could',\n",
       "   'cuts',\n",
       "   'billion',\n",
       "   'nation',\n",
       "   'election',\n",
       "   'republicans',\n",
       "   'big',\n",
       "   'two',\n",
       "   'economic',\n",
       "   'percent',\n",
       "   'american',\n",
       "   'environmental',\n",
       "   'proposed',\n",
       "   'trillion',\n",
       "   'many',\n",
       "   'system',\n",
       "   'democrats',\n",
       "   'first',\n",
       "   'opponent',\n",
       "   'proposals',\n",
       "   'families',\n",
       "   'income',\n",
       "   'plans',\n",
       "   'issues',\n",
       "   'like',\n",
       "   'pay',\n",
       "   'budget',\n",
       "   'get',\n",
       "   'made',\n",
       "   'time',\n",
       "   'prices',\n",
       "   'program',\n",
       "   'next',\n",
       "   'surplus',\n",
       "   'week',\n",
       "   'called',\n",
       "   'make',\n",
       "   'house',\n",
       "   'washington',\n",
       "   'america',\n",
       "   'bill',\n",
       "   'insurance']),\n",
       " (3,\n",
       "  ['mcginn',\n",
       "   'muslim',\n",
       "   'reprieve',\n",
       "   'dna',\n",
       "   'execution',\n",
       "   'surname',\n",
       "   'inmate',\n",
       "   'dow',\n",
       "   'evasions',\n",
       "   'misspelled',\n",
       "   'misstated',\n",
       "   'ricky',\n",
       "   'embarrass',\n",
       "   'pardons',\n",
       "   'krugman',\n",
       "   'orlando',\n",
       "   'testing',\n",
       "   'pardon',\n",
       "   'murder',\n",
       "   'criner',\n",
       "   'martinez',\n",
       "   'miami',\n",
       "   'rob',\n",
       "   'convicted',\n",
       "   'glenn',\n",
       "   'montgomery',\n",
       "   'sponsors',\n",
       "   'tests',\n",
       "   'archer',\n",
       "   'gilmore',\n",
       "   'rogers',\n",
       "   'evidence',\n",
       "   'squad',\n",
       "   'chart',\n",
       "   'generals',\n",
       "   'stepdaughter',\n",
       "   'paroles',\n",
       "   'thin',\n",
       "   'norman',\n",
       "   'observation',\n",
       "   'murdering',\n",
       "   'location',\n",
       "   'mr',\n",
       "   'affirmative',\n",
       "   'singer',\n",
       "   'parole',\n",
       "   'page',\n",
       "   'maneuver',\n",
       "   'grist',\n",
       "   'las',\n",
       "   'derby',\n",
       "   'vegas',\n",
       "   'patricof',\n",
       "   'rape',\n",
       "   'cheerleading',\n",
       "   'front',\n",
       "   'killer',\n",
       "   'nolen',\n",
       "   'dylan',\n",
       "   'clemency',\n",
       "   'freed',\n",
       "   'case',\n",
       "   'raping',\n",
       "   'depict',\n",
       "   'denounced',\n",
       "   'cheney',\n",
       "   'authority',\n",
       "   'awaits',\n",
       "   'mcauliffe',\n",
       "   'article',\n",
       "   'admissions',\n",
       "   'graham',\n",
       "   'texas',\n",
       "   'sanford',\n",
       "   'june',\n",
       "   'secondary',\n",
       "   'board',\n",
       "   'executed',\n",
       "   'schwarzkopf',\n",
       "   'bush',\n",
       "   'system',\n",
       "   'latin',\n",
       "   'altered',\n",
       "   'enrollment',\n",
       "   'bullock',\n",
       "   'governor',\n",
       "   'harding',\n",
       "   'shortfall',\n",
       "   'clinton',\n",
       "   'tax',\n",
       "   'adjustments',\n",
       "   'iii',\n",
       "   'assault',\n",
       "   'exhaustive',\n",
       "   'fans',\n",
       "   'british',\n",
       "   'roy',\n",
       "   'said',\n",
       "   'gov',\n",
       "   'sentenced']),\n",
       " (4,\n",
       "  ['haass',\n",
       "   'location',\n",
       "   'goldsmith',\n",
       "   'upstate',\n",
       "   'prescribed',\n",
       "   'awarded',\n",
       "   'leone',\n",
       "   'holbrooke',\n",
       "   'chronicle',\n",
       "   'india',\n",
       "   'taylor',\n",
       "   'certification',\n",
       "   'brookings',\n",
       "   'scholar',\n",
       "   'realities',\n",
       "   'bushwick',\n",
       "   'cutbacks',\n",
       "   'tally',\n",
       "   'williamsburg',\n",
       "   'contributor',\n",
       "   'riady',\n",
       "   'compiled',\n",
       "   'jeopardy',\n",
       "   'piercing',\n",
       "   'leak',\n",
       "   'computers',\n",
       "   'tatum',\n",
       "   'assembly',\n",
       "   'deploying',\n",
       "   'danforth',\n",
       "   'joyful',\n",
       "   'hospitalized',\n",
       "   'jeopardize',\n",
       "   'mr',\n",
       "   'lieberman',\n",
       "   'montana',\n",
       "   'pakistan',\n",
       "   'substantially',\n",
       "   'zoo',\n",
       "   'metal',\n",
       "   'pershing',\n",
       "   'teams',\n",
       "   'honda',\n",
       "   'iron',\n",
       "   'transformation',\n",
       "   'fist',\n",
       "   'reasoning',\n",
       "   'celebration',\n",
       "   'blocks',\n",
       "   'lockstep',\n",
       "   'hire',\n",
       "   'intellectualism',\n",
       "   'demonstrators',\n",
       "   'rated',\n",
       "   'writes',\n",
       "   'encountered',\n",
       "   'fowler',\n",
       "   'lucas',\n",
       "   'sierra',\n",
       "   'captan',\n",
       "   'yorker',\n",
       "   'stimulate',\n",
       "   'cartoons',\n",
       "   'sanctioned',\n",
       "   'southampton',\n",
       "   'carve',\n",
       "   'huang',\n",
       "   'progressively',\n",
       "   'convention',\n",
       "   'udall',\n",
       "   'hotly',\n",
       "   'quarterback',\n",
       "   'com',\n",
       "   'web',\n",
       "   'hegemony',\n",
       "   'recycling',\n",
       "   'drastically',\n",
       "   'distribution',\n",
       "   'said',\n",
       "   'wrongdoing',\n",
       "   'resistance',\n",
       "   'adlai',\n",
       "   'biltmore',\n",
       "   'stone',\n",
       "   'president',\n",
       "   'users',\n",
       "   'cheney',\n",
       "   'bush',\n",
       "   'choose',\n",
       "   'fondly',\n",
       "   'giovanni',\n",
       "   'attraction',\n",
       "   'prevail',\n",
       "   'gore',\n",
       "   'workshop',\n",
       "   'communism',\n",
       "   'policy',\n",
       "   'highest',\n",
       "   'republican',\n",
       "   'clinton']),\n",
       " (5,\n",
       "  ['bushwick',\n",
       "   'gail',\n",
       "   'corzine',\n",
       "   'brooklyn',\n",
       "   'diner',\n",
       "   'quincy',\n",
       "   'ridgewood',\n",
       "   'detective',\n",
       "   'mccollum',\n",
       "   'adams',\n",
       "   'des',\n",
       "   'border',\n",
       "   'dee',\n",
       "   'queens',\n",
       "   'framing',\n",
       "   'jonathan',\n",
       "   'moines',\n",
       "   'laudable',\n",
       "   'trash',\n",
       "   'outlining',\n",
       "   'eligibility',\n",
       "   'stuyvesant',\n",
       "   'bedford',\n",
       "   'enrolled',\n",
       "   'sits',\n",
       "   'discourse',\n",
       "   'gorecki',\n",
       "   'henryk',\n",
       "   'staggering',\n",
       "   'contradiction',\n",
       "   'barbour',\n",
       "   'bids',\n",
       "   'neighborhoods',\n",
       "   'mr',\n",
       "   'dividend',\n",
       "   'irrelevant',\n",
       "   'nick',\n",
       "   'stores',\n",
       "   'bushehr',\n",
       "   'arcadia',\n",
       "   'clifton',\n",
       "   'gambling',\n",
       "   'lautenberg',\n",
       "   'siding',\n",
       "   'mack',\n",
       "   'medicine',\n",
       "   'fitzwater',\n",
       "   'seal',\n",
       "   'marlin',\n",
       "   'haul',\n",
       "   'dozens',\n",
       "   'consent',\n",
       "   'applauded',\n",
       "   'birthday',\n",
       "   'rosa',\n",
       "   'lag',\n",
       "   'fans',\n",
       "   'immigrant',\n",
       "   'florio',\n",
       "   'retiring',\n",
       "   'rowland',\n",
       "   'stripes',\n",
       "   'iranian',\n",
       "   'colombia',\n",
       "   'reiner',\n",
       "   'street',\n",
       "   'identity',\n",
       "   'pierce',\n",
       "   'experienced',\n",
       "   'lieberman',\n",
       "   'nigeria',\n",
       "   'plurality',\n",
       "   'aug',\n",
       "   'rutgers',\n",
       "   'page',\n",
       "   'weakened',\n",
       "   'gorbachev',\n",
       "   'ethical',\n",
       "   'boyer',\n",
       "   'weakness',\n",
       "   'eligible',\n",
       "   'communities',\n",
       "   'drug',\n",
       "   'front',\n",
       "   'immigrants',\n",
       "   'bomb',\n",
       "   'health',\n",
       "   'trader',\n",
       "   'chernobyl',\n",
       "   'insurance',\n",
       "   'schemes',\n",
       "   'gore',\n",
       "   'podesta',\n",
       "   'haley',\n",
       "   'coke',\n",
       "   'jamaica',\n",
       "   'altar',\n",
       "   'dewey',\n",
       "   'bought',\n",
       "   'pledges']),\n",
       " (6,\n",
       "  ['gorey',\n",
       "   'bosses',\n",
       "   'rats',\n",
       "   'choose',\n",
       "   'geeks',\n",
       "   'cuomo',\n",
       "   'purely',\n",
       "   'entirety',\n",
       "   'candace',\n",
       "   'mccall',\n",
       "   'privileges',\n",
       "   'everglades',\n",
       "   'makersvice',\n",
       "   'plaintiffs',\n",
       "   'publicized',\n",
       "   'tutorial',\n",
       "   'sudden',\n",
       "   'peculiar',\n",
       "   'pac',\n",
       "   'mckinnon',\n",
       "   'enforcing',\n",
       "   'quartet',\n",
       "   'kenny',\n",
       "   'nonexistent',\n",
       "   'peek',\n",
       "   'safire',\n",
       "   'bushnell',\n",
       "   'melrose',\n",
       "   'sept',\n",
       "   'imports',\n",
       "   'tolerant',\n",
       "   'mr',\n",
       "   'whittier',\n",
       "   'racicot',\n",
       "   'deprived',\n",
       "   'renewal',\n",
       "   'episcopal',\n",
       "   'gore',\n",
       "   'diner',\n",
       "   'bush',\n",
       "   'foreigners',\n",
       "   'bushwick',\n",
       "   'cicchino',\n",
       "   'dose',\n",
       "   'copies',\n",
       "   'penn',\n",
       "   'absentee',\n",
       "   'oversight',\n",
       "   'underpaid',\n",
       "   'overworked',\n",
       "   'sex',\n",
       "   'photographer',\n",
       "   'purchases',\n",
       "   'trio',\n",
       "   'vest',\n",
       "   'positives',\n",
       "   'louis',\n",
       "   'formidable',\n",
       "   'housing',\n",
       "   'privacy',\n",
       "   'said',\n",
       "   'seen',\n",
       "   'paddling',\n",
       "   'criticizes',\n",
       "   'article',\n",
       "   'anthony',\n",
       "   'settlements',\n",
       "   'prosecution',\n",
       "   'industry',\n",
       "   'norm',\n",
       "   'hendrix',\n",
       "   'killing',\n",
       "   'pianist',\n",
       "   'founder',\n",
       "   'clinton',\n",
       "   'makers',\n",
       "   'newly',\n",
       "   'rat',\n",
       "   'chutzpah',\n",
       "   'gorelick',\n",
       "   'lurked',\n",
       "   'alarmingly',\n",
       "   'pedestrians',\n",
       "   'nostalgic',\n",
       "   'would',\n",
       "   'mute',\n",
       "   'horn',\n",
       "   'unqualified',\n",
       "   'kearny',\n",
       "   'residents',\n",
       "   'panel',\n",
       "   'convention',\n",
       "   'campaign',\n",
       "   'regents',\n",
       "   'governor',\n",
       "   'screams',\n",
       "   'perplexed',\n",
       "   'beaten',\n",
       "   'designation',\n",
       "   'analyst']),\n",
       " (7,\n",
       "  ['string',\n",
       "   'var',\n",
       "   'else',\n",
       "   'pat',\n",
       "   'buchanan',\n",
       "   'ralph',\n",
       "   'nader',\n",
       "   'gore',\n",
       "   'cbs',\n",
       "   'green',\n",
       "   'party',\n",
       "   'reform',\n",
       "   'held',\n",
       "   'democrat',\n",
       "   'poll',\n",
       "   'bush',\n",
       "   'glamorous',\n",
       "   'vote',\n",
       "   'york',\n",
       "   'times',\n",
       "   'candidates',\n",
       "   'news',\n",
       "   'atlantic',\n",
       "   'monthly',\n",
       "   'candidate',\n",
       "   'election',\n",
       "   'blondes',\n",
       "   'today',\n",
       "   'manhattan',\n",
       "   'bushnell',\n",
       "   'author',\n",
       "   'collins',\n",
       "   'bat',\n",
       "   'sex',\n",
       "   'lives',\n",
       "   'love',\n",
       "   'new',\n",
       "   'mckinnon',\n",
       "   'carnahan',\n",
       "   'republican',\n",
       "   'simpson',\n",
       "   'al',\n",
       "   'city',\n",
       "   'would',\n",
       "   'tame',\n",
       "   'columbia',\n",
       "   'george',\n",
       "   'mo',\n",
       "   'four',\n",
       "   'seen',\n",
       "   'profoundly',\n",
       "   'caption',\n",
       "   'games',\n",
       "   'women',\n",
       "   'conrad',\n",
       "   'latin',\n",
       "   'dumping',\n",
       "   'bureaucrats',\n",
       "   'reno',\n",
       "   'jordan',\n",
       "   'scamp',\n",
       "   'forged',\n",
       "   'sheen',\n",
       "   'murky',\n",
       "   'kiss',\n",
       "   'skirmishes',\n",
       "   'programming',\n",
       "   'informal',\n",
       "   'pine',\n",
       "   'mr',\n",
       "   'mason',\n",
       "   'bruce',\n",
       "   'reserved',\n",
       "   'dismissal',\n",
       "   'caliber',\n",
       "   'replacing',\n",
       "   'prose',\n",
       "   'movies',\n",
       "   'pitcher',\n",
       "   'alienate',\n",
       "   'clinton',\n",
       "   'brokered',\n",
       "   'legally',\n",
       "   'sandy',\n",
       "   'mud',\n",
       "   'investigate',\n",
       "   'headlined',\n",
       "   'yesterday',\n",
       "   'berkeley',\n",
       "   'twist',\n",
       "   'president',\n",
       "   'ashcroft',\n",
       "   'dixon',\n",
       "   'commonly',\n",
       "   'rican',\n",
       "   'bounce',\n",
       "   'netanyahu',\n",
       "   'puerto',\n",
       "   'irish',\n",
       "   'tale']),\n",
       " (8,\n",
       "  ['mr',\n",
       "   'lieberman',\n",
       "   'gore',\n",
       "   'nader',\n",
       "   'said',\n",
       "   'debate',\n",
       "   'percent',\n",
       "   'voters',\n",
       "   'campaign',\n",
       "   'bush',\n",
       "   'clinton',\n",
       "   'cheney',\n",
       "   'debates',\n",
       "   'party',\n",
       "   'president',\n",
       "   'poll',\n",
       "   'vice',\n",
       "   'oct',\n",
       "   'one',\n",
       "   'running',\n",
       "   'presidential',\n",
       "   'like',\n",
       "   'convention',\n",
       "   'senator',\n",
       "   'joseph',\n",
       "   'democrats',\n",
       "   'vote',\n",
       "   'republican',\n",
       "   'would',\n",
       "   'democratic',\n",
       "   'mate',\n",
       "   'time',\n",
       "   'first',\n",
       "   'american',\n",
       "   'two',\n",
       "   'al',\n",
       "   'new',\n",
       "   'political',\n",
       "   'candidates',\n",
       "   'abortion',\n",
       "   'polls',\n",
       "   'last',\n",
       "   'support',\n",
       "   'night',\n",
       "   'candidate',\n",
       "   'even',\n",
       "   'republicans',\n",
       "   'state',\n",
       "   'women',\n",
       "   'people',\n",
       "   'day',\n",
       "   'could',\n",
       "   'among',\n",
       "   'man',\n",
       "   'might',\n",
       "   'ralph',\n",
       "   'house',\n",
       "   'speech',\n",
       "   'election',\n",
       "   'right',\n",
       "   'think',\n",
       "   'news',\n",
       "   'also',\n",
       "   'week',\n",
       "   'national',\n",
       "   'white',\n",
       "   'yesterday',\n",
       "   'three',\n",
       "   'race',\n",
       "   'governor',\n",
       "   'points',\n",
       "   'issues',\n",
       "   'senate',\n",
       "   'mrs',\n",
       "   'know',\n",
       "   'many',\n",
       "   'today',\n",
       "   'win',\n",
       "   'ticket',\n",
       "   'george',\n",
       "   'york',\n",
       "   'gov',\n",
       "   'way',\n",
       "   'aides',\n",
       "   'connecticut',\n",
       "   'may',\n",
       "   'states',\n",
       "   'major',\n",
       "   'made',\n",
       "   'choice',\n",
       "   'asked',\n",
       "   'advisers',\n",
       "   'four',\n",
       "   'likely',\n",
       "   'say',\n",
       "   'show',\n",
       "   'policy',\n",
       "   'well',\n",
       "   'dick',\n",
       "   'lead']),\n",
       " (9,\n",
       "  ['barrels',\n",
       "   'carbon',\n",
       "   'leno',\n",
       "   'fires',\n",
       "   'retarded',\n",
       "   'yorkers',\n",
       "   'moscow',\n",
       "   'madison',\n",
       "   'misidentified',\n",
       "   'ordered',\n",
       "   'heating',\n",
       "   'buoyed',\n",
       "   'coal',\n",
       "   'glimpse',\n",
       "   'literary',\n",
       "   'rid',\n",
       "   'trillions',\n",
       "   'assembly',\n",
       "   'monetary',\n",
       "   'marijuana',\n",
       "   'castro',\n",
       "   'concerts',\n",
       "   'continuation',\n",
       "   'recipes',\n",
       "   'fidel',\n",
       "   'tag',\n",
       "   'trapping',\n",
       "   'cuban',\n",
       "   'printed',\n",
       "   'pronounce',\n",
       "   'climate',\n",
       "   'dual',\n",
       "   'somalia',\n",
       "   'alternatives',\n",
       "   'bright',\n",
       "   'lockhart',\n",
       "   'pipeline',\n",
       "   'antiballistic',\n",
       "   'treaty',\n",
       "   'deserving',\n",
       "   'spectacle',\n",
       "   'homosexuals',\n",
       "   'cookies',\n",
       "   'beijing',\n",
       "   'sources',\n",
       "   'rancor',\n",
       "   'ethnic',\n",
       "   'participated',\n",
       "   'minimal',\n",
       "   'releasing',\n",
       "   'pumping',\n",
       "   'mr',\n",
       "   'assumes',\n",
       "   'starr',\n",
       "   'gracious',\n",
       "   'brownback',\n",
       "   'sensitivity',\n",
       "   'dolls',\n",
       "   'joke',\n",
       "   'assured',\n",
       "   'bored',\n",
       "   'hartford',\n",
       "   'breakthrough',\n",
       "   'optimism',\n",
       "   'crowning',\n",
       "   'cheney',\n",
       "   'supertitles',\n",
       "   'windfall',\n",
       "   'subcommittee',\n",
       "   'natured',\n",
       "   'dictators',\n",
       "   'keyes',\n",
       "   'infrastructure',\n",
       "   'convention',\n",
       "   'germany',\n",
       "   'misstated',\n",
       "   'dearth',\n",
       "   'solemn',\n",
       "   'teams',\n",
       "   'reader',\n",
       "   'clinton',\n",
       "   'speech',\n",
       "   'eagerness',\n",
       "   'energy',\n",
       "   'scandal',\n",
       "   'disruption',\n",
       "   'drawbacks',\n",
       "   'acceptance',\n",
       "   'overlooked',\n",
       "   'installed',\n",
       "   'courage',\n",
       "   'tonic',\n",
       "   'article',\n",
       "   'rhetorical',\n",
       "   'overhauling',\n",
       "   'inauguration',\n",
       "   'attributes',\n",
       "   'dating',\n",
       "   'gore',\n",
       "   'distaste'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "def get_topics(lda_model, num_topics=-1, num_words=100, prob_thresh=0.8):\n",
    "    topics = []\n",
    "    for topic, topic_words in lda_model.print_topics(num_topics=num_topics, num_words=num_words):\n",
    "        words = topic_words.split(\" + \")\n",
    "        all_words = []\n",
    "        all_prob = 0\n",
    "        for elem in words:\n",
    "            prob, word = elem.split(\"*\")\n",
    "            all_prob += float(prob)\n",
    "            all_words.append(word.split('\"')[1])\n",
    "\n",
    "            if all_prob >= prob_thresh:\n",
    "                break\n",
    "        topics.append((topic, all_words))\n",
    "\n",
    "    return topics\n",
    "topics = get_topics(lda_model)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001*\"kiss\" + 0.001*\"simon\" + 0.001*\"arthritis\" + 0.001*\"puzzlement\" + 0.000*\"minimize\" + 0.000*\"clemens\" + 0.000*\"anthony\" + 0.000*\"disconcerting\" + 0.000*\"casey\" + 0.000*\"flash\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001*\"kyoto\" + 0.001*\"jesus\" + 0.001*\"biting\" + 0.000*\"terminal\" + 0.000*\"allen\" + 0.000*\"philosopher\" + 0.000*\"buildings\" + 0.000*\"waterfront\" + 0.000*\"juries\" + 0.000*\"humiliated\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005*\"mr\" + 0.003*\"said\" + 0.003*\"gore\" + 0.003*\"tax\" + 0.003*\"would\" + 0.003*\"plan\" + 0.002*\"bush\" + 0.002*\"oil\" + 0.002*\"campaign\" + 0.002*\"debate\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002*\"mcginn\" + 0.002*\"muslim\" + 0.001*\"reprieve\" + 0.001*\"dna\" + 0.001*\"execution\" + 0.001*\"surname\" + 0.001*\"inmate\" + 0.001*\"dow\" + 0.001*\"evasions\" + 0.001*\"misspelled\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001*\"haass\" + 0.001*\"location\" + 0.001*\"goldsmith\" + 0.001*\"upstate\" + 0.001*\"prescribed\" + 0.001*\"awarded\" + 0.001*\"leone\" + 0.001*\"holbrooke\" + 0.001*\"chronicle\" + 0.001*\"india\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002*\"bushwick\" + 0.002*\"gail\" + 0.001*\"corzine\" + 0.001*\"brooklyn\" + 0.001*\"diner\" + 0.001*\"quincy\" + 0.001*\"ridgewood\" + 0.001*\"detective\" + 0.001*\"mccollum\" + 0.001*\"adams\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002*\"gorey\" + 0.002*\"bosses\" + 0.001*\"rats\" + 0.001*\"choose\" + 0.001*\"geeks\" + 0.001*\"cuomo\" + 0.001*\"purely\" + 0.001*\"entirety\" + 0.000*\"candace\" + 0.000*\"mccall\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.029*\"string\" + 0.025*\"var\" + 0.018*\"else\" + 0.006*\"pat\" + 0.006*\"buchanan\" + 0.005*\"ralph\" + 0.005*\"nader\" + 0.003*\"gore\" + 0.002*\"cbs\" + 0.002*\"green\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005*\"mr\" + 0.004*\"lieberman\" + 0.003*\"gore\" + 0.003*\"nader\" + 0.002*\"said\" + 0.002*\"debate\" + 0.002*\"percent\" + 0.002*\"voters\" + 0.002*\"campaign\" + 0.002*\"bush\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002*\"barrels\" + 0.001*\"carbon\" + 0.001*\"leno\" + 0.001*\"fires\" + 0.001*\"retarded\" + 0.001*\"yorkers\" + 0.001*\"moscow\" + 0.001*\"madison\" + 0.001*\"misidentified\" + 0.001*\"ordered\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  0   \n",
       "1  1   \n",
       "2  2   \n",
       "3  3   \n",
       "4  4   \n",
       "5  5   \n",
       "6  6   \n",
       "7  7   \n",
       "8  8   \n",
       "9  9   \n",
       "\n",
       "                                                                                                                                                                                        1  \n",
       "0    0.001*\"kiss\" + 0.001*\"simon\" + 0.001*\"arthritis\" + 0.001*\"puzzlement\" + 0.000*\"minimize\" + 0.000*\"clemens\" + 0.000*\"anthony\" + 0.000*\"disconcerting\" + 0.000*\"casey\" + 0.000*\"flash\"  \n",
       "1  0.001*\"kyoto\" + 0.001*\"jesus\" + 0.001*\"biting\" + 0.000*\"terminal\" + 0.000*\"allen\" + 0.000*\"philosopher\" + 0.000*\"buildings\" + 0.000*\"waterfront\" + 0.000*\"juries\" + 0.000*\"humiliated\"  \n",
       "2                                  0.005*\"mr\" + 0.003*\"said\" + 0.003*\"gore\" + 0.003*\"tax\" + 0.003*\"would\" + 0.003*\"plan\" + 0.002*\"bush\" + 0.002*\"oil\" + 0.002*\"campaign\" + 0.002*\"debate\"  \n",
       "3           0.002*\"mcginn\" + 0.002*\"muslim\" + 0.001*\"reprieve\" + 0.001*\"dna\" + 0.001*\"execution\" + 0.001*\"surname\" + 0.001*\"inmate\" + 0.001*\"dow\" + 0.001*\"evasions\" + 0.001*\"misspelled\"  \n",
       "4   0.001*\"haass\" + 0.001*\"location\" + 0.001*\"goldsmith\" + 0.001*\"upstate\" + 0.001*\"prescribed\" + 0.001*\"awarded\" + 0.001*\"leone\" + 0.001*\"holbrooke\" + 0.001*\"chronicle\" + 0.001*\"india\"  \n",
       "5        0.002*\"bushwick\" + 0.002*\"gail\" + 0.001*\"corzine\" + 0.001*\"brooklyn\" + 0.001*\"diner\" + 0.001*\"quincy\" + 0.001*\"ridgewood\" + 0.001*\"detective\" + 0.001*\"mccollum\" + 0.001*\"adams\"  \n",
       "6                   0.002*\"gorey\" + 0.002*\"bosses\" + 0.001*\"rats\" + 0.001*\"choose\" + 0.001*\"geeks\" + 0.001*\"cuomo\" + 0.001*\"purely\" + 0.001*\"entirety\" + 0.000*\"candace\" + 0.000*\"mccall\"  \n",
       "7                               0.029*\"string\" + 0.025*\"var\" + 0.018*\"else\" + 0.006*\"pat\" + 0.006*\"buchanan\" + 0.005*\"ralph\" + 0.005*\"nader\" + 0.003*\"gore\" + 0.002*\"cbs\" + 0.002*\"green\"  \n",
       "8                      0.005*\"mr\" + 0.004*\"lieberman\" + 0.003*\"gore\" + 0.003*\"nader\" + 0.002*\"said\" + 0.002*\"debate\" + 0.002*\"percent\" + 0.002*\"voters\" + 0.002*\"campaign\" + 0.002*\"bush\"  \n",
       "9       0.002*\"barrels\" + 0.001*\"carbon\" + 0.001*\"leno\" + 0.001*\"fires\" + 0.001*\"retarded\" + 0.001*\"yorkers\" + 0.001*\"moscow\" + 0.001*\"madison\" + 0.001*\"misidentified\" + 0.001*\"ordered\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "display(pd.DataFrame(lda_model.print_topics()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.010476502), (2, 0.11714508), (3, 0.0112605505), (4, 0.010195531), (5, 0.0109097), (7, 0.6463436), (8, 0.16330336), (9, 0.011147026)]\n",
      "[(2, 0.59236306), (3, 0.010329096), (5, 0.010007265), (7, 0.011145482), (8, 0.32933918), (9, 0.01022496)]\n",
      "[(2, 0.6083541), (8, 0.35104874)]\n",
      "[(2, 0.85344124), (8, 0.11085776)]\n",
      "[(2, 0.03919201), (8, 0.9143367)]\n",
      "[(2, 0.07631529), (8, 0.85570115)]\n",
      "[(2, 0.66931486), (8, 0.28913808)]\n",
      "[(2, 0.29158968), (3, 0.041484423), (8, 0.61582947)]\n",
      "[(2, 0.50365764), (8, 0.4427186)]\n",
      "[(0, 0.012239824), (1, 0.011007043), (2, 0.07444505), (3, 0.013155841), (4, 0.0119115645), (5, 0.012745936), (6, 0.011446362), (7, 0.014195635), (8, 0.82582957), (9, 0.013023207)]\n"
     ]
    }
   ],
   "source": [
    "document_topics = lda_model.get_document_topics(corpus)\n",
    "date_doc_topics = list(zip(nytimes[\"Date\"], lda_model.get_document_topics(corpus)))\n",
    "for l in document_topics[:10]:\n",
    "    print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# for any given day, you look at all the diff topics and identify the prob of that topic\n",
    "# should I normalize? Paper doesn't seem to normalize...\n",
    "date_topic_prob = np.zeros((len(unique_dates), k))\n",
    "for date, article in date_doc_topics:\n",
    "    i = unique_dates.index(date)\n",
    "    for topic, prob in article:\n",
    "        date_topic_prob[i][topic] += prob \n",
    "\n",
    "# Figure out how to normalize [reread paper/rewatch lecture]\n",
    "# date_topic_prob = date_topic_prob/date_topic_prob.max(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.024491</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>6.592127</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.050060</td>\n",
       "      <td>4.373290</td>\n",
       "      <td>0.269631</td>\n",
       "      <td>2000-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.914256</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.295377</td>\n",
       "      <td>0.060871</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.067795</td>\n",
       "      <td>5.089809</td>\n",
       "      <td>0.062195</td>\n",
       "      <td>2000-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>16.590956</td>\n",
       "      <td>0.602970</td>\n",
       "      <td>0.086395</td>\n",
       "      <td>1.166008</td>\n",
       "      <td>0.782960</td>\n",
       "      <td>2.514574</td>\n",
       "      <td>8.791069</td>\n",
       "      <td>0.179511</td>\n",
       "      <td>2000-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.088061</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>10.866314</td>\n",
       "      <td>0.115434</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.063018</td>\n",
       "      <td>0.145146</td>\n",
       "      <td>5.017906</td>\n",
       "      <td>0.283471</td>\n",
       "      <td>2000-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>0.200214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.561383</td>\n",
       "      <td>0.489530</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.515298</td>\n",
       "      <td>0.020171</td>\n",
       "      <td>0.117207</td>\n",
       "      <td>10.978853</td>\n",
       "      <td>0.087822</td>\n",
       "      <td>2000-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>0.445706</td>\n",
       "      <td>0.243035</td>\n",
       "      <td>17.024804</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.283709</td>\n",
       "      <td>0.324562</td>\n",
       "      <td>0.262792</td>\n",
       "      <td>10.955701</td>\n",
       "      <td>12.338105</td>\n",
       "      <td>0.470065</td>\n",
       "      <td>2000-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>0.599238</td>\n",
       "      <td>0.395619</td>\n",
       "      <td>31.018345</td>\n",
       "      <td>0.598833</td>\n",
       "      <td>0.351309</td>\n",
       "      <td>1.139376</td>\n",
       "      <td>0.337588</td>\n",
       "      <td>3.085665</td>\n",
       "      <td>33.364619</td>\n",
       "      <td>0.925718</td>\n",
       "      <td>2000-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>0.231184</td>\n",
       "      <td>0.169742</td>\n",
       "      <td>12.074686</td>\n",
       "      <td>0.258669</td>\n",
       "      <td>0.224984</td>\n",
       "      <td>0.240744</td>\n",
       "      <td>0.770272</td>\n",
       "      <td>6.368464</td>\n",
       "      <td>11.529713</td>\n",
       "      <td>0.256061</td>\n",
       "      <td>2000-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>1.119083</td>\n",
       "      <td>0.474256</td>\n",
       "      <td>37.445542</td>\n",
       "      <td>1.131816</td>\n",
       "      <td>0.576392</td>\n",
       "      <td>1.020954</td>\n",
       "      <td>0.533998</td>\n",
       "      <td>17.982314</td>\n",
       "      <td>30.437469</td>\n",
       "      <td>0.901880</td>\n",
       "      <td>2000-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01</th>\n",
       "      <td>0.525475</td>\n",
       "      <td>0.288880</td>\n",
       "      <td>20.997570</td>\n",
       "      <td>0.720387</td>\n",
       "      <td>0.343718</td>\n",
       "      <td>0.441336</td>\n",
       "      <td>0.310699</td>\n",
       "      <td>10.571242</td>\n",
       "      <td>13.096889</td>\n",
       "      <td>0.534848</td>\n",
       "      <td>2000-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1          2         3         4         5  \\\n",
       "2000-05-01  0.024491  0.022024   6.592127  0.077900  0.023834  0.025503   \n",
       "2000-05-02  0.038868  0.083333   2.914256  0.062829  0.295377  0.060871   \n",
       "2000-05-03  0.129160  0.041622  16.590956  0.602970  0.086395  1.166008   \n",
       "2000-05-04  0.088061  0.031278  10.866314  0.115434  0.085700  0.724263   \n",
       "2000-05-05  0.200214  0.000000  12.561383  0.489530  0.041574  0.515298   \n",
       "...              ...       ...        ...       ...       ...       ...   \n",
       "2000-10-28  0.445706  0.243035  17.024804  0.426414  0.283709  0.324562   \n",
       "2000-10-29  0.599238  0.395619  31.018345  0.598833  0.351309  1.139376   \n",
       "2000-10-30  0.231184  0.169742  12.074686  0.258669  0.224984  0.240744   \n",
       "2000-10-31  1.119083  0.474256  37.445542  1.131816  0.576392  1.020954   \n",
       "2000-11-01  0.525475  0.288880  20.997570  0.720387  0.343718  0.441336   \n",
       "\n",
       "                   6          7          8         9        Date  \n",
       "2000-05-01  0.022903   0.050060   4.373290  0.269631  2000-05-01  \n",
       "2000-05-02  0.036349   0.067795   5.089809  0.062195  2000-05-02  \n",
       "2000-05-03  0.782960   2.514574   8.791069  0.179511  2000-05-03  \n",
       "2000-05-04  0.063018   0.145146   5.017906  0.283471  2000-05-04  \n",
       "2000-05-05  0.020171   0.117207  10.978853  0.087822  2000-05-05  \n",
       "...              ...        ...        ...       ...         ...  \n",
       "2000-10-28  0.262792  10.955701  12.338105  0.470065  2000-10-28  \n",
       "2000-10-29  0.337588   3.085665  33.364619  0.925718  2000-10-29  \n",
       "2000-10-30  0.770272   6.368464  11.529713  0.256061  2000-10-30  \n",
       "2000-10-31  0.533998  17.982314  30.437469  0.901880  2000-10-31  \n",
       "2000-11-01  0.310699  10.571242  13.096889  0.534848  2000-11-01  \n",
       "\n",
       "[185 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_topic = pd.DataFrame(date_topic_prob, index=unique_dates)\n",
    "date_topic[\"Date\"] = unique_dates\n",
    "date_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.024491</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>6.592127</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.050060</td>\n",
       "      <td>4.373290</td>\n",
       "      <td>0.269631</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.914256</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.295377</td>\n",
       "      <td>0.060871</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.067795</td>\n",
       "      <td>5.089809</td>\n",
       "      <td>0.062195</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>16.590956</td>\n",
       "      <td>0.602970</td>\n",
       "      <td>0.086395</td>\n",
       "      <td>1.166008</td>\n",
       "      <td>0.782960</td>\n",
       "      <td>2.514574</td>\n",
       "      <td>8.791069</td>\n",
       "      <td>0.179511</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.088061</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>10.866314</td>\n",
       "      <td>0.115434</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.063018</td>\n",
       "      <td>0.145146</td>\n",
       "      <td>5.017906</td>\n",
       "      <td>0.283471</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>0.200214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.561383</td>\n",
       "      <td>0.489530</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.515298</td>\n",
       "      <td>0.020171</td>\n",
       "      <td>0.117207</td>\n",
       "      <td>10.978853</td>\n",
       "      <td>0.087822</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-27</th>\n",
       "      <td>0.824211</td>\n",
       "      <td>0.624444</td>\n",
       "      <td>38.928351</td>\n",
       "      <td>1.926377</td>\n",
       "      <td>0.782506</td>\n",
       "      <td>1.223071</td>\n",
       "      <td>0.960232</td>\n",
       "      <td>17.073540</td>\n",
       "      <td>28.986691</td>\n",
       "      <td>1.087956</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>0.445706</td>\n",
       "      <td>0.243035</td>\n",
       "      <td>17.024804</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.283709</td>\n",
       "      <td>0.324562</td>\n",
       "      <td>0.262792</td>\n",
       "      <td>10.955701</td>\n",
       "      <td>12.338105</td>\n",
       "      <td>0.470065</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>0.599238</td>\n",
       "      <td>0.395619</td>\n",
       "      <td>31.018345</td>\n",
       "      <td>0.598833</td>\n",
       "      <td>0.351309</td>\n",
       "      <td>1.139376</td>\n",
       "      <td>0.337588</td>\n",
       "      <td>3.085665</td>\n",
       "      <td>33.364619</td>\n",
       "      <td>0.925718</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>0.231184</td>\n",
       "      <td>0.169742</td>\n",
       "      <td>12.074686</td>\n",
       "      <td>0.258669</td>\n",
       "      <td>0.224984</td>\n",
       "      <td>0.240744</td>\n",
       "      <td>0.770272</td>\n",
       "      <td>6.368464</td>\n",
       "      <td>11.529713</td>\n",
       "      <td>0.256061</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>1.119083</td>\n",
       "      <td>0.474256</td>\n",
       "      <td>37.445542</td>\n",
       "      <td>1.131816</td>\n",
       "      <td>0.576392</td>\n",
       "      <td>1.020954</td>\n",
       "      <td>0.533998</td>\n",
       "      <td>17.982314</td>\n",
       "      <td>30.437469</td>\n",
       "      <td>0.901880</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1          2         3         4         5  \\\n",
       "Date                                                                      \n",
       "2000-05-01  0.024491  0.022024   6.592127  0.077900  0.023834  0.025503   \n",
       "2000-05-02  0.038868  0.083333   2.914256  0.062829  0.295377  0.060871   \n",
       "2000-05-03  0.129160  0.041622  16.590956  0.602970  0.086395  1.166008   \n",
       "2000-05-04  0.088061  0.031278  10.866314  0.115434  0.085700  0.724263   \n",
       "2000-05-05  0.200214  0.000000  12.561383  0.489530  0.041574  0.515298   \n",
       "...              ...       ...        ...       ...       ...       ...   \n",
       "2000-10-27  0.824211  0.624444  38.928351  1.926377  0.782506  1.223071   \n",
       "2000-10-28  0.445706  0.243035  17.024804  0.426414  0.283709  0.324562   \n",
       "2000-10-29  0.599238  0.395619  31.018345  0.598833  0.351309  1.139376   \n",
       "2000-10-30  0.231184  0.169742  12.074686  0.258669  0.224984  0.240744   \n",
       "2000-10-31  1.119083  0.474256  37.445542  1.131816  0.576392  1.020954   \n",
       "\n",
       "                   6          7          8         9  LastPrice  \n",
       "Date                                                             \n",
       "2000-05-01  0.022903   0.050060   4.373290  0.269631   0.523810  \n",
       "2000-05-02  0.036349   0.067795   5.089809  0.062195   0.504970  \n",
       "2000-05-03  0.782960   2.514574   8.791069  0.179511   0.509491  \n",
       "2000-05-04  0.063018   0.145146   5.017906  0.283471   0.511466  \n",
       "2000-05-05  0.020171   0.117207  10.978853  0.087822   0.520875  \n",
       "...              ...        ...        ...       ...        ...  \n",
       "2000-10-27  0.960232  17.073540  28.986691  1.087956   0.384310  \n",
       "2000-10-28  0.262792  10.955701  12.338105  0.470065   0.296488  \n",
       "2000-10-29  0.337588   3.085665  33.364619  0.925718   0.345703  \n",
       "2000-10-30  0.770272   6.368464  11.529713  0.256061   0.380711  \n",
       "2000-10-31  0.533998  17.982314  30.437469  0.901880   0.381966  \n",
       "\n",
       "[182 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = date_topic.set_index('Date').join(stock_prices.set_index('Date')).dropna()\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.9832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8656</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.6672</td>\n",
       "      <td>0.5237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.3832</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.8541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.3009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.6386</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8207</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.7071</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.4774</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1       2       3       4       5       6       7  \\\n",
       "0          1.0000  0.9159  0.0223  0.2516  0.6420  0.5100  0.9862  0.1433   \n",
       "1          0.8656  1.0000  0.2317  0.1685  0.9400  0.4512  0.6934  0.0683   \n",
       "2          0.5992  0.6411  1.0000  0.7782  0.8251  0.3832  0.9611  0.4004   \n",
       "3          0.8043  0.2619  0.2321  1.0000  0.7057  0.5495  0.6683  0.4888   \n",
       "4          0.5951  0.7258  0.4393  0.3318  1.0000  0.2978  0.6507  0.6678   \n",
       "5          0.3412  0.0692  0.1614  0.2148  0.6802  1.0000  0.8395  0.0383   \n",
       "6          0.9873  0.5242  0.8196  0.9135  0.6386  0.6923  1.0000  0.0853   \n",
       "7          0.0139  0.0761  0.0118  0.0278  0.0708  0.2113  0.8127  1.0000   \n",
       "8          0.8207  0.9228  0.1371  0.8602  0.7071  0.7979  0.7649  0.5049   \n",
       "9          0.5745  0.6655  0.1161  0.4774  0.9286  0.5451  0.6443  0.3038   \n",
       "LastPrice  0.8435  0.5697  0.7302  0.5636  0.9237  0.8508  0.9902  0.5776   \n",
       "\n",
       "                8       9  LastPrice  \n",
       "0          0.1708  0.5967     0.9832  \n",
       "1          0.4399  0.6672     0.5237  \n",
       "2          0.3621  0.1449     0.8541  \n",
       "3          0.1535  0.1931     0.3009  \n",
       "4          0.9207  0.6570     0.9249  \n",
       "5          0.0905  0.1102     0.1438  \n",
       "6          0.8756  0.3177     0.0068  \n",
       "7          0.0163  0.0047     0.8669  \n",
       "8          1.0000  0.3198     0.9240  \n",
       "9          0.1192  1.0000     0.3419  \n",
       "LastPrice  0.8769  0.5332     1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9  LastPrice\n",
       "0          0.0  2.0  0.0  4.0  3.0  0.0  0.0  2.0  0.0  3.0        4.0\n",
       "1          0.0  0.0  4.0  4.0  0.0  1.0  0.0  2.0  0.0  3.0        2.0\n",
       "2          4.0  4.0  0.0  3.0  2.0  2.0  1.0  4.0  0.0  4.0        0.0\n",
       "3          4.0  0.0  4.0  0.0  1.0  4.0  0.0  4.0  4.0  3.0        0.0\n",
       "4          1.0  4.0  2.0  1.0  0.0  2.0  0.0  2.0  0.0  2.0        0.0\n",
       "5          4.0  0.0  0.0  4.0  3.0  0.0  0.0  2.0  0.0  4.0        2.0\n",
       "6          4.0  2.0  0.0  3.0  1.0  0.0  0.0  1.0  0.0  2.0        1.0\n",
       "7          3.0  1.0  0.0  3.0  0.0  3.0  0.0  0.0  0.0  1.0        2.0\n",
       "8          4.0  4.0  3.0  4.0  2.0  3.0  2.0  2.0  0.0  4.0        3.0\n",
       "9          4.0  0.0  0.0  0.0  4.0  4.0  2.0  2.0  0.0  0.0        4.0\n",
       "LastPrice  3.0  0.0  3.0  0.0  0.0  3.0  2.0  3.0  2.0  2.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/58005681/is-it-possible-to-run-a-vector-autoregression-analysis-on-a-large-gdp-data-with\n",
    "# Can I rewrite this so that I only measure stock_price on topic and not topic on topic\n",
    "# 11/24 - changed from chi^2 to f\n",
    "def grangers_causality_matrix(data, variables, maxlag=5, test='ssr_ftest', verbose=False):\n",
    "    dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    lags    = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in dataset.columns:\n",
    "        for r in dataset.index:            \n",
    "            test_result = grangercausalitytests(data[[r,c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4) for i in range(maxlag)]\n",
    "            \n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "\n",
    "            max_p_value_i = np.argmax(p_values)\n",
    "            max_p_value = p_values[max_p_value_i]\n",
    "            dataset.loc[r, c] = max_p_value\n",
    "            \n",
    "            lags.loc[r, c] = max_p_value_i\n",
    "    \n",
    "    return dataset, lags\n",
    "\n",
    "# grangers_causality_matrix(dataset, variables = dataset.columns)\n",
    "causality, lags = grangers_causality_matrix(joined, variables=joined.columns, verbose=False)\n",
    "display(causality)\n",
    "display(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 4.0), (6, 2.0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_causal_topics(gc, lags, significance=0.95):\n",
    "    keep_topics = gc[gc['LastPrice' ] > significance].index[:-1] \n",
    "    keep_lags = list(lags.loc[keep_topics, 'LastPrice'])\n",
    "\n",
    "    keep_topics_temp = (gc.loc[\"LastPrice\", gc.loc[\"LastPrice\"] > significance].index[:-1])\n",
    "    keep_topics = keep_topics.append(keep_topics_temp)\n",
    "    keep_lags += list(lags.loc[\"LastPrice\", keep_topics_temp])\n",
    "\n",
    "    keep_topics = list(keep_topics)\n",
    "    return list(zip(keep_topics, keep_lags))\n",
    "\n",
    "causal_topics = get_causal_topics(causality, lags)\n",
    "causal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, datetime.date(2000, 10, 27)), (6, datetime.date(2000, 10, 27))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for all topics, if a majority of docs from one date are in that topic, you're going to label that topic with that date\n",
    "# def get_topic_date(date_doc_topics, causal_topics):\n",
    "#     topic_date_cnts = {key: {} for key in causal_topics}\n",
    "    \n",
    "#     for date, doc in date_doc_topics:\n",
    "#         for topic, prob in doc:\n",
    "#             if topic in causal_topics:\n",
    "#                 try:\n",
    "#                     topic_date_cnts[topic][date] += 1\n",
    "#                 except KeyError:\n",
    "#                     topic_date_cnts[topic][date] = 1\n",
    "    \n",
    "#     topic_date = []\n",
    "    \n",
    "#     for topic in topic_date_cnts:\n",
    "#         max_date = max(topic_date_cnts[topic], key=lambda key: topic_date_cnts[topic][key])\n",
    "#         topic_date += [(topic, max_date)]\n",
    "        \n",
    "#     return topic_date\n",
    "    \n",
    "# causalTopic_dates = get_topic_date(date_doc_topics, [topic for topic, lag in causal_topics])\n",
    "# causalTopic_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "              cleansing  willey  legendary  woolsey  recapture  evaluate  \\\n",
       "  2000-05-01        2.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-05-02        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-05-03        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-05-04        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-05-05        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  ...               ...     ...        ...      ...        ...       ...   \n",
       "  2000-10-28        0.0     0.0        0.0      0.0        0.0       1.0   \n",
       "  2000-10-29        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-10-30        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  2000-10-31        0.0     0.0        2.0      0.0        0.0       0.0   \n",
       "  2000-11-01        0.0     0.0        0.0      0.0        0.0       0.0   \n",
       "  \n",
       "              lovers  humans  glorious  salt  ...  negotiating  claritin  pryor  \\\n",
       "  2000-05-01     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  2000-05-02     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  2000-05-03     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  2000-05-04     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  2000-05-05     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  ...            ...     ...       ...   ...  ...          ...       ...    ...   \n",
       "  2000-10-28     0.0     0.0       0.0   1.0  ...          0.0       0.0    0.0   \n",
       "  2000-10-29     0.0     0.0       0.0   0.0  ...          2.0       0.0    0.0   \n",
       "  2000-10-30     0.0     0.0       0.0   0.0  ...          0.0       0.0    0.0   \n",
       "  2000-10-31     4.0     0.0       0.0   4.0  ...          0.0       0.0    4.0   \n",
       "  2000-11-01     0.0     0.0       0.0   0.0  ...          4.0       0.0    0.0   \n",
       "  \n",
       "              front  immigrant  manufacturer  delayed  sizzle  dissolved  \\\n",
       "  2000-05-01    1.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-05-02    0.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-05-03    0.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-05-04    1.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-05-05    0.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  ...           ...        ...           ...      ...     ...        ...   \n",
       "  2000-10-28    1.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-10-29    6.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-10-30    1.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  2000-10-31    8.0        0.0           0.0      0.0     2.0        0.0   \n",
       "  2000-11-01    1.0        0.0           0.0      0.0     0.0        0.0   \n",
       "  \n",
       "              persuasion  \n",
       "  2000-05-01         0.0  \n",
       "  2000-05-02         0.0  \n",
       "  2000-05-03         0.0  \n",
       "  2000-05-04         0.0  \n",
       "  2000-05-05         0.0  \n",
       "  ...                ...  \n",
       "  2000-10-28         0.0  \n",
       "  2000-10-29         0.0  \n",
       "  2000-10-30         0.0  \n",
       "  2000-10-31         0.0  \n",
       "  2000-11-01         0.0  \n",
       "  \n",
       "  [185 rows x 100 columns]),\n",
       " (6,\n",
       "              oversight  imports  penn  makers  cicchino  residents  trio  \\\n",
       "  2000-05-01        0.0      0.0   0.0     0.0       0.0        1.0   0.0   \n",
       "  2000-05-02        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  2000-05-03        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  2000-05-04        0.0      0.0   0.0     3.0       0.0        0.0   0.0   \n",
       "  2000-05-05        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  ...               ...      ...   ...     ...       ...        ...   ...   \n",
       "  2000-10-28        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  2000-10-29        0.0      0.0   0.0     2.0       0.0        0.0   0.0   \n",
       "  2000-10-30        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  2000-10-31        0.0      4.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  2000-11-01        0.0      0.0   0.0     0.0       0.0        0.0   0.0   \n",
       "  \n",
       "              positives  tolerant  copies  ...  purchases  sex   bush  \\\n",
       "  2000-05-01        0.0       0.0     0.0  ...        0.0  0.0   74.0   \n",
       "  2000-05-02        0.0       0.0     0.0  ...        0.0  0.0   13.0   \n",
       "  2000-05-03        0.0       0.0     0.0  ...        0.0  0.0  150.0   \n",
       "  2000-05-04        0.0       0.0     0.0  ...        0.0  0.0   86.0   \n",
       "  2000-05-05        0.0       0.0     0.0  ...        0.0  0.0  246.0   \n",
       "  ...               ...       ...     ...  ...        ...  ...    ...   \n",
       "  2000-10-28        0.0       0.0     0.0  ...        0.0  0.0  368.0   \n",
       "  2000-10-29        0.0       0.0     2.0  ...        0.0  2.0  464.0   \n",
       "  2000-10-30        0.0       0.0     0.0  ...        0.0  0.0  271.0   \n",
       "  2000-10-31        0.0       0.0     0.0  ...        0.0  0.0  592.0   \n",
       "  2000-11-01        0.0       0.0     0.0  ...        0.0  0.0  396.0   \n",
       "  \n",
       "              prosecution  choose  peek  underpaid  racicot  candace  publicized  \n",
       "  2000-05-01          0.0     0.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-05-02          0.0     1.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-05-03          0.0     0.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-05-04          0.0     0.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-05-05          0.0     0.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  ...                 ...     ...   ...        ...      ...      ...         ...  \n",
       "  2000-10-28          0.0     0.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-10-29          0.0     2.0   0.0        0.0      0.0      2.0         0.0  \n",
       "  2000-10-30          0.0     2.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-10-31          0.0     2.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  2000-11-01          0.0     2.0   0.0        0.0      0.0      0.0         0.0  \n",
       "  \n",
       "  [185 rows x 100 columns])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_stream(nytimes, topics, causal_topics):\n",
    "    ct_ws = []\n",
    "    for ct in causal_topics:\n",
    "        causal_vocab = list(set(topics[ct][1]))\n",
    "        date_terms = pd.DataFrame(np.zeros((len(unique_dates), len(causal_vocab))), index=unique_dates, columns=causal_vocab)\n",
    "\n",
    "        for date, doc in zip(nytimes['Date'], doc_word_cnts):\n",
    "            for word, count in doc:\n",
    "                try:\n",
    "                     date_terms.loc[date, word] += int(count)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        ct_ws.append((ct, date_terms))\n",
    "    \n",
    "    return ct_ws\n",
    "\n",
    "ct_ws = get_word_stream(nytimes, topics, [topic for topic, lag in causal_topics])\n",
    "ct_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, [], []), (6, [], [])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_impact_words(topic_wordstream, significance=0.95):\n",
    "    topic_impact_words = []\n",
    "    \n",
    "    for topic, ws in topic_wordstream:\n",
    "        ws_prices = ws.join(stock_prices.set_index('Date')).dropna()\n",
    "        ws_gc, _ = grangers_causality_matrix(ws_prices, variables=ws_prices.columns, verbose=False)\n",
    "        \n",
    "#         display(ws_gc)\n",
    "        keep_words = ws_gc[ws_gc['LastPrice' ] > significance].index[:-1] \n",
    "\n",
    "        keep_words_temp = (ws_gc.loc[\"LastPrice\", ws_gc.loc[\"LastPrice\"] > significance].index[:-1])\n",
    "        keep_words = keep_words.append(keep_words_temp)\n",
    "        \n",
    "        pos = []\n",
    "        neg = []\n",
    "        for word in keep_words:\n",
    "            corr = pearsonr(ws_prices[word], stock_prices['LastPrice'])[0]\n",
    "            if abs(corr) >= significance:\n",
    "                print (word, corr)\n",
    "                if corr > 0:\n",
    "                    pos.append((word, corr))\n",
    "                else:\n",
    "                    neg.append((word, corr))\n",
    "        topic_impact_words.append((topic, pos, neg))\n",
    "    \n",
    "    return topic_impact_words\n",
    "        \n",
    "\n",
    "impact_words = get_impact_words(ct_ws)\n",
    "impact_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleansing</th>\n",
       "      <th>willey</th>\n",
       "      <th>oversight</th>\n",
       "      <th>legendary</th>\n",
       "      <th>imports</th>\n",
       "      <th>woolsey</th>\n",
       "      <th>recapture</th>\n",
       "      <th>penn</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>lovers</th>\n",
       "      <th>...</th>\n",
       "      <th>sizzle</th>\n",
       "      <th>dissolved</th>\n",
       "      <th>persuasion</th>\n",
       "      <th>choose</th>\n",
       "      <th>peek</th>\n",
       "      <th>underpaid</th>\n",
       "      <th>racicot</th>\n",
       "      <th>candace</th>\n",
       "      <th>publicized</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cleansing  willey  oversight  legendary  imports  woolsey  \\\n",
       "2000-05-01        2.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-05-02        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-05-03        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-05-04        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-05-05        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "...               ...     ...        ...        ...      ...      ...   \n",
       "2000-10-27        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-10-28        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-10-29        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-10-30        0.0     0.0        0.0        0.0      0.0      0.0   \n",
       "2000-10-31        0.0     0.0        0.0        2.0      4.0      0.0   \n",
       "\n",
       "            recapture  penn  evaluate  lovers  ...  sizzle  dissolved  \\\n",
       "2000-05-01        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-05-02        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-05-03        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-05-04        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-05-05        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "...               ...   ...       ...     ...  ...     ...        ...   \n",
       "2000-10-27        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-10-28        0.0   0.0       1.0     0.0  ...     0.0        0.0   \n",
       "2000-10-29        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-10-30        0.0   0.0       0.0     0.0  ...     0.0        0.0   \n",
       "2000-10-31        0.0   0.0       0.0     4.0  ...     2.0        0.0   \n",
       "\n",
       "            persuasion  choose  peek  underpaid  racicot  candace  publicized  \\\n",
       "2000-05-01         0.0     0.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-05-02         0.0     1.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-05-03         0.0     0.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-05-04         0.0     0.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-05-05         0.0     0.0   0.0        0.0      0.0      0.0         0.0   \n",
       "...                ...     ...   ...        ...      ...      ...         ...   \n",
       "2000-10-27         0.0     2.0   2.0        0.0      0.0      0.0         0.0   \n",
       "2000-10-28         0.0     0.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-10-29         0.0     2.0   0.0        0.0      0.0      2.0         0.0   \n",
       "2000-10-30         0.0     2.0   0.0        0.0      0.0      0.0         0.0   \n",
       "2000-10-31         0.0     2.0   0.0        0.0      0.0      0.0         0.0   \n",
       "\n",
       "            LastPrice  \n",
       "2000-05-01   0.523810  \n",
       "2000-05-02   0.504970  \n",
       "2000-05-03   0.509491  \n",
       "2000-05-04   0.511466  \n",
       "2000-05-05   0.520875  \n",
       "...               ...  \n",
       "2000-10-27   0.384310  \n",
       "2000-10-28   0.296488  \n",
       "2000-10-29   0.345703  \n",
       "2000-10-30   0.380711  \n",
       "2000-10-31   0.381966  \n",
       "\n",
       "[182 rows x 197 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleansing</th>\n",
       "      <th>willey</th>\n",
       "      <th>oversight</th>\n",
       "      <th>legendary</th>\n",
       "      <th>imports</th>\n",
       "      <th>woolsey</th>\n",
       "      <th>recapture</th>\n",
       "      <th>penn</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>lovers</th>\n",
       "      <th>...</th>\n",
       "      <th>sizzle</th>\n",
       "      <th>dissolved</th>\n",
       "      <th>persuasion</th>\n",
       "      <th>choose</th>\n",
       "      <th>peek</th>\n",
       "      <th>underpaid</th>\n",
       "      <th>racicot</th>\n",
       "      <th>candace</th>\n",
       "      <th>publicized</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleansing</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.7411</td>\n",
       "      <td>0.5432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>willey</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversight</th>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>0.8078</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legendary</th>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>0.9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imports</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.4114</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.7877</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underpaid</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racicot</th>\n",
       "      <td>0.9975</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8146</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8301</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.6653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candace</th>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.9329</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicized</th>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.4439</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cleansing  willey  oversight  legendary  imports  woolsey  \\\n",
       "cleansing      1.0000  1.0000     0.9721     0.8977   0.0000   1.0000   \n",
       "willey         0.9997  1.0000     0.9998     0.9981   0.9995   1.0000   \n",
       "oversight      0.8024  0.9999     1.0000     0.8517   0.9693   0.9998   \n",
       "legendary      0.0638  0.9956     0.9571     1.0000   0.6603   0.9253   \n",
       "imports        0.0099  0.9996     0.9792     0.4114   1.0000   0.9559   \n",
       "...               ...     ...        ...        ...      ...      ...   \n",
       "underpaid      0.9997  1.0000     0.9998     0.9983   0.9995   1.0000   \n",
       "racicot        0.9975  1.0000     0.8146     0.8918   0.9944   0.9999   \n",
       "candace        0.7297  0.9973     0.9206     0.9033   0.0000   0.9965   \n",
       "publicized     0.5756  0.9993     0.9064     0.6458   0.7762   0.9366   \n",
       "LastPrice      0.9988  0.8845     0.3444     0.9877   0.9958   0.9955   \n",
       "\n",
       "            recapture    penn  evaluate  lovers  ...  sizzle  dissolved  \\\n",
       "cleansing      0.9995  1.0000    0.2825  0.9998  ...  1.0000     0.9999   \n",
       "willey         0.8549  1.0000    0.9993  0.9998  ...  0.9999     0.9998   \n",
       "oversight      0.9841  0.9996    0.9326  0.9981  ...  0.9994     0.9904   \n",
       "legendary      0.9027  0.0000    0.7894  0.9525  ...  0.9931     0.9490   \n",
       "imports        0.9763  0.9980    0.7877  0.9294  ...  0.9914     0.9633   \n",
       "...               ...     ...       ...     ...  ...     ...        ...   \n",
       "underpaid      0.9993  1.0000    0.9993  0.9998  ...  0.9999     0.9998   \n",
       "racicot        0.7644  0.9695    0.9985  0.9446  ...  0.9998     0.8301   \n",
       "candace        0.9487  0.9865    0.9386  0.9491  ...  0.9807     0.9669   \n",
       "publicized     0.9552  0.9961    0.8131  0.7951  ...  0.9832     0.8723   \n",
       "LastPrice      0.9620  0.9988    0.4439  0.9710  ...  0.9600     0.7668   \n",
       "\n",
       "            persuasion  choose    peek  underpaid  racicot  candace  \\\n",
       "cleansing       0.8639  0.0241  0.8763     1.0000   0.9983   0.8490   \n",
       "willey          0.9999  0.9427  0.9997     1.0000   0.9999   0.9979   \n",
       "oversight       0.8078  0.8801  0.9974     0.9999   0.9223   0.9514   \n",
       "legendary       0.6402  0.9061  0.7268     0.9798   0.7368   0.6727   \n",
       "imports         0.9958  0.8559  0.7863     0.9996   0.9861   0.8753   \n",
       "...                ...     ...     ...        ...      ...      ...   \n",
       "underpaid       0.9999  0.8082  0.9997     1.0000   0.9999   0.9979   \n",
       "racicot         0.9997  0.0887  0.9468     1.0000   1.0000   0.7221   \n",
       "candace         0.9964  0.7863  0.9329     0.9973   0.7908   1.0000   \n",
       "publicized      0.9816  0.6685  0.9533     0.9993   0.9271   0.7581   \n",
       "LastPrice       0.9574  0.9319  0.9956     0.9881   0.9024   0.6179   \n",
       "\n",
       "            publicized  LastPrice  \n",
       "cleansing       0.7411     0.5432  \n",
       "willey          0.9988     0.9999  \n",
       "oversight       0.8684     0.8391  \n",
       "legendary       0.7776     0.9877  \n",
       "imports         0.2851     0.9984  \n",
       "...                ...        ...  \n",
       "underpaid       0.9988     0.9950  \n",
       "racicot         0.9874     0.6653  \n",
       "candace         0.7252     0.9957  \n",
       "publicized      1.0000     0.9793  \n",
       "LastPrice       0.8601     1.0000  \n",
       "\n",
       "[197 rows x 197 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleansing</th>\n",
       "      <th>willey</th>\n",
       "      <th>oversight</th>\n",
       "      <th>legendary</th>\n",
       "      <th>imports</th>\n",
       "      <th>woolsey</th>\n",
       "      <th>recapture</th>\n",
       "      <th>penn</th>\n",
       "      <th>evaluate</th>\n",
       "      <th>lovers</th>\n",
       "      <th>...</th>\n",
       "      <th>sizzle</th>\n",
       "      <th>dissolved</th>\n",
       "      <th>persuasion</th>\n",
       "      <th>choose</th>\n",
       "      <th>peek</th>\n",
       "      <th>underpaid</th>\n",
       "      <th>racicot</th>\n",
       "      <th>candace</th>\n",
       "      <th>publicized</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleansing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>willey</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversight</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legendary</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imports</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underpaid</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racicot</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candace</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicized</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LastPrice</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cleansing  willey  oversight  legendary  imports  woolsey  \\\n",
       "cleansing         0.0     4.0        4.0        3.0      0.0      4.0   \n",
       "willey            4.0     0.0        4.0        4.0      4.0      4.0   \n",
       "oversight         4.0     4.0        0.0        4.0      4.0      4.0   \n",
       "legendary         4.0     4.0        4.0        0.0      4.0      1.0   \n",
       "imports           0.0     4.0        4.0        3.0      0.0      1.0   \n",
       "...               ...     ...        ...        ...      ...      ...   \n",
       "underpaid         4.0     4.0        4.0        4.0      4.0      4.0   \n",
       "racicot           4.0     4.0        0.0        1.0      4.0      4.0   \n",
       "candace           1.0     4.0        2.0        4.0      0.0      4.0   \n",
       "publicized        4.0     4.0        4.0        2.0      2.0      1.0   \n",
       "LastPrice         4.0     0.0        0.0        2.0      4.0      4.0   \n",
       "\n",
       "            recapture  penn  evaluate  lovers  ...  sizzle  dissolved  \\\n",
       "cleansing         4.0   4.0       0.0     4.0  ...     4.0        4.0   \n",
       "willey            0.0   4.0       4.0     4.0  ...     4.0        4.0   \n",
       "oversight         4.0   4.0       2.0     4.0  ...     4.0        2.0   \n",
       "legendary         4.0   0.0       1.0     4.0  ...     4.0        4.0   \n",
       "imports           4.0   4.0       1.0     3.0  ...     4.0        3.0   \n",
       "...               ...   ...       ...     ...  ...     ...        ...   \n",
       "underpaid         4.0   4.0       4.0     4.0  ...     4.0        4.0   \n",
       "racicot           0.0   4.0       4.0     4.0  ...     4.0        0.0   \n",
       "candace           4.0   4.0       4.0     2.0  ...     4.0        2.0   \n",
       "publicized        4.0   4.0       2.0     2.0  ...     4.0        2.0   \n",
       "LastPrice         2.0   2.0       4.0     2.0  ...     0.0        0.0   \n",
       "\n",
       "            persuasion  choose  peek  underpaid  racicot  candace  publicized  \\\n",
       "cleansing          0.0     0.0   1.0        4.0      4.0      1.0         1.0   \n",
       "willey             4.0     4.0   4.0        4.0      4.0      4.0         4.0   \n",
       "oversight          0.0     4.0   4.0        4.0      4.0      2.0         1.0   \n",
       "legendary          4.0     1.0   2.0        2.0      0.0      4.0         3.0   \n",
       "imports            3.0     1.0   2.0        4.0      4.0      3.0         0.0   \n",
       "...                ...     ...   ...        ...      ...      ...         ...   \n",
       "underpaid          4.0     4.0   4.0        0.0      4.0      4.0         4.0   \n",
       "racicot            4.0     2.0   1.0        4.0      0.0      0.0         4.0   \n",
       "candace            4.0     2.0   0.0        4.0      1.0      0.0         1.0   \n",
       "publicized         4.0     1.0   3.0        4.0      4.0      4.0         0.0   \n",
       "LastPrice          4.0     4.0   2.0        4.0      4.0      0.0         4.0   \n",
       "\n",
       "            LastPrice  \n",
       "cleansing         4.0  \n",
       "willey            4.0  \n",
       "oversight         4.0  \n",
       "legendary         1.0  \n",
       "imports           1.0  \n",
       "...               ...  \n",
       "underpaid         1.0  \n",
       "racicot           2.0  \n",
       "candace           0.0  \n",
       "publicized        4.0  \n",
       "LastPrice         0.0  \n",
       "\n",
       "[197 rows x 197 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws_prices = ct_ws.join(stock_prices.set_index('Date')).dropna()\n",
    "ws_impact, ws_lags = grangers_causality_matrix(ws_prices, variables=ws_prices.columns, verbose=False)\n",
    "\n",
    "display(ws_prices)\n",
    "display(ws_impact)\n",
    "display(ws_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06858530091902565"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pearsonr(ws_prices[\"cleansing\"], stock_prices['LastPrice'])[0]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>0.504970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-03</td>\n",
       "      <td>0.509491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-04</td>\n",
       "      <td>0.511466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-05</td>\n",
       "      <td>0.520875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>0.384310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>0.296488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000-10-30</td>\n",
       "      <td>0.380711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>0.381966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  LastPrice\n",
       "0    2000-05-01   0.523810\n",
       "1    2000-05-02   0.504970\n",
       "2    2000-05-03   0.509491\n",
       "3    2000-05-04   0.511466\n",
       "4    2000-05-05   0.520875\n",
       "..          ...        ...\n",
       "177  2000-10-27   0.384310\n",
       "178  2000-10-28   0.296488\n",
       "179  2000-10-29   0.345703\n",
       "180  2000-10-30   0.380711\n",
       "181  2000-10-31   0.381966\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cleansing', 'willey', 'legendary', 'woolsey', 'recapture', 'evaluate',\n",
       "       'lovers', 'humans', 'glorious', 'salt', 'kicking', 'page', 'spells',\n",
       "       'casey', 'glass', 'toronto', 'andrea', 'mr', 'flash', 'torricelli',\n",
       "       'lent', 'techniques', 'diane', 'renews', 'redesign', 'plough',\n",
       "       'accepts', 'arthritis', 'deepest', 'identity', 'embassies', 'schering',\n",
       "       'lieberman', 'panama', 'convention', 'fated', 'generosity',\n",
       "       'restaurant', 'worthy', 'aug', 'shiloh', 'speculation', 'laboratories',\n",
       "       'performances', 'beans', 'clemens', 'ratified', 'abm', 'minimize',\n",
       "       'pledges', 'bigotry', 'kiss', 'wells', 'puzzlement', 'stained',\n",
       "       'graeme', 'inexperienced', 'compares', 'simon', 'clark', 'diary',\n",
       "       'upset', 'eliot', 'said', 'antonetty', 'teams', 'cherished', 'anthony',\n",
       "       'canal', 'raiservice', 'treaty', 'menu', 'negotiators', 'lodine',\n",
       "       'ethics', 'lloyd', 'import', 'wooing', 'homer', 'carrier',\n",
       "       'governorship', 'gentle', 'medication', 'disconcerting', 'medicine',\n",
       "       'pet', 'jews', 'coffin', 'uncertainty', 'navy', 'negotiating',\n",
       "       'claritin', 'pryor', 'front', 'immigrant', 'manufacturer', 'delayed',\n",
       "       'sizzle', 'dissolved', 'persuasion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_ws[0][1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {1: (\n",
    "        {'ssr_ftest': (0.0, 1.0, 179.0, 1), \n",
    "         'ssr_chi2test': (0.0, 1.0, 1), \n",
    "         'lrtest': (-0.0, 1.0, 1), \n",
    "         'params_ftest': (2.6551965154348363, 0.1049705333686674, 179.0, 1.0)}, \n",
    "         [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9c0120e80>, \n",
    "          <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9c0120640>, \n",
    "          array([[0., 1., 0.]])]), \n",
    "     2: ({'ssr_ftest': (0.0, 1.0, 177.0, 2), \n",
    "          'ssr_chi2test': (0.0, 1.0, 2), \n",
    "          'lrtest': (-0.0, 1.0, 2), \n",
    "          'params_ftest': (28.669712759208675, 1.6380216282244424e-11, 177.0, 2.0)}, \n",
    "         [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9c0120940>, \n",
    "          <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c160>, \n",
    "          array([[0., 0., 1., 0., 0.],\n",
    "                 [0., 0., 0., 1., 0.]])]), \n",
    "     3: ({'ssr_ftest': (0.0, 1.0, 175.0, 3), \n",
    "          'ssr_chi2test': (0.0, 1.0, 3), \n",
    "          'lrtest': (-0.0, 1.0, 3), \n",
    "          'params_ftest': (18.935898175907948, 1.1078151069488875e-10, 175.0, 3.0)}, \n",
    "         [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26cc40>, \n",
    "          <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26cac0>, \n",
    "          array([[0., 0., 0., 1., 0., 0., 0.],\n",
    "                 [0., 0., 0., 0., 1., 0., 0.],\n",
    "                 [0., 0., 0., 0., 0., 1., 0.]])]), \n",
    "     4: ({'ssr_ftest': (0.0, 1.0, 173.0, 4), \n",
    "          'ssr_chi2test': (0.0, 1.0, 4), \n",
    "          'lrtest': (-0.0, 1.0, 4), \n",
    "          'params_ftest': (24.90653594920218, 2.677610622848283e-16, 173.0, 4.0)}, [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c760>, <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c5e0>, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]), \n",
    "     5: ({'ssr_ftest': (-3.955967903576136e-15, 1.0, 171.0, 5), \n",
    "          'ssr_chi2test': (-2.047386897464842e-14, 1.0, 5), \n",
    "          'lrtest': (-0.0, 1.0, 5), \n",
    "          'params_ftest': (20.40580635942483, 6.031245590056417e-16, 171.0, 5.0)}, \n",
    "         [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c580>, \n",
    "          <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c610>, \n",
    "          array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],/\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}\n",
    "\n",
    "{1: ({'ssr_ftest': (6.669662363748857, 0.010610382296105314, 178.0, 1), \n",
    "      'ssr_chi2test': (6.78207240358732, 0.009207792227606254, 1), \n",
    "      'lrtest': (6.658097641379641, 0.009870623339659977, 1), \n",
    "      'params_ftest': (6.669662363748866, 0.010610382296105314, 178.0, 1.0)}, \n",
    "     [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc98e26c370>, \n",
    "      <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9ed2ef220>, \n",
    "      array([[0., 1., 0.]])]), \n",
    " 2: ({'ssr_ftest': (11.169212517137323, 2.7215054361967665e-05, 175.0, 2), \n",
    "      'ssr_chi2test': (22.976665749539638, 1.0248974821774139e-05, 2), \n",
    "      'lrtest': (21.62415140965004, 2.015464641527244e-05, 2), \n",
    "      'params_ftest': (11.169212517137293, 2.721505436196856e-05, 175.0, 2.0)},\n",
    "     [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9ed2ef550>, \n",
    "      <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9ed2ef5b0>, \n",
    "      array([[0., 0., 1., 0., 0.],\n",
    "       [0., 0., 0., 1., 0.]])]), \n",
    " 3: ({'ssr_ftest': (21.28195759280595, 8.991511901217905e-12, 172.0, 3), \n",
    "      'ssr_chi2test': (66.44425132172555, 2.4625076931282265e-14, 3), \n",
    "      'lrtest': (56.50744198114023, 3.2737765892104785e-12, 3), \n",
    "      'params_ftest': (21.28195759280595, 8.991511901217905e-12, 172.0, 3.0)}, \n",
    "     [<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fc9ed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
