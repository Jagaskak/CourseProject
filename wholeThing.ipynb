{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/patsy/constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell contains the processing of NYTimes data and IEM stock market data. You should only run this once.\n",
    "'''\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Tokenize and remove stop words from content\n",
    "def tokenize(content, lemmatize=False):\n",
    "    words = gensim.utils.simple_preprocess(content, deacc=True)  # tokenizes\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(content):\n",
    "    words = []\n",
    "    for word in content:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "'''\n",
    "Retrieve Data from files\n",
    "'''\n",
    "\n",
    "# New York Times Data\n",
    "rows = []\n",
    "dates = []\n",
    "articles = []\n",
    "for month in range(5, 11):\n",
    "    with open(\"Data/NYTimes/\"+ str(month) + \".txt\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            date, article = line.split(\",\", 1)\n",
    "            timestamp = datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "            tokenized = tokenize(article)\n",
    "            destopped = remove_stopwords(tokenized)\n",
    "\n",
    "            articles.append(destopped)\n",
    "            dates.append(timestamp)\n",
    "            rows.append([timestamp, destopped])\n",
    "\n",
    "nytimes = pd.DataFrame(rows, columns=[\"Date\", \"Content\"]) \n",
    "unique_dates = sorted(list(set(nytimes[\"Date\"])))\n",
    "# print (unique_dates)\n",
    "\n",
    "# Time Series Data\n",
    "ts_months = [\"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\"]\n",
    "cols = ['Date', 'LastPrice']\n",
    "stock_prices = pd.DataFrame()\n",
    "for month in ts_months:\n",
    "    ts_df = pd.read_csv(\"Data/PriceHistory/\" + month + \".txt\", delim_whitespace=True)\n",
    "    ts_df['Date'] =  ts_df['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%y\").date())\n",
    "    \n",
    "    Gore = ts_df.loc[ts_df['Contract'] == 'Dem'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "    Bush = ts_df.loc[ts_df['Contract'] == 'Rep'][['Date', 'LastPrice']].fillna(0).reset_index()\n",
    "\n",
    "    # Gore/(Gore + Bush)\n",
    "    relation = list(zip(Gore['Date'], (Gore['LastPrice']/(Gore['LastPrice'] + Bush['LastPrice'])).fillna(0.001)))\n",
    "    stock_prices = stock_prices.append(relation, ignore_index=True)\n",
    "\n",
    "stock_prices.columns = cols\n",
    "\n",
    "\n",
    "'''\n",
    "BOW - corpus, date x word cnts\n",
    "'''\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(articles)\n",
    "\n",
    "# Filtering: \n",
    "# Keep words that appear in at least 15 docs\n",
    "# Don't keep words that appear in more that 70% of docs in corpus\n",
    "id2word.filter_extremes(no_below=15, no_above=0.8)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in articles]\n",
    "\n",
    "# TF-IDF seems to give better coherence (but it wasn't in the paper...)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "# [[(id2word[id], freq) for id, freq in cp] for cp in tfidf_corpus[:1]][0][:5]\n",
    "\n",
    "# bow by date?\n",
    "date_term_cnts = defaultdict(lambda: [])\n",
    "\n",
    "for index, row in nytimes.iterrows():\n",
    "    date = row[\"Date\"]\n",
    "    content = row[\"Content\"]\n",
    "    \n",
    "    date_term_cnts[date] += content\n",
    "    \n",
    "date_term_cnts = list(date_term_cnts.items())\n",
    "# date_term_cnts\n",
    "date_term_cnts = [(date, {id2word[id]: freq for id, freq in id2word.doc2bow(text)}) for date, text in date_term_cnts]\n",
    "date_term_cnts = sorted(date_term_cnts, key=lambda x: x[0])\n",
    "date_term_cnts = pd.DataFrame([date_term_cnts[i][1] for i in range(len(date_term_cnts))], index=[date_term_cnts[i][0] for i in range(len(date_term_cnts))]).fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell contains function definitions.\n",
    "'''\n",
    "\n",
    "def rel_purity(currPurity, prevPurity):\n",
    "    return abs(currPurity - prevPurity)/prevPurity\n",
    "\n",
    "\n",
    "# Select the model and print the topics\n",
    "def get_topics(lda_model, num_topics=-1, num_words=100, prob_thresh=0.8):\n",
    "    topics = []\n",
    "    for topic, topic_words in lda_model.print_topics(num_topics=num_topics, num_words=num_words):\n",
    "        words = topic_words.split(\" + \")\n",
    "        all_words = []\n",
    "        all_prob = 0\n",
    "        for elem in words:\n",
    "            prob, word = elem.split(\"*\")\n",
    "            all_prob += float(prob)\n",
    "            all_words.append(word.split('\"')[1])\n",
    "\n",
    "            if all_prob >= prob_thresh:\n",
    "                break\n",
    "        topics.append((topic, all_words))\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# https://stackoverflow.com/questions/58005681/is-it-possible-to-run-a-vector-autoregression-analysis-on-a-large-gdp-data-with\n",
    "def grangers_causality_matrix(data, variables, maxlag=5, test='ssr_ftest', verbose=False):\n",
    "    dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    lags    = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    \n",
    "    for c in dataset.columns:\n",
    "        for r in dataset.index:            \n",
    "            test_result = grangercausalitytests(data[[r,c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4) for i in range(maxlag)]\n",
    "            \n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "\n",
    "            # smaller p-val corresponds to higher f-val\n",
    "            min_p_value_i = np.argmin(p_values)\n",
    "            min_p_value = p_values[min_p_value_i]\n",
    "            dataset.loc[r, c] = min_p_value\n",
    "            \n",
    "            lags.loc[r, c] = min_p_value_i\n",
    "   \n",
    "    return dataset, lags\n",
    "\n",
    "def get_causal_vars(data, significance=0.95, getLags=False, getCausalSig=False, verbose=False):\n",
    "    cols = data.columns[:-1]\n",
    "    causal_vars = []\n",
    "    causal_lags = []\n",
    "    \n",
    "    for col in cols:\n",
    "        try:\n",
    "            gc, lags = grangers_causality_matrix(data[[col, 'LastPrice']], \n",
    "                                             variables=[col, 'LastPrice'], \n",
    "                                             verbose=False)\n",
    "        except:\n",
    "            raise Exception(data[[col, 'LastPrice']])\n",
    "        \n",
    "        gc = 1 - gc\n",
    "        \n",
    "        col_causes = gc.loc['LastPrice', col] >= significance\n",
    "        col_causedBy = gc.loc[col, 'LastPrice'] >= significance\n",
    "        if col_causes or col_causedBy:\n",
    "            if getCausalSig:\n",
    "                causal_vars.append((col, max(gc.loc['LastPrice', col], gc.loc[col, 'LastPrice'])))\n",
    "            else:\n",
    "                causal_vars.append(col)\n",
    "            \n",
    "            if getLags:\n",
    "                # if sig. granger causality for topic causing ts and ts causing topic, choose whichever is higher\n",
    "                if col_causes and col_causedBy:\n",
    "                    if gc.loc['LastPrice', col] >= gc.loc[col, 'LastPrice']:\n",
    "                        causal_lags.append(lags.loc['LastPrice', col])\n",
    "                    else:\n",
    "                        causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "                elif col_causes:\n",
    "                    causal_lags.append(lags.loc['LastPrice', col])\n",
    "                else:\n",
    "                    causal_lags.append(lags.loc[col, 'LastPrice'] * -1)\n",
    "    if getLags:\n",
    "        return causal_vars, causal_lags\n",
    "    \n",
    "    return causal_vars\n",
    "                \n",
    "def get_word_stream(nytimes, topics, causal_topics):\n",
    "    ct_ws = []\n",
    "    for ct in causal_topics:\n",
    "        causal_vocab = list(set(topics[ct][1]))\n",
    "        date_terms = pd.DataFrame(np.zeros((len(unique_dates), len(causal_vocab))), index=unique_dates, columns=causal_vocab)\n",
    "        \n",
    "        for word in causal_vocab:\n",
    "            date_terms[word] = date_term_cnts[word]\n",
    "            \n",
    "        ct_ws.append((ct, date_terms))\n",
    "    \n",
    "    return ct_ws\n",
    "\n",
    "def get_impact_words(topic_wordstream, significance=0.95, verbose=False):\n",
    "    topic_impact_words = []\n",
    "    \n",
    "    first = True\n",
    "    for topic, ws in topic_wordstream:\n",
    "        ws_prices = ws.join(stock_prices.set_index('Date')).dropna()        \n",
    "        ws_gc = get_causal_vars(ws_prices, significance=significance, getCausalSig=True, verbose=verbose)\n",
    "        \n",
    "        pos = []\n",
    "        neg = []\n",
    "        for word, sig in ws_gc:                \n",
    "            corr = pearsonr(ws_prices[word], stock_prices['LastPrice'])[0]\n",
    "            if corr > 0:\n",
    "                pos.append((word, sig))\n",
    "            else:\n",
    "                neg.append((word, sig))\n",
    "                \n",
    "        topic_impact_words.append((topic, pos, neg))\n",
    "    \n",
    "    return topic_impact_words\n",
    "        \n",
    "def construct_prior(impact_words, curr_k, sig=0.95):\n",
    "    # find number of topics that we are splitting\n",
    "#     new_k = curr_k + len(impact_words)\n",
    "    new_k = curr_k\n",
    "    word_priors = np.zeros((new_k, date_term_cnts.shape[1])) + 0.001\n",
    "\n",
    "    i = 0\n",
    "    for num, pos, neg in impact_words:\n",
    "        pos_denom = sum([granger-sig for word, granger in pos])\n",
    "        neg_denom = sum([granger-sig for word, granger in neg])\n",
    "        \n",
    "        if len(pos) < 0.1 * len(neg):\n",
    "            # num neg words >> num pos\n",
    "            for word, granger in pos:              \n",
    "                word_priors[i, id2word.token2id[word]] = 0\n",
    "            for word, granger in neg:\n",
    "                word_priors[i, id2word.token2id[word]] = (granger-sig)/neg_denom \n",
    "            \n",
    "        elif len(neg) < 0.1 * len(pos):\n",
    "            # num pos words >> num neg\n",
    "            for word, granger in pos:              \n",
    "                word_priors[i, id2word.token2id[word]] = (granger-sig)/pos_denom \n",
    "            for word, granger in neg:\n",
    "                word_priors[i, id2word.token2id[word]] = 0\n",
    "            \n",
    "\n",
    "        for word, granger in pos:              \n",
    "            word_priors[i, id2word.token2id[word]] = (granger-sig)/pos_denom \n",
    "        \n",
    "        for word, granger in neg:\n",
    "            word_priors[i + 1, id2word.token2id[word]] = (granger-sig)/neg_denom \n",
    "        \n",
    "        i += 2\n",
    "    return word_priors\n",
    "            \n",
    "def calculate_purity(pWords, nWords):\n",
    "    n = float(len(pWords) + len(nWords))\n",
    "    pProb = len(pWords)/n\n",
    "    nProb = len(nWords)/n\n",
    "    \n",
    "    pProb = pProb if pProb else 1\n",
    "    nProb = nProb if nProb else 1\n",
    "    \n",
    "    entropy = pProb * np.log2(pProb) + nProb * np.log2(nProb)\n",
    "    purity = 100 + 100 * entropy\n",
    "    return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Purity:  27.064402139120297\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.9076785714285714\n",
      "Purity:  16.181895109383632\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.9259888888888889\n",
      "Purity:  0.24974536308847917\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.0\n",
      "Purity:  0\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.9343619047619048\n",
      "Purity:  11.714393630795108\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.8232499999999999\n",
      "Purity:  27.80719051126377\n",
      "\n",
      "Number topics:  10\n",
      "Avg. Conf:  0.729425\n",
      "Purity:  8.170416594551043\n"
     ]
    }
   ],
   "source": [
    "isBaseline = True\n",
    "baseline_purity = 0.0\n",
    "prevPurity = 100\n",
    "purity = 0\n",
    "threshold = 10**-16\n",
    "mu = 1\n",
    "k = 10\n",
    "alpha = \"auto\"\n",
    "eta = \"auto\"\n",
    "\n",
    "avg_purities = []\n",
    "\n",
    "# while k < 30 and rel_purity(prevPurity, purity) <= threshold:\n",
    "num_iter = 0\n",
    "while num_iter <= 5:\n",
    "    if isBaseline:\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(\n",
    "                                corpus=tfidf_corpus,\n",
    "                                id2word=id2word,\n",
    "                                num_topics=k, \n",
    "                                passes=10,\n",
    "                                iterations=10,\n",
    "                                alpha='auto',  # assuming that topic distribution is assymetric. Not all topics equally represented in corpus.\n",
    "                                eta='auto')        \n",
    "        \n",
    "        topics = get_topics(lda_model, prob_thresh=0.3, num_words=50)\n",
    "        ct_ws = get_word_stream(nytimes, topics, [i for i in range(k)])\n",
    "\n",
    "        impact_words = get_impact_words(ct_ws)\n",
    "\n",
    "        purities = [calculate_purity(topic[1], topic[2]) for topic in impact_words]\n",
    "        baseline_purity = sum(purities)/len(purities)\n",
    "        prev_purity = baseline_purity\n",
    "        \n",
    "        print (\"Baseline Purity: \", baseline_purity)\n",
    "        \n",
    "        isBaseline = False\n",
    "        avg_purities.append(baseline_purity)\n",
    "        continue\n",
    "    else:\n",
    "        print (\"\\nNumber topics: \", k)          \n",
    "            \n",
    "        lda_model = gensim.models.ldamodel.LdaModel(\n",
    "                                corpus=tfidf_corpus,\n",
    "                                id2word=id2word,\n",
    "                                num_topics=k, \n",
    "                                passes=10,\n",
    "                                iterations=10,\n",
    "                                alpha=alpha,  # assuming that topic distribution is assymetric. Not all topics equally represented in corpus.\n",
    "                                eta=eta,\n",
    "                                decay=mu)\n",
    "        \n",
    "    topics = get_topics(lda_model, prob_thresh=0.3, num_words=50)\n",
    "    document_topics = lda_model.get_document_topics(corpus)\n",
    "    date_doc_topics = list(zip(nytimes[\"Date\"], lda_model.get_document_topics(corpus)))\n",
    "    \n",
    "    # for any given day, you look at all the diff topics and identify the prob of that topic\n",
    "    date_topic_prob = np.zeros((len(unique_dates), k))\n",
    "    for date, article in date_doc_topics:\n",
    "        i = unique_dates.index(date)\n",
    "        for topic, prob in article:\n",
    "            date_topic_prob[i][topic] += prob \n",
    "            \n",
    "    date_topic = pd.DataFrame(date_topic_prob, index=unique_dates)\n",
    "    date_topic[\"Date\"] = unique_dates\n",
    "    \n",
    "    date_topic_prices = date_topic.set_index('Date').join(stock_prices.set_index('Date')).dropna()\n",
    "    causal_topics, ct_lags = get_causal_vars(date_topic_prices, getLags=True)\n",
    "    ct_ws = get_word_stream(nytimes, topics, causal_topics)\n",
    "\n",
    "    impact_words = get_impact_words(ct_ws)\n",
    "    \n",
    "    all_conf = 0.0\n",
    "    num_words = 0\n",
    "    for topic, pos, neg in impact_words:\n",
    "        num_words += len(pos) + len(neg)\n",
    "        for words, gc in pos:\n",
    "            all_conf += gc\n",
    "            \n",
    "        for words, gc in neg:\n",
    "            all_conf += gc\n",
    "    print (\"Avg. Conf: \", all_conf/(num_words + 1))\n",
    "    \n",
    "    eta = construct_prior(impact_words, k)\n",
    "    \n",
    "    purities = [calculate_purity(topic[1], topic[2]) for topic in impact_words]\n",
    "    if len(purities) == 0:\n",
    "        avg_purity= 0\n",
    "    else:\n",
    "        avg_purity = sum(purities)/len(purities)\n",
    "    \n",
    "    prevPurity = purity\n",
    "    purity = avg_purity\n",
    "    \n",
    "    avg_purities.append(purity)\n",
    "    print (\"Purity: \", purity)\n",
    "    \n",
    "    # adjust num topics\n",
    "#     k += len(impact_words)\n",
    "    \n",
    "    num_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "confidences = [0.9076785714285714, 0.9259888888888889, 0.90, 0.9343619047619048, 0.8232499999999999, 0.729425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Avg Purity')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(range(6), avg_purities[1:], label=\"VarTN\")\n",
    "plt.plot(range(6), confidences, label=\"10\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Avg Purity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagaskak/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[45.64355568004036,\n",
       " 0.892394016177775,\n",
       " 13.521302074318882,\n",
       " 2.904940554533141,\n",
       " 10.442655944485722,\n",
       " 21.84108674155414]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_purities[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
